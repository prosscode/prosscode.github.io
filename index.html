<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>PROSS</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 5.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">PROSS</h1><a id="logo" href="/.">PROSS</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a><a href="/daysmatter/"><i class="fa fa-home"> DaysMatter</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/archives/2019/12/10/">SparkStreaming之解析mapWithState</a></h1><div class="post-meta">2019-12-10</div><a class="disqus-comment-count" data-disqus-identifier="archives/2019/12/10/" href="/archives/2019/12/10/#disqus_thread"></a><div class="post-content"><p>最近经历挫折教育，今天闲得时间，整理状态管理之解析mapWithState。今天说道的mapWithState是从Spark1.6开始引入的一种新的状态管理机制，支持输出全量的状态和更新的状态，支持对状态超时的管理，和自主选择需要的输出。</p></div><p class="readmore"><a href="/archives/2019/12/10/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/archives/2019/10/19/">SparkStreaming之解析updateStateByKey</a></h1><div class="post-meta">2019-10-19</div><a class="disqus-comment-count" data-disqus-identifier="archives/2019/10/19/" href="/archives/2019/10/19/#disqus_thread"></a><div class="post-content"><p>说到Spark Streaming的状态管理，就会想到updateStateByKey，还有mapWithState。今天整理了一下，着重了解一下前者。</p>
<h4 id="状态管理的需求"><a href="#状态管理的需求" class="headerlink" title="状态管理的需求"></a>状态管理的需求</h4><p>举一个最简单的需求例子来解释状态（state）管理，现在有这样的一个需求：计算从数据流开始到目前为止单词出现的次数。是不是看起来很眼熟，这其实就是一个升级版的wordcount，只不过需要在每个batchInterval计算当前batch的单词计数，然后对各个批次的计数进行累加。每一个批次的累积的计数就是当前的一个状态值。我们需要把这个状态保存下来，和后面批次单词的计数结果来进行计算，这样我们就能不断的在历史的基础上进行次数的更新。</p>
<p>SparkStreaming提供了两种方法来解决这个问题：updateStateByKey和mapWithState。mapWithState是1.6版本新增的功能，官方说性能较updateStateByKey提升10倍。</p></div><p class="readmore"><a href="/archives/2019/10/19/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/archives/2019/09/09/">Apache-Thrift-Thrift-Thrift</a></h1><div class="post-meta">2019-09-09</div><a class="disqus-comment-count" data-disqus-identifier="archives/2019/09/09/" href="/archives/2019/09/09/#disqus_thread"></a><div class="post-content"><p>接着上篇文章说。</p>
<p>我们知道了Apache Thrift主要用于各个服务之间的RPC通信，并且支持跨语言；包括C++，Java，Python，PHP，Ruby，Go，Node.js等等，还有一些都没听说过的语言；而且从上篇文章的RPC例子中可以发现，Thrift是一个典型的CS（客户端/服务端）架构；加上跨语言的特性，我们可以推断一下：客户端和服务端是可以使用不同的语言开发的。</p>
<p>如果CS端可以使用不同的语言来开发，那么一定是有一种中间语言来关联客户端和服务端（相同语言也需要关联客户端和服务端）。其实这个答案都知道，那就是接口定义语言：IDL（Interface Description Language）；下面我们从IDL进行开场表演，进行一次Thrift RPC的完整演出。</p></div><p class="readmore"><a href="/archives/2019/09/09/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/archives/2019/08/17/">远程过程调用</a></h1><div class="post-meta">2019-08-17</div><a class="disqus-comment-count" data-disqus-identifier="archives/2019/08/17/" href="/archives/2019/08/17/#disqus_thread"></a><div class="post-content"><p>啊，原本是写一篇Apache Thrift in HiveServer，改写JDBC连接Hive相关应用的推文，因为HiveServer是使用Thrift提供服务创建网络RPC的多种语言客户端；单独拿出来说，使用Thrift也可以轻松构建RPC服务器，是轻量级的跨语言的远程服务调用框架。说到远程过程调用，感觉又要解释很多，所以就先上个前菜，说一说远程过程调用（RPC）；并加了一份佐料：关于JDBC连接Hive的实现。</p></div><p class="readmore"><a href="/archives/2019/08/17/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/archives/2019/05/29/">理解Spark核心之RDD</a></h1><div class="post-meta">2019-05-29</div><a class="disqus-comment-count" data-disqus-identifier="archives/2019/05/29/" href="/archives/2019/05/29/#disqus_thread"></a><div class="post-content"><p>Spark是围绕RDD的概念展开的，RDD是可以并行操作的容错元素集合。RDD全称是Resilient Distributed Datasets（弹性分布式数据集）</p>
<h4 id="理解RDD"><a href="#理解RDD" class="headerlink" title="理解RDD"></a>理解RDD</h4><p>如果你在Spark集群中加载了一个很大的文本数据，Spark就会将该文本抽象为一个RDD，这个RDD根据你定义的分区策略（比如HashKey）可以分为数个Partition，这样就可以对各个分区进行并行处理，从而提高效率。</p>
<p>RDD是一个容错的，并行的数据结构，可以让用户显示地将数据存储到磁盘和内存中，并能控制数据的分区。同时，RDD还提供了一组丰富的操作来操作这些数据。在这些操作中，比如Map、flatMap、filter等转换操作实现了monad模式（Monad是一种设计模式，表示将一个运算过程，通过函数拆解成互相连接的多个步骤；你只要提供下一步运算所需的函数，整个运算就会自动进行下去。），很好的切合了Scala的集合操作。另外，RDD还提供了比如join，groupBy，reduceByKey（action操作）等更为方便的操作，用来支持常见的数据运算。</p>
<p>RDD是一系列只读分区的集合，它只能从文件中读取并创建，或者从旧的RDD生成新的RDD。RDD的每一次变换操作都会生成新的RDD，而不是在原来的基础上进行修改，这种粗粒度的数据操作方式为RDD带来了容错和数据共享方面的优势，但是在面对大数据集中频繁的小操作的时候，显得效率比较低下。</p></div><p class="readmore"><a href="/archives/2019/05/29/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/archives/2019/03/15/">Spark的运行模式</a></h1><div class="post-meta">2019-03-15</div><a class="disqus-comment-count" data-disqus-identifier="archives/2019/03/15/" href="/archives/2019/03/15/#disqus_thread"></a><div class="post-content"><p>Spark是新一代基于内存的计算框架，是用于大规模数据处理的同意分析引擎。相比于Hadoop MapReduce计算框架，Spark将中间计算结果保留在内存中，速度提升10~100倍；同时采用弹性分布式数据集（RDD）实现迭代计算，更好的适用于数据挖掘、机器学习，极大的提升开发效率。</p>
<p>Spark的运行模式，它不仅支持单机模式，同时支持集群模式运行；这里具体的总结一下Spark的各种运行模式的区分。</p>
<h4 id="Local模式"><a href="#Local模式" class="headerlink" title="Local模式"></a>Local模式</h4><p>Local模式又称本地模式，通过Local模式运行非常简单，只需要把Spark的安装包解压后，改一些常用的配置即可使用，而不用启动Spark的Master、Worker进程（只有集群的Standalone模式运行时，才需要这两个角色），也不用启动Hadoop的服务，除非你需要用到HDFS。</p></div><p class="readmore"><a href="/archives/2019/03/15/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/archives/2019/02/02/">使用Swagger2构建RESTful API</a></h1><div class="post-meta">2019-02-02</div><a class="disqus-comment-count" data-disqus-identifier="archives/2019/02/02/" href="/archives/2019/02/02/#disqus_thread"></a><div class="post-content"><p>吐槽了一阵公司提供的记录接口文档工具后，抽个空档时间搭了个RESTful风格的API文档Demo，感觉还不错，在这里记录一下，技术栈使用Spring Boot+Swagger2。</p>
<p>Swagger可以很轻松的整合到Spring Boot中，在代码里根据swagger语法打些标签，生成可预览的Api文档，减少了很多时间写API接口文档上，让维护文档和修改代码整合一体了，并且可以与Spring MVC程序配合组织出强大RESTful API文档，也能提供了强大的页面测试功能来调试测试每个接口。</p></div><p class="readmore"><a href="/archives/2019/02/02/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/archives/2019/01/13/">散列表</a></h1><div class="post-meta">2019-01-13</div><a class="disqus-comment-count" data-disqus-identifier="archives/2019/01/13/" href="/archives/2019/01/13/#disqus_thread"></a><div class="post-content"><p>关于算法系列，在前面已经整理过大O表示法和排序算法相关的文章，今天接着上次的话说一说散列表（Hash Table，也叫哈希表），顺便穿插和另外两种基本的数据结构，数组和链表比较；并在最后介绍良好的散列函数——SHA函数的使用。这三种基本数据结构，可简可繁，在写代码时候都是比较频繁使用的，那我们先从散列表开始入手。</p>
<p>散列表是根据键（Key）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做<code>散列函数</code>，存放记录的数组称做<code>散列表</code>。散列表是最有用的基本数据结构之一，我们需要总结散列表：实现、冲突和散列函数。</p></div><p class="readmore"><a href="/archives/2019/01/13/">Read More</a></p></div><nav class="page-navigator"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">Next</a></nav><script id="dsq-count-scr" src="//pross-space.disqus.com/count.js" async></script></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://pross.space"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Thrift/" style="font-size: 15px;">Thrift</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Hibernate/" style="font-size: 15px;">Hibernate</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/MapReduce/" style="font-size: 15px;">MapReduce</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/tags/%E9%9A%8F%E7%AC%94%E6%9D%82%E8%AE%B0/" style="font-size: 15px;">随笔杂记</a> <a href="/tags/Swagger/" style="font-size: 15px;">Swagger</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 15px;">数据结构</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 15px;">设计模式</a> <a href="/tags/RPC/" style="font-size: 15px;">RPC</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/archives/2019/12/10/">SparkStreaming之解析mapWithState</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/10/19/">SparkStreaming之解析updateStateByKey</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/09/09/">Apache-Thrift-Thrift-Thrift</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/08/17/">远程过程调用</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/05/29/">理解Spark核心之RDD</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/03/15/">Spark的运行模式</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/02/02/">使用Swagger2构建RESTful API</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/01/13/">散列表</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/01/01/">几种定时调度的介绍与实现</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/12/22/">Java线程池</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/prosscode" title="Github" target="_blank">Github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">PROSS.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>