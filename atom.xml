<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Pross&#39;s Blog</title>
  
  
  <link href="https://pross.space/atom.xml" rel="self"/>
  
  <link href="https://pross.space/"/>
  <updated>2021-03-31T12:17:09.461Z</updated>
  <id>https://pross.space/</id>
  
  <author>
    <name>RukiapR0ss</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>谈谈Kafka中CAP理论的实践</title>
    <link href="https://pross.space/blog/2021/03/26/talk-about-the-practice-of-cap-theory-in-kafka.html"/>
    <id>https://pross.space/blog/2021/03/26/talk-about-the-practice-of-cap-theory-in-kafka.html</id>
    <published>2021-03-26T10:13:25.000Z</published>
    <updated>2021-03-31T12:17:09.461Z</updated>
    
    <content type="html"><![CDATA[<p>在现在发布的绝大部分项目中，大部分都是采用的分布式系统架构。分布式系统可以防止系统突然宕机导致服务整体不可用，可以从容的应对高并发请求，从而提高系统的可用性。但是如果实现一个分布式系统，经过一段时间的编码和设计，其实会发现并没有这么简单。</p><p>相比于单机系统，分布式系统需要多台服务器，而服务器之间的通信是需要绝对保障的；如果通信超时，会影响项目的正常运行；如果是分布式存储系统（不仅仅是），写入的数据也需要被同步到多台服务器上，数据更新肯定是有一定的延迟的，怎么权衡延迟时间和数据实时性的要求更需要被考虑；如果是Leader服务器宕机了，follower服务器需要立刻自动切换角色，提供服务，且要保证数据一致性等等，这些都是在分布式系统设计中需要被面对的问题。</p><p>有没有一个架构或框架，能够解决在分布式系统中面临的问题？答案是没有。这个问题起源于加州大学柏克莱分校（University of California, Berkeley）的计算机科学家埃里克·布鲁尔（Eric Brewer），在2000年的分布式计算原理研讨会（PODC）上提出的猜想。但在2002年，麻省理工学院的赛斯·吉尔伯特和南希·林奇证明了布鲁尔的猜想，使之成为一个定理，这个就是<strong>CAP定理</strong>（CAP theorem），也被称作<strong>布鲁尔定理</strong>（Brewer’s theorem）。</p><p>Kafka是一个典型的分布式系统，涉及到数据存储和数据传递（通信），Kafka在设计和开发的过程中，是怎么合理的解决分布式系统普遍面临的这些问题的呢？那么今天的这篇文章，来谈谈CAP理论在Kafka中的实践。</p><a id="more"></a><p>（因篇幅稍长，可Mark后细看。）</p><h4 id="理解CAP定理"><a href="#理解CAP定理" class="headerlink" title="理解CAP定理"></a>理解CAP定理</h4><p>CAP定理对于分布式系统的设计是一个很重要的参考，它指出对于一个分布式系统来说，不可能同时满足以下三点：</p><ul><li>一致性（Consistency），表示数据一致性，即所有节点在同一时间的数据完全一致。</li><li>可用性（Availability），表示服务高可用，即分布式服务在正常响应时间内一直是可用状态。</li><li>分区容错性（Partition tolerance），分区相当于对通信的时限要求。即当遇到网络分区故障时，仍然可满足一致性和可用性服务。</li></ul><p>根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。</p><p><strong>理解CAP理论最简单方式是想象两个节点分在分区两侧（出现网络分区故障）</strong>，允许至少一个节点更新状态会导致数据不一致，即丧失了C性质（无法通信，数据不一致）。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质（服务高可用）。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质（不满足分区容错）。</p><img src="https://image-static.segmentfault.com/272/788/2727887823-5afe4f365241b_fix732" style="zoom:75%;" /><p>对于需要在分布式条件下运行的系统而言，如果在一致性、可用性和分区容错性中取舍（或者说是弱化）哪一个属性是首要考虑的问题。在现实场景中，网络分区故障是比较容易出现的问题，并且人为因素也有可能导致，因此往往选择就在CP或者AP中，但是往往也不是严格的AP或者CP系统，比如Apache Zookeeper：</p><p>Zookeeper是用于分布式系统中的协调服务，用于同步，节点状态、配置等信息、服务注册等信息，所以一定得需要数据的一致性，任何时刻对ZooKeeper的访问请求能得到一致的数据结果。</p><p>我们采用理解CAP理论的方式来理解Zookeeper的设计：Zookeeper采用ZAB（ZooKeeper Atomic Broadcast）协议（崩溃恢复和消息广播模式），当出现网络崩溃等异常情况，ZAB协议进入恢复模式，并选举产生新的Leader服务器，当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进入消息广播模式。当有同样遵守 ZAB 协议的服务器（因为出现了网络故障）启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播 ， 那么新加的服务器就会自觉地进入数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去，并提供数据一致性服务。</p><p>但是在恢复模式中，选举Leader节点可能花费时间较长，这就导致在选举期间服务会短暂不可用，但是服务能够最终是恢复了。所以说，在ZooKeeper设计中，为了实现CP特性，就不得不弱化了服务高可用性，但是这不代表Zookeeper完全失去了AP特性。</p><p>所以，如果将精力浪费在思考如何设计能满足三者的完美系统上是错误的路线，应该根据应用场景进行适当的配置来进行取舍。那么，Kafka是满足了CAP定理的哪两种特性呢？</p><p>接下来我们看看Kafka在设计时，是如何进行适当权衡的。</p><h4 id="Kafka可用性"><a href="#Kafka可用性" class="headerlink" title="Kafka可用性"></a>Kafka可用性</h4><p>对于分布式系统来说，当集群规模上升到一定程度后，一台或者多台机器宕机的可能性会大大提高，这是一个概率问题。所以，对于Failover机制的要求也非常高，对于Kafka消息引擎系统而言，如果频繁出现数据丢失或在一定时间内服务不可用的问题，这绝对不是不可容忍的，于是Kafka在0.8版本之后，提供了High Availablity机制。</p><p>在分布式系统中，我们都说可用性保证的是该服务的高可用；但是在Kafka只要有一台Broker正常存在，那么就可以继续提供服务的，因为Kafka的元数据保存在Zookeeper中，只要Broker存在，既可以提供正常的服务。那么既然如此，Kafka提供的服务是提供的什么？Kafka高可用性保证是什么？</p><p>显而易见，如果一旦有一个或多个Broker宕机，如果没有高可用机制，则宕机期间其上所有Partition都无法继续提供服务；如果该Broker出现了磁盘故障，永远不能再恢复了，那么该服务器上所有的数据就彻底丢失了，那么消息是否能够正常获取或消费，决定着Kafka是否能够提供正常服务。所以，对于Kafka而言，提供的是消息可用性服务；那服务高可用在于，保证Kafka中消息的高可用性。</p><p>所以，Kafka在保障消息的高可用性上，推出了几项机制：</p><ul><li>引入Replication机制，分配Replica。</li><li>动态维护ISR副本集合，选举Leader提供消息服务。</li></ul><p><strong>Replication机制</strong></p><p>在Kafka消息日志解析中，我们讨论过，Kafka消息设计是三层结构：主题-分区-消息。分区是为了实现高伸缩性和提供负载均衡，可以很好的让一个比较大的Topic中的消息分布到多台Broker机器上，并提高并行能力。</p><p>Kafka的Replication机制，会尽量将所有的Partition均匀分配到整个集群上，同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的Broker机器上，Kafka分配Replica的的算法如下：</p><ul><li>将所有Broker（假设共n个Broker）和待分配的Partition排序</li><li>将第i个Partition分配到第（i mod n）个Broker上</li><li>将第i个Partition的第j个Replica分配到第（ (i + j) mod n）个Broker上</li></ul><p>这样做的好处是，如果所有的Replica都在同一个Broker上，那一旦该Broker宕机，该Partition的所有Replica都无法工作；如果Replica分散在不同的Broker机器上，则可以尽可能的避免这个问题，从而尽可能的达到Partition的高可用。Replica个数是由<code>replication.factor</code>参数决定。</p><img src="https://static001.infoq.cn/resource/image/83/88/83afae5ea62d63d69c69cd650ae14e88.png" style="zoom:50%;" /><p>通过Replica，可以解决Partition的高可用问题，但是又出现了几个新的问题：Producer发送消息，Replica之间怎么同步消息？Producer怎么才确认Broker已经收到消息了呢？如果Replica都不可用了怎么办？这我们得来说说，ISR(in-sync replicas)副本策略。</p><p><strong>ISR副本策略</strong></p><p>Kafka的ISR副本策略动态的维护了一个包含所有已提交日志副本的节点集合，并且存储在Zookeeper中。当触发选举时，会从Zookeeper保存的ISR副本节点中，选出一个作为Leader副本，其它则是Follower副本，ISR副本策略节点集合最小个数由<code>min.insync.replicas</code>参数决定，需要注意的是，<code>min.insync.replicas &gt;= replication.factor</code>。所有追上Leader副本消息进度的Follower副本都应该在ISR副本策略中，Leader副本本身也在ISR副本集合中。</p><p>如果Leader节点突然宕机，但是ISR副本集合中没有节点可用。那该怎么办？Kafka提供<code>unclean.leader.election.enable=false</code>参数来让用户决定应该怎么办；如果为true，则表示非ISR集合中的副本也可以参加选举成为Leader；默认是为true，意思是只能从ISR副本集合中选出Leader，这样可以避免数据丢失，但是如果没有可用的ISR副本，那么这个分区将处于不可用状态，只能等待ISR副本节点恢复可用。</p><p>Producer怎么才确认Broker已经收到消息了呢？Kafka提供了一个Broker的参数：<code>acks = all</code>，参数有0、1和all三个值可以选择。如果值为0，则表示Producer不需要等待任何确认收到的信息；如果值为1，则至少要等待Leader已经成功将数据写入本地Log中；如果值是all的话，则需要在ISR副本集合中的所有的副本都确认收到消息，才算消息成功写入。</p><p>我们发现上面的三个参数不同但组合其实可以达到不同的效果，比如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">replication.factor = <span class="number">3</span></span><br><span class="line">min.insync.replicas = <span class="number">3</span></span><br><span class="line">acks = all</span><br></pre></td></tr></table></figure><p>上面配置组合，使得Kafka尽可能满足CP特性。任意写入一条数据，需要复制保存三个副本，且每个副本都要求在ISR副本集合中，并且Producer产生的消息必须等所有副本都成功写入才算完成commit；即使在有副本的节点宕机的情况下，在任意节点都可以消费到这条数据，包括Leader节点宕机的情况；但是这样会损耗了部分吞吐性能，因为要等待ISR集合中所有副本都成功写入。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">replication.factor = <span class="number">3</span></span><br><span class="line">min.insync.replicas = <span class="number">3</span></span><br><span class="line">acks = <span class="number">1</span></span><br></pre></td></tr></table></figure><p>而这组配置，主要是保证可用性，使得Kafka满足AP特性。对于任意写入一条数据，当Leader节点副本commit了之后就返回ack；如果Leader节点在数据被发送到从节点之前就宕机，这时，重新选举之后，Consumer就消费不到这条数据。这种配置，保证了消息可用性，但是损失了一致性。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">replication.factor = <span class="number">3</span></span><br><span class="line">min.insync.replicas = <span class="number">2</span></span><br><span class="line">acks = all</span><br></pre></td></tr></table></figure><p>基于最后的这种配置组合，虽然会损失了一定的consistency和availability，使得Kafka满足的是一种介于AP和CP之间的一种平衡状态。因为，在这种配置下，可以在容忍一个节点（包括Leader节点）宕机的情况下，尽可能保证数据一致性和整体可用性；但是有两个节点宕机的情况，该分区整体也会不可用。</p><h4 id="Kafka一致性"><a href="#Kafka一致性" class="headerlink" title="Kafka一致性"></a>Kafka一致性</h4><p>关于保证一致性部分，用词说的是，尽可能的保证了数据一致性。为什么这样说？在这之前，我们先简单介绍Kafka的高水位(High Watermark，HW）和日志末端位移（Log End offset，LEO）概念以及Kafka副本同步消息的详细流程。</p><p><strong>High Watermark和Log End offset</strong></p><p>高水位（HW）其实就是表示的是已经提交(commit)的最大日志偏移量；而日志末端位移（LEO）是记录了该副本日志(Log)中下一条消息的位移值，比如LEO=10，表示副本日志中保存了10条消息，位移范围值是[0-9]。</p><img src="https://pic2.zhimg.com/80/v2-944238b824c604d817109c0b1a51469d_1440w.jpg" style="zoom:50%;" /><p>已经提交的日志和未提交的日志的区别在于，Consumer是否能够消费到，所以在HW位移位置以下，即被Leader和ISR副本集合内的Follower都确认commit写入本地的消息，都可以认为是不会丢失的。所以在上图中，可被消费的消息位移范围值是[0-7]，[8-14]表示已经写入当前节点副本的本地的Log中，但还没被commit的消息日志。</p><p><strong>Kafka副本同步消息</strong></p><p>我们假设两个副本：Leade副本A和Follower副本B，且都ISR副本集合中，初始状态如下：</p><img src="/Users/shuang.peng/Library/Application Support/typora-user-images/image-20210330205720472.png" alt="image-20210330205720472" style="zoom:50%;" /><p>Leader节点会缓存一份其它副本的LEO值（remote LEO），Leader副本会依赖remote LEO值来更新HW（ISR副本集合中的所有副本都成功写入，Leader HW才会更新）。Leader副本更新HW值=max (currentHW, min(LEO-1, LEO-2, ……，LEO-n) )，Follower副本更新HW值=min(currentHW, currentLEO)。</p><p>当Producer给分区发送一条消息后，Leader会写入到本地Log中，并更新自己的LEO；Follower会带上自己的LEO值，发起fetch request来pull数据；Leader收到请求后，会更新remote LEO和HW值，并带上自己的HW值和消息log，传输给Follower副本；Follower副本接收到消息，写入本地Log中，并更新自己的LEO值，状态变更如下：</p><img src="/Users/shuang.peng/Library/Application Support/typora-user-images/image-20210330210206783.png" alt="image-20210330210206783" style="zoom:50%;" /><p>各自都发送请求后，Leader和Follower副本的LEO都是1，但各自的HW依然是 0，还没有被更新。在第二次Follower发起fetch request请求后，Leader更新remote LEO=1，然后更新Leader HW为1。更新完后，Leader会将当前已更新过的HW=1的值发送给 Follower 副本，Follower副本根据min(leader hw, leo)计算来更新自己的HW值，最终状态如下：</p><img src="/Users/shuang.peng/Library/Application Support/typora-user-images/image-20210331121057234.png" alt="image-20210331121057234" style="zoom:50%;" /><p>了解完这些后，我们能发现，其实Follower副本的HW更新需要第二次request请求才能得到更新，也就是说Leader副本HW更新和 Follower副本HW更新在时间上是存在错位的，这种错位在某些场景下就会导致“数据丢失” 或 “数据不一致”的问题。</p><p>我们假设一个特定的场景（<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation#KIP101AlterReplicationProtocoltouseLeaderEpochratherthanHighWatermarkforTruncation-LeaderEpoch">KAFKA/KIP-101</a>），Follower副本写入Log后，Leader副本节点宕机或不可用状态，经过选举后Follower副本成为Leader副本。</p><img src="/Users/shuang.peng/Library/Application Support/typora-user-images/image-20210331154511228.png" alt="image-20210331154511228" style="zoom:50%;" /><p>情况一：副本B成为Leader后，发现自己的HW=0，也就是说副本B的offset=1的数据是未提交确认的，副本B会做一个日志截断(log truncation)，把offset=1的消息日志删除掉，并调整LEO=1；等副本A恢复过来，发送请求同步Leader副本B的数据，发现Leader副本的HW=0，同样也会进行一个日志截断，和Leader副本数据保持一致。</p><img src="/Users/shuang.peng/Library/Application Support/typora-user-images/image-20210331121501503.png" alt="image-20210331121501503" style="zoom:50%;" /><p>这种情况会导致，原本已经写入副本A的数据会丢失，因为Producer端认为该消息日志已经提交，已经开始进行下一条消息的写入流程了，实际Kafka并没有存储到这条消息，导致Consumer根本消费不到。</p><p>情况二：副本B成为Leader后，也会进行日志截断，此时HW=0，LEO=1，副本A还没有恢复；当接收到了Producer发来的新消息（绿色框），副本B会更新LEO=2，HW=1，这时副本A恢复了，发送请求同步Leader副本B的数据，发现不需要进行日志截断和写入。</p><img src="/Users/shuang.peng/Library/Application Support/typora-user-images/image-20210331122644365.png" style="zoom:50%;" /><p>这种情况会导致，Leader副本A的日志和Follower副本B的数据不一致；在下次选举切换Leader副本后，新的Consumer消费该分区的数据会和之前Consumer消费的数据部分不一致。</p><p>导致数据不一致或丢失的根本原因是HW值被用于衡量副本写入日志的成功与否以及在出现宕机恢复时，作为日志截断的位移依据；但之前我们说过，Leader副本和Follower副本的HW值的更新时间是存在时间错位的，Follower需要额外的FETCH请求才能更新HW值。</p><p>为了解决精确一致性的问题，Kafka在0.11版本，引入了Leader epoch来取代作为日志截断依据的HW值。</p><p><strong>Leader Epoch</strong></p><p>Leader Epoch是由一对值组成：（epoch, offset）。</p><ul><li>Epoch：epoch表示Leader的版本号，一个单调增加的版本号。当Leader变更过时，epoch就会+1；小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader权力。</li><li>offset：消息起始位移，Leader副本在该Epoch值上写入的首条消息的位移。</li></ul><p>比如有两对值 (0, 0)和(1, 100)，表示第一个Leader从位移0开始写入消息；共写了120条[0, 99]；而第二个Leader版本号是1，从位移120处开始写入消息。Broker会把Leader Epoch数据缓存起来，并定期写入分区副本的日志文件leader-epoch-checkpoint中。</p><p>当Leader副本写入Log时，Broker会尝试更新，如果这个Leader首次写消息，则会在缓存中增加一条记录；而每次副本重新成为Leader时，会首先查询这部分缓存，获取出对应Leader版本的位移，在进行判断。</p><img src="/Users/shuang.peng/Library/Application Support/typora-user-images/image-20210331154534551.png" alt="image-20210331154534551" style="zoom:50%;" /><p>我们看看数据丢失的情况：引用Leader Epoch机制后，Follower副本B需要向Leader副本A发送OffsetsForLeadErepochRequest请求并同步数据，Leader副本A返回自身的LEO=2的值，此时副本B发现Leader副本的LEO值并不比自己的LEO值小，且缓存中也没有保存任何起始位移值大于Leader副本的LEO值，故不做任何日志截断的操作。</p><p>现在Leader副本A宕机，副本B成为Leader。同样地，当副本A重启回来后，执行与副本B相同的逻辑判断，发现也不用执行日志截断，至此位移值为1的那条消息在两个副本中均得到保留。后面当Producer程序向Leader副本B写入新消息时，Leader副本B所在的 Broker缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本B会使用这条记录帮助判断后续是否执行日志截断操作。这样，通过 Leader Epoch 机制，Kafka可以规避了这种数据丢失的场景。</p><img src="/Users/shuang.peng/Library/Application Support/typora-user-images/image-20210331161222850.png" alt="image-20210331161222850" style="zoom:50%;" /><p>我们再看看数据不一致的情况：副本B成为Leader副本后发现leader epoch缓存的位移值并没有大于自身的LEO值2，故不会做截断操作，保留了自身的offset=1的消息，并更新自身的HW=1。等副本A恢复后，发送请求同步Leader副本B的数据，执行相同的判断逻辑，也不需要进行日志截断，这样看来，两个副本的消息就保持了一致。</p><p>通过Leader Epoch机制，对高水位机制有了一个明显改进，即副本是否执行日志截断不再依赖于高水位进行判断，从而解决数据丢失和一致性问题。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>其实我们会发现，没有满足CAP定理的完美系统。在实现一个功能，满足一个特性的同时，还可能还会引入另外的问题。上面长篇介绍了Kafka在不同的版本增加的一些机制来解决遇到了问题，只是说明Kafka会提供一些配置参数，可以根据具体的业务需求，进行不同的配置，使得Kafka满足AP或者CP，或者使它们之间的达成一种平衡状态，这是一个tradeoff的过程。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在现在发布的绝大部分项目中，大部分都是采用的分布式系统架构。分布式系统可以防止系统突然宕机导致服务整体不可用，可以从容的应对高并发请求，从而提高系统的可用性。但是如果实现一个分布式系统，经过一段时间的编码和设计，其实会发现并没有这么简单。&lt;/p&gt;
&lt;p&gt;相比于单机系统，分布式系统需要多台服务器，而服务器之间的通信是需要绝对保障的；如果通信超时，会影响项目的正常运行；如果是分布式存储系统（不仅仅是），写入的数据也需要被同步到多台服务器上，数据更新肯定是有一定的延迟的，怎么权衡延迟时间和数据实时性的要求更需要被考虑；如果是Leader服务器宕机了，follower服务器需要立刻自动切换角色，提供服务，且要保证数据一致性等等，这些都是在分布式系统设计中需要被面对的问题。&lt;/p&gt;
&lt;p&gt;有没有一个架构或框架，能够解决在分布式系统中面临的问题？答案是没有。这个问题起源于加州大学柏克莱分校（University of California, Berkeley）的计算机科学家埃里克·布鲁尔（Eric Brewer），在2000年的分布式计算原理研讨会（PODC）上提出的猜想。但在2002年，麻省理工学院的赛斯·吉尔伯特和南希·林奇证明了布鲁尔的猜想，使之成为一个定理，这个就是&lt;strong&gt;CAP定理&lt;/strong&gt;（CAP theorem），也被称作&lt;strong&gt;布鲁尔定理&lt;/strong&gt;（Brewer’s theorem）。&lt;/p&gt;
&lt;p&gt;Kafka是一个典型的分布式系统，涉及到数据存储和数据传递（通信），Kafka在设计和开发的过程中，是怎么合理的解决分布式系统普遍面临的这些问题的呢？那么今天的这篇文章，来谈谈CAP理论在Kafka中的实践。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Kafka" scheme="https://pross.space/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka日志消息解析</title>
    <link href="https://pross.space/blog/2021/03/14/kafka-log-message-analysis.html"/>
    <id>https://pross.space/blog/2021/03/14/kafka-log-message-analysis.html</id>
    <published>2021-03-14T06:49:39.000Z</published>
    <updated>2021-03-15T05:19:11.338Z</updated>
    
    <content type="html"><![CDATA[<p>我们知道，写入kafka的消息都需要指定一个Topic（主题），Kafka可以根据Topic来对消息进行区分，每个Topic分为多个Partition（分区）。</p><p>Partition的概念是为了实现高伸缩性和提供负载均衡的作用，可以很好的让一个比较大的（数据量级）Topic中的消息可以分布到多台broker机器上。不仅如此，也可以提高并行能力，因为水平扩展后可以以Partition为粒度进行读写，这样每个broker节点都能独立执行各自分区的读写请求；</p><p>Partition下就是Log的消息体，每条消息都只会保存在某一个分区中，而且在每个Partition下消息都是append模式写入的，也就是说，每个Partition下的消息都是顺序性的。</p><p>Kafka消息设计方式就是这样的三层结构：主题-分区-消息；说到设计，不同的分布式系统对分区的叫法也不大一样，在Kafka中的概念是Partition（分区），在ES中叫做Shard（分片），而在HBase中被称为Region。从表面上来看实现原理可能不尽相同，但对底层实现的思想却都是一致的。</p><p>话题扯回来，今天这篇文章分享的主题是：Kafka消息格式。</p><a id="more"></a><p>消息存储在哪，取决于broker端的<code>log.dirs</code>参数决定，目录文件如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── __consumer_offsets-0</span><br><span class="line">│   ├── 00000000000000000000.index</span><br><span class="line">│   ├── 00000000000000000000.log</span><br><span class="line">│   ├── 00000000000000000000.timeindex</span><br><span class="line">│   └── leader-epoch-checkpoint</span><br><span class="line">├── log-start-offset-checkpoint</span><br><span class="line">├── meta.properties</span><br><span class="line">├── recovery-point-offset-checkpoint</span><br><span class="line">├── replication-offset-checkpoint</span><br><span class="line">├── test1-0</span><br><span class="line">├── test2-0</span><br><span class="line">└── test2-1</span><br><span class="line">    ├── 00000000000000000000.index</span><br><span class="line">    ├── 00000000000000000000.log</span><br><span class="line">    ├── 00000000000000000000.timeindex</span><br><span class="line">    ├── 00000000000000000013.index</span><br><span class="line">    ├── 00000000000000000013.log</span><br><span class="line">    ├── 00000000000000000013.timeindex</span><br><span class="line">    └── leader-epoch-checkpoint</span><br></pre></td></tr></table></figure><h4 id="位移主题"><a href="#位移主题" class="headerlink" title="位移主题"></a>位移主题</h4><p>__consumer_offsets是位移主题，老版本的Consumer的位移管理是在Zookeeper，在新版本中位移管理机制中是作为一个内部Topic的方式来记录位移。</p><p>新版本位移管理机制其实也比较简单，是将Consumer的位移数据作为一条条普通的 Kafka 消息，提交到__consumer_offsets中，以前读写位移操作就由Zookeeper变成了Kafka自身。在位移主题中的消息包含三类，消费者组注册消息（Group Metadata）、消费者组的已提交位移消息（Offset Commit）和Tombstone消息；其写入提交过程都可以交由Kafka自动管理起来，应用上并没有太大的差异。</p><p><strong>注册消息</strong></p><p>我们随着获取注册消息的key和value方法一路看下去</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> key = <span class="type">GroupMetadataManager</span>.groupMetadataKey(group.groupId)</span><br><span class="line"><span class="keyword">val</span> value = <span class="type">GroupMetadataManager</span>.groupMetadataValue(group, groupAssignment, interBrokerProtocolVersion)</span><br></pre></td></tr></table></figure><p>注册消息的key</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">GroupMetadataKey</span>(<span class="params">version: <span class="type">Short</span>, key: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">BaseKey</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 保存的是消费者组名称</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">toString</span></span>: <span class="type">String</span> = key</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由GroupMetadataManager类中的groupMetadataKey方法而来</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[group] <span class="function"><span class="keyword">def</span> <span class="title">groupMetadataKey</span></span>(group: <span class="type">String</span>): <span class="type">Array</span>[<span class="type">Byte</span>] = &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> key = <span class="keyword">new</span> <span class="type">Struct</span>(<span class="type">CURRENT_GROUP_KEY_SCHEMA</span>)</span><br><span class="line">    key.set(<span class="type">GROUP_KEY_GROUP_FIELD</span>, group)</span><br><span class="line"><span class="comment">// 构造ByteBuffer对象，容纳version和key</span></span><br><span class="line">    <span class="keyword">val</span> byteBuffer = <span class="type">ByteBuffer</span>.allocate(<span class="number">2</span> <span class="comment">/* version */</span> + key.sizeOf)</span><br><span class="line">    byteBuffer.putShort(<span class="type">CURRENT_GROUP_KEY_SCHEMA_VERSION</span>)</span><br><span class="line">  <span class="comment">// 写入byteBuffer</span></span><br><span class="line">    key.writeTo(byteBuffer)</span><br><span class="line">    byteBuffer.array()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>注册消息的key构造完毕，接下来是value。groupMetadataValue 方法会将消费者组重要的元数据写入到字节数组并返回。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * GroupMetadata 消费者组元数据对象</span></span><br><span class="line"><span class="comment"> * assignment 分区消费分配方案</span></span><br><span class="line"><span class="comment"> * apiVersion api版本号</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span>[group] <span class="function"><span class="keyword">def</span> <span class="title">groupMetadataValue</span></span>(groupMetadata: <span class="type">GroupMetadata</span>,</span><br><span class="line">                                        assignment: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Array</span>[<span class="type">Byte</span>]],</span><br><span class="line">                                        apiVersion: <span class="type">ApiVersion</span>): <span class="type">Array</span>[<span class="type">Byte</span>] = &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 依次写入消费者组主要的元数据信息</span></span><br><span class="line">    value.set(<span class="type">PROTOCOL_TYPE_KEY</span>, groupMetadata.protocolType.getOrElse(<span class="string">&quot;&quot;</span>))</span><br><span class="line">    value.set(<span class="type">GENERATION_KEY</span>, groupMetadata.generationId)</span><br><span class="line">    value.set(<span class="type">PROTOCOL_KEY</span>, groupMetadata.protocolOrNull)</span><br><span class="line">    value.set(<span class="type">LEADER_KEY</span>, groupMetadata.leaderOrNull)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">val</span> memberArray = groupMetadata.allMemberMetadata.map &#123; memberMetadata =&gt;</span><br><span class="line">      <span class="keyword">val</span> memberStruct = value.instance(<span class="type">MEMBERS_KEY</span>)</span><br><span class="line">      memberStruct.set(<span class="type">MEMBER_ID_KEY</span>, memberMetadata.memberId)</span><br><span class="line">      memberStruct.set(<span class="type">CLIENT_ID_KEY</span>, memberMetadata.clientId)</span><br><span class="line">      memberStruct.set(<span class="type">CLIENT_HOST_KEY</span>, memberMetadata.clientHost)</span><br><span class="line">      memberStruct.set(<span class="type">SESSION_TIMEOUT_KEY</span>, memberMetadata.sessionTimeoutMs)</span><br><span class="line">...</span><br><span class="line">      <span class="comment">// 写入消费订阅信息和费分配方案信息</span></span><br><span class="line">      <span class="keyword">val</span> metadata = memberMetadata.metadata(protocol)</span><br><span class="line">      memberStruct.set(<span class="type">SUBSCRIPTION_KEY</span>, <span class="type">ByteBuffer</span>.wrap(metadata))</span><br><span class="line">      <span class="keyword">val</span> memberAssignment = assignment(memberMetadata.memberId)</span><br><span class="line">      assert(memberAssignment != <span class="literal">null</span>)</span><br><span class="line">      memberStruct.set(<span class="type">ASSIGNMENT_KEY</span>, <span class="type">ByteBuffer</span>.wrap(memberAssignment))</span><br><span class="line">      memberStruct</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    value.set(<span class="type">MEMBERS_KEY</span>, memberArray.toArray)</span><br><span class="line">  <span class="comment">// 写入byteBuffer 并返回</span></span><br><span class="line">    <span class="keyword">val</span> byteBuffer = <span class="type">ByteBuffer</span>.allocate(<span class="number">2</span> <span class="comment">/* version */</span> + value.sizeOf)</span><br><span class="line">    byteBuffer.putShort(version)</span><br><span class="line">    value.writeTo(byteBuffer)</span><br><span class="line">    byteBuffer.array()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>随后会组装成消息体，通过appendForGroup方法写入到位移主题中。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// build records</span></span><br><span class="line"><span class="keyword">val</span> records = &#123;</span><br><span class="line">          <span class="keyword">val</span> buffer = <span class="type">ByteBuffer</span>.allocate(<span class="type">AbstractRecords</span>.estimateSizeInBytes(magicValue, compressionType,</span><br><span class="line">            <span class="type">Seq</span>(<span class="keyword">new</span> <span class="type">SimpleRecord</span>(timestamp, key, value)).asJava))</span><br><span class="line">          <span class="keyword">val</span> builder = <span class="type">MemoryRecords</span>.builder(buffer, magicValue, compressionType, timestampType, <span class="number">0</span>L)</span><br><span class="line">          builder.append(timestamp, key, value)</span><br><span class="line">          builder.build()</span><br></pre></td></tr></table></figure><p>注册消息体主体结构为：&lt;消费者组名称 group.groupId , 消费者组主要的元数据信息 groupMetadata / 消费订阅信息 metadata / 分配方案信息 memberAssignment&gt;。</p><p><strong>位移消息</strong></p><p>构造位移消息的key</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 参数是version和GroupTopicPartition</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">OffsetKey</span>(<span class="params">version: <span class="type">Short</span>, key: <span class="type">GroupTopicPartition</span></span>) <span class="keyword">extends</span> <span class="title">BaseKey</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">toString</span></span>: <span class="type">String</span> = key.toString</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// GroupTopicPartition 类型是 &lt;消费者组名，主题，分区&gt; 的三元组。</span></span><br><span class="line"><span class="type">OffsetKey</span>(version, <span class="type">GroupTopicPartition</span>(group, <span class="keyword">new</span> <span class="type">TopicPartition</span>(topic, partition)))</span><br></pre></td></tr></table></figure><p>位移消息的value，在offsetCommitValue 方法决定了 value 中都有哪些元素。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> offsetAndMetadata = <span class="type">GroupMetadataManager</span>.readOffsetMessageValue(record.value)</span><br><span class="line">...</span><br><span class="line"><span class="keyword">private</span>[group] <span class="function"><span class="keyword">def</span> <span class="title">offsetCommitValue</span></span>(offsetAndMetadata: <span class="type">OffsetAndMetadata</span>,</span><br><span class="line">                                       apiVersion: <span class="type">ApiVersion</span>): <span class="type">Array</span>[<span class="type">Byte</span>] = &#123;</span><br><span class="line">  <span class="comment">// 根据不同的消息格式版本，创建对应的对象</span></span><br><span class="line">    <span class="keyword">val</span> (version, value) = &#123;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">if</span> (apiVersion &lt; <span class="type">KAFKA_2_1_IV0</span> || offsetAndMetadata.expireTimestamp.nonEmpty) &#123;</span><br><span class="line">...</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (apiVersion &lt; <span class="type">KAFKA_2_1_IV1</span>) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 依次写入位移值、Leader Epoch值、自定义元数据以及时间戳</span></span><br><span class="line">        <span class="keyword">val</span> value = <span class="keyword">new</span> <span class="type">Struct</span>(<span class="type">OFFSET_COMMIT_VALUE_SCHEMA_V3</span>)</span><br><span class="line">        value.set(<span class="type">OFFSET_VALUE_OFFSET_FIELD_V3</span>, offsetAndMetadata.offset)</span><br><span class="line">        value.set(<span class="type">OFFSET_VALUE_LEADER_EPOCH_FIELD_V3</span>,</span><br><span class="line">          offsetAndMetadata.leaderEpoch.orElse(<span class="type">RecordBatch</span>.<span class="type">NO_PARTITION_LEADER_EPOCH</span>))</span><br><span class="line">        value.set(<span class="type">OFFSET_VALUE_METADATA_FIELD_V3</span>, offsetAndMetadata.metadata)</span><br><span class="line">        value.set(<span class="type">OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3</span>, offsetAndMetadata.commitTimestamp)</span><br><span class="line">        (<span class="number">3</span>, value)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 构建ByteBuffer，写入消息格式版本和结构体并返回</span></span><br><span class="line">    <span class="keyword">val</span> byteBuffer = <span class="type">ByteBuffer</span>.allocate(<span class="number">2</span> <span class="comment">/* version */</span> + value.sizeOf)</span><br><span class="line">    byteBuffer.putShort(version.toShort)</span><br><span class="line">    value.writeTo(byteBuffer)</span><br><span class="line">    byteBuffer.array()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>随后也会组装消息体SimpleRecord，通过MemoryRecords.builder后，由appendForGroup方法发送。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> records = filteredOffsetMetadata.map &#123; <span class="keyword">case</span> (topicPartition, offsetAndMetadata) =&gt;</span><br><span class="line">            <span class="keyword">val</span> key = <span class="type">GroupMetadataManager</span>.offsetCommitKey(group.groupId, topicPartition)</span><br><span class="line">            <span class="keyword">val</span> value = <span class="type">GroupMetadataManager</span>.offsetCommitValue(offsetAndMetadata, interBrokerProtocolVersion)</span><br><span class="line">            <span class="keyword">new</span> <span class="type">SimpleRecord</span>(timestamp, key, value)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// build MemoryRecords</span></span><br><span class="line"><span class="keyword">val</span> builder = <span class="type">MemoryRecords</span>.builder(buffer, magicValue, compressionType, timestampType, <span class="number">0</span>L, time.milliseconds(),</span><br><span class="line">            producerId, producerEpoch, <span class="number">0</span>, isTxnOffsetCommit, <span class="type">RecordBatch</span>.<span class="type">NO_PARTITION_LEADER_EPOCH</span>)</span><br><span class="line"><span class="comment">// 可能会有多个record，遍历append build</span></span><br><span class="line">records.foreach(builder.append)</span><br><span class="line"></span><br><span class="line"><span class="comment">// entries终将会传入appendForGroup方法</span></span><br><span class="line"><span class="keyword">val</span> entries = <span class="type">Map</span>(offsetTopicPartition -&gt; builder.build())</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>位移消息的主体格式是：&lt; version / &lt;消费者组名，主题，分区&gt; , 位移值 / Leader Epoch值 / 元数据信息 / 时间戳&gt;。</p><p><strong>Tombstone消息</strong></p><p>翻译过来就是墓碑消息，Tombstone消息的Value 为 null。Tombstone消息在注册消息和位移消息中都可能出现。如果在注册消息中出现，表示Kafka可以将该消费者组元数据从位移主题中删除；如果在位移消息中出现了，则表示Kafka能够将该消费者组在某主题分区上的位移提交数据删除。这很好的保证了，内部位移主题不会持续增加磁盘占用空间。</p><h4 id="Checkpoint文件"><a href="#Checkpoint文件" class="headerlink" title="Checkpoint文件"></a>Checkpoint文件</h4><p>Log-start-offset-checkpoint文件是用来标识LogStartOffset（日志的起始偏移量），recovery-point-offset-checkpoint和replication-offset-checkpoint这两个文件分别对应了Log End Offset（日志末端位移）和High Watermark（副本的高水印值）。</p><p>会有定时任务负责将所有分区的LogStartOffset，LEO，HW写到以上文件中，定时周期由broker端参数<code>log.flush.start.offset.checkpoint.interval.ms</code>，<code>log.flush.offset. checkpoint.interval.ms</code>，<code>replica.high.watermark.checkpoint.interval.ms</code>决定。</p><p>对应的机制是为了解决数据丢失或数据不一致的问题，在Kafka中还需要结合<code>Leader Epoch</code>来共同解决，日后可详细再言。</p><h4 id="消息日志"><a href="#消息日志" class="headerlink" title="消息日志"></a>消息日志</h4><p>消息存储的目录格式默认为：topic-partition_num；展示的Topic为test1（一个分区）和test2（两个分区）：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">├── test1-0</span><br><span class="line">├── test2-0</span><br><span class="line">└── test2-1</span><br><span class="line">    ├── 00000000000000000000.index</span><br><span class="line">    ├── 00000000000000000000.log</span><br><span class="line">    ├── 00000000000000000000.timeindex</span><br><span class="line">    ├── 00000000000000000013.index</span><br><span class="line">    ├── 00000000000000000013.log</span><br><span class="line">    ├── 00000000000000000013.timeindex</span><br><span class="line">    └── leader-epoch-checkpoint</span><br></pre></td></tr></table></figure><p>文章在开篇谈到，一个分区对应一个日志(Log)，为了防止日志过大，引入了日志分段(LogSegment）概念，切分成多个较小文件；Log在物理上是以文件夹的形式存储，而每个LogSegment对应着磁盘上的日志文件：以”.log”为文件后缀，和两个索引文件：偏移量的索引文件（以”.index”为文件后缀）和时间戳的索引文件（以”.timeindex”为文件后缀），而<code>leader-epoch-checkpoint</code>保存的是Leader Epoch的值（解决副本数据一致性需要）。</p><p><strong>LogSegment</strong></p><p>LogSegment的大小取决于broker端的<code>log.segment.bytes</code>参数决定，我们先看看LogSegment的构造参数：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * log Kafka消息对象</span></span><br><span class="line"><span class="comment"> * lazyOffsetIndex 位移索引文件</span></span><br><span class="line"><span class="comment"> * lazyTimeIndex 时间戳索引文件</span></span><br><span class="line"><span class="comment"> * txnIndex 已中止事务索引文件</span></span><br><span class="line"><span class="comment"> * baseOffset 每个日志段对象的起始位移</span></span><br><span class="line"><span class="comment"> * indexIntervalBytes 日志对象新增索引项的频率</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogSegment</span> <span class="title">private</span>[log] (<span class="params">val log: <span class="type">FileRecords</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyOffsetIndex: <span class="type">LazyOffsetIndex</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyTimeIndex: <span class="type">LazyTimeIndex</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val txnIndex: <span class="type">TransactionIndex</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val baseOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val indexIntervalBytes: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val rollJitterMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val time: <span class="type">Time</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">...</span></span><br><span class="line"><span class="class"><span class="comment">/**</span></span></span><br><span class="line"><span class="class"><span class="comment"> * largestOffset  待写入消息批次中消息的最大位移值</span></span></span><br><span class="line"><span class="class"><span class="comment"> * largestTimestamp 最大时间戳</span></span></span><br><span class="line"><span class="class"><span class="comment"> * shallowOffsetOfMaxTimestamp 最大时间戳对应消息的位移</span></span></span><br><span class="line"><span class="class"><span class="comment"> * records 待写入的消息体</span></span></span><br><span class="line"><span class="class"><span class="comment"> */</span></span></span><br><span class="line"><span class="class"><span class="title">def</span> <span class="title">append</span>(<span class="params">largestOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">             largestTimestamp: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">             shallowOffsetOfMaxTimestamp: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">             records: <span class="type">MemoryRecords</span></span>)</span>: <span class="type">Unit</span> = &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * startOffset 要读取的第一条消息的位移</span></span><br><span class="line"><span class="comment"> * maxSize 能读取的最大字节数</span></span><br><span class="line"><span class="comment"> * maxPosition 能读到的最大文件位置</span></span><br><span class="line"><span class="comment"> * minOneMessage 是否允许在消息体过大时至少返回第一条消息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(startOffset: </span><br><span class="line">         <span class="type">Long</span>, maxOffset: <span class="type">Option</span>[<span class="type">Long</span>], </span><br><span class="line">         maxSize: <span class="type">Int</span>, </span><br><span class="line">         maxPosition: <span class="type">Long</span> = size,</span><br><span class="line">         minOneMessage: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">FetchDataInfo</span> = &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * leaderEpochCache 在恢复过程中缓存的leaderEpoch值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recover</span></span>(producerStateManager: <span class="type">ProducerStateManager</span>, </span><br><span class="line">            leaderEpochCache: <span class="type">Option</span>[<span class="type">LeaderEpochFileCache</span>] = <span class="type">None</span>): <span class="type">Int</span> = &#123;...&#125;</span><br></pre></td></tr></table></figure><p>通过几项参数，大概可以猜测出这样构造LogSegment的意义。每个segment保存的是消息实体，FileRecords是必不可少，通过位移索引和时间戳索引可以快速定位到该segment的消息。在LogSegment类中，需要读写消息（append和read）；需要恢复日志段（recover），broker启动时需要从磁盘文件中加载所有的日志段信息到内存中等功能的实现。</p><p>可以通过Kafka client命令来查看消息存储的详细内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-run-class.sh kafka.tools.DumpLogSegments \ </span><br><span class="line">--files /tmp/kafka-logs/test2-1/00000000000000000000.log \</span><br><span class="line">--print-data-log </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">| offset: 342 CreateTime: 1615706871552 keysize: -1 valuesize: 50 sequence: -1 headerKeys: [] payload: &#123;<span class="string">&quot;type&quot;</span>:<span class="string">&quot;bootstrap-insert&quot;</span>,<span class="string">&quot;is_valid&quot;</span>:0,<span class="string">&quot;version&quot;</span>:4,<span class="string">&quot;ts&quot;</span>:1613980836,<span class="string">&quot;create_time&quot;</span>:<span class="string">&quot;2020-05-04 07:41:29&quot;</span>,<span class="string">&quot;update_time&quot;</span>:<span class="string">&quot;2020-07-04 12:40:15&quot;</span>&#125;</span><br></pre></td></tr></table></figure><p>根据位移值，我们可以通过.index文件快速查找消息所在文件位置；根据时间戳，我们可以通过.timeindex查找；所以快速的查找的根本原因，是基于消息存储格式和机制来决定的。</p><p><strong>Message</strong></p><p>接下来继续看下消息Message内部结构，也就是LogSegment构造类中的FileRecords参数是怎么样的格式。</p><p>前面有追踪过位移主题内的消息体的定义，都是采用的map格式，这是便于快速取得位移值；但是真正的消息实体和位移主题的消息格式还是有很大的不同，要考虑消息的完整性、元数据信息的表示、消息属性等等，另外我们只是讨论<strong>消息未压缩</strong>的情景。</p><p>Kafka的消息结构在设计时，有过几次设计变化：在Kafka 0.10.0版本之前都是采用的是无timestamp字段（v0版本），在其之后的版本添加了timestamp字段，表示消息的时间戳（v1版本）。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">v0</span><br><span class="line"><span class="type">Message</span> =&gt; <span class="type">Crc</span> <span class="type">MagicByte</span> <span class="type">Attributes</span> <span class="type">Key</span> <span class="type">Value</span></span><br><span class="line">  <span class="type">Crc</span> =&gt; int32</span><br><span class="line">  <span class="type">MagicByte</span> =&gt; int8</span><br><span class="line">  <span class="type">Attributes</span> =&gt; int8</span><br><span class="line">  <span class="type">Key</span> =&gt; bytes</span><br><span class="line">  <span class="type">Value</span> =&gt; bytes</span><br><span class="line">  </span><br><span class="line">v1 (supported since <span class="number">0.10</span><span class="number">.0</span>)</span><br><span class="line"><span class="type">Message</span> =&gt; <span class="type">Crc</span> <span class="type">MagicByte</span> <span class="type">Attributes</span> <span class="type">Key</span> <span class="type">Value</span></span><br><span class="line"><span class="comment">// CRC用于检查代理和消息的完整</span></span><br><span class="line">  <span class="type">Crc</span> =&gt; int32</span><br><span class="line"><span class="comment">// 版本id，用于允许消息二进制格式的向后兼容演变。当前值为1。</span></span><br><span class="line">  <span class="type">MagicByte</span> =&gt; int8</span><br><span class="line"><span class="comment">// 保存有关消息的元数据属性</span></span><br><span class="line"><span class="comment">// 最低3位包含用于消息的压缩解码器</span></span><br><span class="line"><span class="comment">// 最低的第4位用于表示时间戳类型，0代表createtime,1代表logappendtime。</span></span><br><span class="line">  <span class="type">Attributes</span> =&gt; int8</span><br><span class="line"><span class="comment">// 消息时间戳</span></span><br><span class="line">  <span class="type">Timestamp</span> =&gt; int64</span><br><span class="line"><span class="comment">// 分区分配的可选消息密钥</span></span><br><span class="line">  <span class="type">Key</span> =&gt; bytes</span><br><span class="line"><span class="comment">// 实际消息内容，可能是包含的一个消息集。</span></span><br><span class="line">  <span class="type">Value</span> =&gt; bytes</span><br></pre></td></tr></table></figure><p>实现类是message类：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Message</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// crc 消息的校验码，防止消息错误（4B）</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">CrcOffset</span> = <span class="number">0</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">CrcLength</span> = <span class="number">4</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// magic 消息格式的版本号（1B）</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">MagicOffset</span> = <span class="type">CrcOffset</span> + <span class="type">CrcLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">MagicLength</span> = <span class="number">1</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// attributes 消息的属性，比如压缩类型，时间戳类型，创建时间/追加时间 (1B)</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">AttributesOffset</span> = <span class="type">MagicOffset</span> + <span class="type">MagicLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">AttributesLength</span> = <span class="number">1</span></span><br><span class="line">  <span class="comment">// timestamp 时间戳信息(8B)</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">TimestampOffset</span> = <span class="type">AttributesOffset</span> + <span class="type">AttributesLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">TimestampLength</span> = <span class="number">8</span></span><br><span class="line">  <span class="comment">// key （4B）</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeySizeOffset_V0</span> = <span class="type">AttributesOffset</span> + <span class="type">AttributesLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeySizeOffset_V1</span> = <span class="type">TimestampOffset</span> + <span class="type">TimestampLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeySizeLength</span> = <span class="number">4</span> </span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeyOffset_V0</span> = <span class="type">KeySizeOffset_V0</span> + <span class="type">KeySizeLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeyOffset_V1</span> = <span class="type">KeySizeOffset_V1</span> + <span class="type">KeySizeLength</span></span><br><span class="line">  <span class="comment">// value （4B）</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">ValueSizeLength</span> = <span class="number">4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>发送一条key=”key”，value=”value”的消息，在v1版本中最小则会占用22+8+12=42B。</p><p>在kafka0.11.0版本后，改动是比较大的，在以前的版本，value是一个消息集（Message Set），而在v2版本中，直接把Crc检查校验，attributes的元数据属性等信息提入了Record Batch属性中，还参考了Protocol Buffer引入了变长整型（Varints）和ZigZag编码大大减少消息体大小。</p><p>v2版本Record Batch格式：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 表示当前RecordBatch的起始位移 (8B)</span></span><br><span class="line">baseOffset: int64 </span><br><span class="line"><span class="comment">// 计算partition leader epoch到headers之间的长度 (4B)</span></span><br><span class="line">batchLength: int32</span><br><span class="line"><span class="comment">// 用来确保数据可靠性 4B</span></span><br><span class="line">partitionLeaderEpoch: int32</span><br><span class="line"><span class="comment">// magic等于2 (1B)</span></span><br><span class="line">magic: int8 (current magic value is <span class="number">2</span>)</span><br><span class="line"><span class="comment">// 4B</span></span><br><span class="line">crc: int32</span><br><span class="line"><span class="comment">// 2B</span></span><br><span class="line">attributes: int16</span><br><span class="line">bit <span class="number">0</span>~<span class="number">2</span>:</span><br><span class="line"><span class="number">0</span>: no compression</span><br><span class="line"><span class="number">1</span>: gzip</span><br><span class="line"><span class="number">2</span>: snappy</span><br><span class="line"><span class="number">3</span>: lz4</span><br><span class="line">bit <span class="number">3</span>: timestampType</span><br><span class="line">bit <span class="number">4</span>: isTransactional (<span class="number">0</span> means not transactional)</span><br><span class="line">bit <span class="number">5</span>: isControlBatch (<span class="number">0</span> means not a control batch)</span><br><span class="line">bit <span class="number">6</span>~<span class="number">15</span>: unused</span><br><span class="line"><span class="comment">// 4B</span></span><br><span class="line">lastOffsetDelta: int32</span><br><span class="line"><span class="comment">// 8B</span></span><br><span class="line">firstTimestamp: int64</span><br><span class="line">maxTimestamp: int64</span><br><span class="line">producerId: int64</span><br><span class="line">producerEpoch: int16</span><br><span class="line">baseSequence: int32</span><br><span class="line"><span class="comment">// batch records</span></span><br><span class="line">records: [<span class="type">Record</span>]</span><br></pre></td></tr></table></figure><p>v2版本Record格式：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 消息总长度 3B</span></span><br><span class="line">length: varint</span><br><span class="line"><span class="comment">// 弃用</span></span><br><span class="line">attributes: int8</span><br><span class="line">bit <span class="number">0</span>~<span class="number">7</span>: unused</span><br><span class="line"><span class="comment">// 时间戳增量 3B</span></span><br><span class="line">timestampDelta: varint</span><br><span class="line"><span class="comment">// 位移增量 3B</span></span><br><span class="line">offsetDelta: varint</span><br><span class="line"><span class="comment">// key</span></span><br><span class="line">keyLength: varint</span><br><span class="line">key: byte[]</span><br><span class="line"><span class="comment">// value</span></span><br><span class="line">valueLen: varint</span><br><span class="line">value: byte[]</span><br><span class="line"><span class="type">Headers</span> =&gt; [<span class="type">Header</span>]</span><br></pre></td></tr></table></figure><p>v2版本格式中增加了length（消息总长度）、timestamp delta（时间戳增量）、offset delta（位移增量）和headers信息：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">headerKeyLength: varint</span><br><span class="line">headerKey: <span class="type">String</span></span><br><span class="line">headerValueLength: varint</span><br><span class="line"><span class="type">Value</span>: byte[]</span><br></pre></td></tr></table></figure><p>根据Varints的规则可以推导出0-63之间的数字占1个字节，64-8191之间的数字占2个字节，8192-1048575之间的数字占3个字节；而kafka broker的配置message.max.bytes的默认大小为1000012（Varints编码占3个字节）。</p><p>所以发送一条key=”key”，value=”value”的消息，在v2版本中最小则会占9+3+3=15B。在v0和v1版本的消息格式中，如果消息本身没有key，那么key length字段为-1，int类型的需要4个字节来保存，而v2版本的消息格式中与长度有关的字段都是采用Varints的编码，只需要一个字节，这也会节省很多空间大小。</p><hr><p>Kafka日志消息存储结构是比较复杂的，底层结构决定着上层功能。从消息结构中，也可以窥得一丝kafka设计的原理和实现的机制。在消息体结构介绍中，对引用的变长整型（Varints）和ZigZag编码了解的较少，所以讲述的不是很详细，不过也需要适可而止的深究技术的深度。</p><p>完。</p><p><strong>Refer</strong></p><p>[1] <a href="https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-Messagesets">A Guide To The Kafka Protocol</a></p><p>[2] <a href="https://kafka.apache.org/10/documentation.html#semantics">kafka deign documentation</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们知道，写入kafka的消息都需要指定一个Topic（主题），Kafka可以根据Topic来对消息进行区分，每个Topic分为多个Partition（分区）。&lt;/p&gt;
&lt;p&gt;Partition的概念是为了实现高伸缩性和提供负载均衡的作用，可以很好的让一个比较大的（数据量级）Topic中的消息可以分布到多台broker机器上。不仅如此，也可以提高并行能力，因为水平扩展后可以以Partition为粒度进行读写，这样每个broker节点都能独立执行各自分区的读写请求；&lt;/p&gt;
&lt;p&gt;Partition下就是Log的消息体，每条消息都只会保存在某一个分区中，而且在每个Partition下消息都是append模式写入的，也就是说，每个Partition下的消息都是顺序性的。&lt;/p&gt;
&lt;p&gt;Kafka消息设计方式就是这样的三层结构：主题-分区-消息；说到设计，不同的分布式系统对分区的叫法也不大一样，在Kafka中的概念是Partition（分区），在ES中叫做Shard（分片），而在HBase中被称为Region。从表面上来看实现原理可能不尽相同，但对底层实现的思想却都是一致的。&lt;/p&gt;
&lt;p&gt;话题扯回来，今天这篇文章分享的主题是：Kafka消息格式。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Kafka" scheme="https://pross.space/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka无消息丢失配置</title>
    <link href="https://pross.space/blog/2021/01/30/kafka-no-message-loss-configuration.html"/>
    <id>https://pross.space/blog/2021/01/30/kafka-no-message-loss-configuration.html</id>
    <published>2021-01-30T07:13:16.000Z</published>
    <updated>2021-03-15T04:35:58.537Z</updated>
    
    <content type="html"><![CDATA[<p>今天这篇文章分享的主题是：Kafka无消息丢失配置，以及分析一些常见的消息丢失案例。</p><p>在这之前，我们需要清楚，Kafka丢失消息的几种场景。比如：producer生产者把消息写入topic中，broker端并没有接收到，消息在去的路上丢失了；broker端接收到了消息，但是consumer并没有消费到这条数据，消息在broker端丢失了；broker端接收到了消息，但是consumer消费者并没有消费到，消息在来的路上丢失了。</p><p>这几种场景其实就是Kafka架构决定的。</p><a id="more"></a><p><img src="./kafka-no-message-loss-configuration/kafka-design.png" alt="kafka-design"></p><p>其次，我们也需要清楚，Kafka在什么情况下能保证消息不丢失。用胡夕老师的话总结：<strong>Kafka只对”已提交”的消息（commited message），做有限度的持久化保证</strong>。</p><p>“已提交”是表示，当Kafka的broker成功接收到了某条消息，写入到日志文件中，并且告诉producer生产者这条消息已经成功提交后，这条消息才算已提交。”有限度的持久化保证”意思是，Kafka不可能保证任何情况下做到不丢数据，比如，broker服务器全炸毁了，这种情况不可能做到不丢数据，但是如果消息保存在N个broker中，那么N个broker只要有一个存活，就可以保证消息不丢失。</p><p>所以理解了不丢失含义和丢失的场景后，我们分析下常见消息丢失的场景。</p><h4 id="Producer生产者丢失数据"><a href="#Producer生产者丢失数据" class="headerlink" title="Producer生产者丢失数据"></a>Producer生产者丢失数据</h4><p>生产者丢失数据也是比较常见的场景，大多数是因为producer发送消息时API使用不合理造成的。Kafka producer默认是异步发送消息，大概流程是：初始化producer实例，创建sender现成负责发送消息-&gt;将消息暂存在缓冲区，消息根据topic-partition分类缓存-&gt;消息数量达到batch.size或时间达到linger.ms，sender线程将消息发送到topic-partition所在的broker。</p><p>因为是默认异步发送，也就是说如果调用的是producer.send(msg)，通常会立即返回，但是并不代表消息已经发送成功，只能代表消息暂存在了缓冲区。如果网络抖动（producer没有发送消息）、消息本身不合格（broker端拒绝接收）等都能导致消息丢失。</p><p>那么正常的做法是使用producer.send(msg,callback)，使用<code>callback回调</code>，能够告诉开发者消息是否真的提交成功，如果提交失败，也可以针对性处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 发送消息</span></span><br><span class="line">producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, message), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span>(e != <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="comment">// do something for send msg exception</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>使用带有回调的API能够解决producer发送的问题，但如果是broker的问题，导致消息发送不过去，那么就需要去调整broker端参数；当然，Kafka也可以同步发送消息，但是性能会很差。</p><blockquote><p>batch.size是producer端参数，默认值是16KB，表示producer端凑够16KB的数据才会发送；linger.ms表示一个batch被创建之后，最多过多久，不管这个Batch有没有写满，都必须发送出去。</p><p>这两个参数结合使用，可避免一个batch迟迟无法达到size大小，导致消息一直积压在内存里发送不出去的情况。</p></blockquote><h4 id="Broker端丢失数据"><a href="#Broker端丢失数据" class="headerlink" title="Broker端丢失数据"></a>Broker端丢失数据</h4><p>如果配置参数合理，broker端丢失数据概率是比较小的。比如：</p><p>设置unclean.leader.election.enable = false，这个参数控制的是哪些 Broker 有资格竞选分区的 Leader，如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。</p><p>设置 replication.factor &gt;= 3，Kafka副本策略参数，最好将消息多保存几份，毕竟Broker端防止消息丢失的主要机制就是冗余副本。</p><p>设置 min.insync.replicas &gt; 1，这个参数控制的是消息至少要被写入到多少个副本才算是“已提交”，设置成大于 1 可以提升消息持久性。对应这个参数含义的还有acks = all，acks参数是producer端的参数，表示对”已提交”消息的定义；如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是”已提交”。</p><p>设置 replication.factor &gt; min.insync.replicas，如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。</p><p>除了以上这些，还有很多参数可以去参考和调整。</p><h4 id="Consumer消费者丢失数据"><a href="#Consumer消费者丢失数据" class="headerlink" title="Consumer消费者丢失数据"></a>Consumer消费者丢失数据</h4><p>consumer是采用pull 模式从 broker 中读取数据，pull模式读取数据的好处是，消费速度可以由自己控制，但是另一方面会涉及到，需要记录每个consumer消费者pull数据的位置，这个位置用offset来记录；所以消费者丢失消息的情形比较简单，如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失。offset位移表示的是这个consumer当前消费到的topic分区的位置。</p><p><img src="./kafka-no-message-loss-configuration/kafka-offset.png" alt="kafka-offset"></p><p>如果设置为自动提交位移（enable.auto.commit=true），Kafka 会保证在开始调用 poll 方法时，提交上次 poll 返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此能保证不出现消费丢失的情况，但存在一个问题是，消息可能会从重复消费。</p><p>默认情况下，Consumer 每 5 秒自动提交一次位移。我们假设提交位移之后的 3 秒发生了 <code>Rebalance</code> 操作。在 Rebalance 之后，所有 Consumer 从上一次提交的位移处继续消费，但该位移已经是 3 秒前的位移数据了，故在 Rebalance 发生前 3 秒消费的所有数据都要重新再消费一次。虽然能够通过减小自动提交位移的间隔时间（auto.commit.interval.ms）的值来提高提交频率，但这么做只能缩小重复消费的时间窗口，不可能完全消除它。</p><p>还有一种情况是，消费者消费了10条消息，还没有处理完，offset已经提交了；offset提交后消费者程序有问题，需要修复重启，但是消费的消息并没有处理完；那么重启后重新去消费时，会接着上次消费位移接着消费，那么没处理完的10条消息就会丢失。</p><p>所有的异常因素都需要被考虑到，才能让提高程序的鲁棒性，所以正确使用位移的方式是：<strong>维持先消费消息，在更新位移的顺序，尽量关闭自动提交</strong>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 配置消费者客户端参数</span></span><br><span class="line">Properties properties=<span class="keyword">new</span> Properties();</span><br><span class="line">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, Boolean.FALSE);</span><br><span class="line">...</span><br><span class="line"><span class="comment">// 定义状态</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> AtomicBoolean isRunning=<span class="keyword">new</span> AtomicBoolean(<span class="keyword">true</span>);</span><br><span class="line"><span class="comment">//创建相应的消费者实例</span></span><br><span class="line">KafkaConsumer&lt;String,String&gt; consumer=<span class="keyword">new</span> KafkaConsumer&lt;&gt;(properties);</span><br><span class="line"><span class="comment">//订阅主题</span></span><br><span class="line">consumer.subscribe(Arrays.asList(topic));</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">//拉取消息并消费</span></span><br><span class="line"><span class="keyword">while</span>(isRunning.get())&#123;</span><br><span class="line">ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line"><span class="comment">// do something</span></span><br><span class="line">process(records);</span><br><span class="line"><span class="comment">// 手动异步提交offset，规避阻塞</span></span><br><span class="line">consumer.commitAsync();</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line"><span class="comment">// 处理异常</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;<span class="keyword">finally</span> &#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">// 同步阻塞式提交offset</span></span><br><span class="line">consumer.commitSync();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">consumer.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码中offset进行了两次提交，分别是 <code>commitAsync</code> 和 <code>commitSync</code>。commitAsync的问题在于，如果提交过程中出现问题时，不会自动重试，因为它是异步操作；如果异步提交设计成，提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了，也没有实际意义。</p><p>所以在finally代码块里，我们可以用commitSync提交，通过自动重试，来规避一些网络抖动，broker端瞬时状态导致不可用的问题（比如broker端GC）等。</p><p>完。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天这篇文章分享的主题是：Kafka无消息丢失配置，以及分析一些常见的消息丢失案例。&lt;/p&gt;
&lt;p&gt;在这之前，我们需要清楚，Kafka丢失消息的几种场景。比如：producer生产者把消息写入topic中，broker端并没有接收到，消息在去的路上丢失了；broker端接收到了消息，但是consumer并没有消费到这条数据，消息在broker端丢失了；broker端接收到了消息，但是consumer消费者并没有消费到，消息在来的路上丢失了。&lt;/p&gt;
&lt;p&gt;这几种场景其实就是Kafka架构决定的。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Kafka" scheme="https://pross.space/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka为什么快</title>
    <link href="https://pross.space/blog/2021/01/17/why-is-kafka-fast.html"/>
    <id>https://pross.space/blog/2021/01/17/why-is-kafka-fast.html</id>
    <published>2021-01-17T10:35:08.000Z</published>
    <updated>2021-01-30T08:25:55.582Z</updated>
    
    <content type="html"><![CDATA[<p>今天这篇文章分享的主题是：Kafka为什么速度这么快？</p><p>快是基于比较得出来的，相对与其它消息队列或消息引擎，在很多讲解Kafka的文章都会提到这一点：<code>Kafka可以很轻松的支持每秒百万级的TPS请求</code>，其实在实际的基准测试中，每秒写入速率高达两百万，这远远高于其它消息队列的测试数据，Kafka在大数据消息队列组件中也是不二之选，并且绝大多数的大数据计算组件都与kafka进行集成。</p><p>但实际生产中的性能数据会受很多参数和环境的影响，比如acks设置：在保证数据不丢失的情况下，设置acks=all，吞吐量会明显降低；replication副本数量：副本数越多，吞吐量越低；batch大小：batch-size大小达到阈值时，会达到吞吐量峰值，超过阈值后，并不会提升性能；和压缩设置等等因素都可以影响Kafka吞吐量。</p><p>我们知道，Kafka的消息是保存或缓存在磁盘上的，一般认为在磁盘上读写是相对而言是较慢的，因为磁盘寻址是相对需要消耗大量的时间，那为什么Kafka速度还是这么快？我们得从<code>Kafka写入为什么这么快</code>和<code>Kafka消费为什么这么快</code>两方面，深入解析下Kafka主要的技术原理。</p><a id="more"></a><h4 id="Kafka为什么写入这么快"><a href="#Kafka为什么写入这么快" class="headerlink" title="Kafka为什么写入这么快"></a>Kafka为什么写入这么快</h4><p>前面已经提到过，Kafka会把消息保存在磁盘中，可以设置副本，保障Kafka消息的高可用性；基于当前不可改变的技术方案事实，为了优化写入，Kafka采取了两项措施：避免随机访问磁盘和使用MMAP技术。</p><h5 id="避免随机访问磁盘"><a href="#避免随机访问磁盘" class="headerlink" title="避免随机访问磁盘"></a>避免随机访问磁盘</h5><p>我们先来看这张图，出自<a href="!https://queue.acm.org/detail.cfm?id=1563874">ACM Queue - The Pathologies of Big Data</a>一文中的数据：</p><p><img src="./why-is-kafka-fast/comparison-between-disk-and-memory.jpg" alt="comparison"></p><p>采用顺序写入磁盘比随机写入磁盘的速率要快上不少，甚至比随机写入内存和SSD都略胜一筹，但这种方法有一个缺陷是没办法删除数据，所以Kafka会把所有的数据都保留下来，每个消费者对每个Topic都有可以用一个offset（偏移量）来表示读取到了第几条数据。</p><p>当然，顺序写入确实保证了一定的写入性能，但绝不是唯一的因素。</p><h5 id="MMAP技术"><a href="#MMAP技术" class="headerlink" title="MMAP技术"></a>MMAP技术</h5><p>如果采用传统系统调用open()、read()和write()的方式来顺序读磁盘文件，那么每个文件的读写都需要调用系统资源和磁盘访问，磁盘的访问速度还是不可能追得上内存，如果我们将文件的I/O作为常规内存访问，充分利用现代操作系统分页存储来利用内存提高I/O效率，这会变得更加高效；所以Kafka的数据并不是实时的写入磁盘，中间会有一个过程，让虚拟内存和文件进行逻辑关联，这就是MMAP技术，全称是Memory Mapped Files（内存映射）。</p><p>文件的内存映射是将每个磁盘块映射到一个或多个内存页面，实现文件磁盘地址和进程虚拟内存中的虚拟地址一一对应。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而不必在调用read()和write()等系统调用函数。</p><p><img src="./why-is-kafka-fast/mmap-file.jpeg" alt="mmap-file"></p><blockquote><p>磁盘块是计算机存储中的术语，硬盘的的读写是以扇区为基本单位，磁盘上的每个磁道被等份为若干个弧段，这些弧段被称为扇区。扇区是磁盘最小的物理存储单元，操作系统将相邻的扇区组合在一起，形成一个块，对块进行管理，磁盘块是磁盘操作的基本单位。</p></blockquote><p> 用代码来验证是否采用MMAP的顺序读写是否更加高效。</p><p>初始化时间对比：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//记录开始时间</span></span><br><span class="line"><span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line"><span class="comment">//通过RandomAccessFile的方式获取文件的Channel，我们用文件一般是随机读写</span></span><br><span class="line">RandomAccessFile randomAccessFile = <span class="keyword">new</span> RandomAccessFile(<span class="string">&quot;./data/f-data.txt&quot;</span>, <span class="string">&quot;rw&quot;</span>);</span><br><span class="line">FileChannel channel = randomAccessFile.getChannel();</span><br><span class="line">System.out.println(<span class="string">&quot;FileChannel初始化时间：&quot;</span> + (System.currentTimeMillis() - start) + <span class="string">&quot;ms&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//内存映射文件，模式是READ_WRITE，如果文件不存在，就会被创建</span></span><br><span class="line">MappedByteBuffer mappedByteBuffer1 = channel.map(FileChannel.MapMode.READ_WRITE, <span class="number">0</span>, <span class="number">128</span> * <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">MappedByteBuffer mappedByteBuffer2 = channel.map(FileChannel.MapMode.READ_WRITE, <span class="number">0</span>, <span class="number">128</span> * <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;MMAPFile初始化时间：&quot;</span> + (System.currentTimeMillis() - start) + <span class="string">&quot;ms&quot;</span>);</span><br></pre></td></tr></table></figure><p>顺序写时间对比：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 记录开始时间</span></span><br><span class="line">start = System.currentTimeMillis();</span><br><span class="line">testFileChannelSequentialRW(channel);</span><br><span class="line">System.out.println(<span class="string">&quot;FileChannel顺序读写时间：&quot;</span> + (System.currentTimeMillis() - start) + <span class="string">&quot;ms&quot;</span>);</span><br><span class="line"></span><br><span class="line">start = System.currentTimeMillis();</span><br><span class="line">testFileMMapSequentialRW(mappedByteBuffer1, mappedByteBuffer2);</span><br><span class="line">System.out.println(<span class="string">&quot;MMAPFile顺序读写时间：&quot;</span> + (System.currentTimeMillis() - start) + <span class="string">&quot;ms&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>testFileChannelSequentialRW class：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testFileChannelSequentialRW</span><span class="params">(FileChannel fileChannel)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">byte</span>[] bytes = <span class="string">&quot;测试字符串1测试字符串1测试字符串1测试字符串1测试字符串1&quot;</span>.getBytes();</span><br><span class="line">    <span class="keyword">byte</span>[] to = <span class="keyword">new</span> <span class="keyword">byte</span>[bytes.length];</span><br><span class="line">    <span class="comment">//分配直接内存，减少复制</span></span><br><span class="line">    ByteBuffer byteBuffer = ByteBuffer.allocateDirect(bytes.length);</span><br><span class="line">    <span class="comment">//顺序写入</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">        byteBuffer.put(bytes);</span><br><span class="line">        byteBuffer.flip();</span><br><span class="line">        fileChannel.write(byteBuffer);</span><br><span class="line">        byteBuffer.flip();</span><br><span class="line">    &#125;</span><br><span class="line">    fileChannel.position(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">//顺序读取</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">        fileChannel.read(byteBuffer);</span><br><span class="line">        byteBuffer.flip();</span><br><span class="line">        byteBuffer.get(to);</span><br><span class="line">        byteBuffer.flip();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>testFileMMapSequentialRW class：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testFileMMapSequentialRW</span><span class="params">(MappedByteBuffer mappedByteBuffer1, MappedByteBuffer mappedByteBuffer2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">byte</span>[] bytes = <span class="string">&quot;测试字符串2测试字符串2测试字符串2测试字符串2测试字符串2&quot;</span>.getBytes();</span><br><span class="line">        <span class="keyword">byte</span>[] to = <span class="keyword">new</span> <span class="keyword">byte</span>[bytes.length];</span><br><span class="line"></span><br><span class="line">        <span class="comment">//顺序写入</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">            mappedByteBuffer1.put(bytes);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//顺序读取</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">            mappedByteBuffer2.get(to);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>最终测试结果：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FileChannel初始化时间：6ms</span><br><span class="line">MMAPFile初始化时间：10ms</span><br><span class="line"></span><br><span class="line">FileChannel顺序读写时间：418ms</span><br><span class="line">MMAPFile顺序读写时间：16ms</span><br></pre></td></tr></table></figure><p>也可以对比随机读写的性能，完整代码可见<a href="https://github.com/prosscode/code-practice/blob/master/code-java/src/main/java/code/java/mmap/MMAPvsFile.java">Github-MMAPvsFile</a>。</p><p>使用MMAP内存映射文件的方式操作文件，更加快速，并且性能提升的相当明显，但也有一个明显的缺陷：数据写入不可靠。写到MMAP的数据并没有真正写到磁盘上，当操作系统会在程序主动调用Flush的时候才把数据真正写到磁盘上，所以针对这个缺陷，Kafka提供了<code>produce.type</code>参数来控制是不是主动Flush，这也是判断Producer是异步写入还是同步写入的关键参数。</p><h4 id="Kafka为什么读取这么快"><a href="#Kafka为什么读取这么快" class="headerlink" title="Kafka为什么读取这么快"></a>Kafka为什么读取这么快</h4><p>当然，MMAP技术不仅仅优化了写入性能，对读取文件也有显著提升。为了优化读取消费，Kafka也采取了两项关键措施：Zero Copy（零拷贝）和批量压缩。</p><h5 id="Zero-Copy（零拷贝）"><a href="#Zero-Copy（零拷贝）" class="headerlink" title="Zero Copy（零拷贝）"></a>Zero Copy（零拷贝）</h5><p>零拷贝技术大家都应该熟悉，聊到操作系统、文件操作和文件读写都会说到零拷贝。</p><p>以传统的read/write方式进行网络文件的传输的大致步骤如下：</p><p>调用read函数读取文件，文件数据被copy到内核缓存区-&gt;read函数返回，文件数据从内核缓冲区copy到用户缓冲区-&gt;write函数调用，将文件数据从用户缓冲区copy到内核与socket相关的缓冲区-&gt;数据从socket缓冲区copy到硬件（如网卡）缓冲区，write()系统调用返回。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Socket socket &#x3D; new Socket(Remote_HOST, Remote_PORT);</span><br><span class="line">InputStream inputStream &#x3D; new FileInputStream(Local_FILE_PATH);</span><br><span class="line">OutputStream outputStream &#x3D; new DataOutputStream(socket.getOutputStream());</span><br><span class="line"></span><br><span class="line">byte[] buffer &#x3D; new byte[4096];</span><br><span class="line">while (inputStream.read(buffer) &gt;&#x3D; 0) &#123;</span><br><span class="line">    outputStream.write(buffer);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">outputStream.close();</span><br><span class="line">socket.close();</span><br><span class="line">inputStream.close();</span><br></pre></td></tr></table></figure><blockquote><p>这里的内核和用户是Linux文件系统的概念，操作系统的主要功能是为管理硬件资源和为应用程序开发人员提供良好开发环境，但是计算机系统的各种硬件资源是有限的，为了保证每一个进程都能够安全的执行，处理器设置两种模式来区分：内核模式和用户模式。一些容易发生安全问题的操作，比如：I/O操作，修改基址寄存器内容等，都被限制在只有内核模式下才可以执行。</p></blockquote><p>这个过程中，文件数据实际上经过了四次copy操作（2次CPU拷贝，2次DMA拷贝）：读取磁盘文件-&gt;内核空间-&gt;用户空间-&gt;socket缓存区-&gt;系统调用返回。</p><p><img src="./why-is-kafka-fast/copy-line.jpg" alt="copy-line"></p><p>通过流程图，可以看出其实第二次和第三次拷贝（内核空间和用户空间来回互换）是没有意义的，数据应该可以直接从内核缓冲区直接送入Socket缓冲区中，这就是零拷贝实现的机制。不过零拷贝是需要操作系统来支持，不同的OS之间有不同的实现方法。在Linux中，是基于<code>sendfile()</code>的方式实现。</p><p>由此，流程就变的简单许多：</p><p>sendfile系统调用，文件数据被copy到内核缓冲区-&gt;从内核缓冲区copy至内核socket相关的缓冲区-&gt;最后在socket相关的缓冲区copy到硬件缓冲区。</p><h5 id="批量压缩"><a href="#批量压缩" class="headerlink" title="批量压缩"></a>批量压缩</h5><p>在大多数的情况下，系统服务的瓶颈不是CPU或磁盘，而是网络I/O；通过网络传输文件，发送消息接受响应都是会占据一定的网络I/O开销，进行数据压缩会消耗少量的CPU资源，不过对于Kafka而言。网络I/O更应该需要考虑。</p><p>Kafka将多条消息一起压缩，而不是单个消息压缩，并且批量的消息可以通过压缩的形式进行传输和保存，直到被消费者消费时才解压。Kafka支持四种压缩算法：GZIP，Snappy，LZ4和Zstd。</p><p>下面这张表是 Facebook Zstandard（Zstd）官网提供的一份压缩算法比较结果：</p><p><img src="./why-is-kafka-fast/compression.png" alt="compression"></p><p>看一个压缩算法的优劣，有两个重要的指标：一个指标是压缩比，原先占100M空间的文件经压缩之后占20M空间，那么压缩比就是 5，压缩比越高越好；另一个指标是压缩和解压缩的吞吐量，比如每秒能压缩或解压缩多少 MB 的数据，吞吐量越高越好。</p><p>另外对于Kafka压缩，Producer端和Broker端配置是分开的，所以得要保证两端的压缩配置是相同的，不然就会出现多余的解压和重新压缩。</p><p>不可否认，文件分段存储（Topic-Partition-Segment）的机制（Topic被分为了多个区partition, 每个partition又分为了多个segment，所以一个队列中的消息实际上是保存在N多个片段文件中，通过分段的方式，每次文件操作都是对一个小文件的操作，同时也增加了并行处理能力），利用Offset偏移量快速寻找到到哪去消费消息来减少随机I/O，以及批量发送的机制也是其中的因素。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天这篇文章分享的主题是：Kafka为什么速度这么快？&lt;/p&gt;
&lt;p&gt;快是基于比较得出来的，相对与其它消息队列或消息引擎，在很多讲解Kafka的文章都会提到这一点：&lt;code&gt;Kafka可以很轻松的支持每秒百万级的TPS请求&lt;/code&gt;，其实在实际的基准测试中，每秒写入速率高达两百万，这远远高于其它消息队列的测试数据，Kafka在大数据消息队列组件中也是不二之选，并且绝大多数的大数据计算组件都与kafka进行集成。&lt;/p&gt;
&lt;p&gt;但实际生产中的性能数据会受很多参数和环境的影响，比如acks设置：在保证数据不丢失的情况下，设置acks=all，吞吐量会明显降低；replication副本数量：副本数越多，吞吐量越低；batch大小：batch-size大小达到阈值时，会达到吞吐量峰值，超过阈值后，并不会提升性能；和压缩设置等等因素都可以影响Kafka吞吐量。&lt;/p&gt;
&lt;p&gt;我们知道，Kafka的消息是保存或缓存在磁盘上的，一般认为在磁盘上读写是相对而言是较慢的，因为磁盘寻址是相对需要消耗大量的时间，那为什么Kafka速度还是这么快？我们得从&lt;code&gt;Kafka写入为什么这么快&lt;/code&gt;和&lt;code&gt;Kafka消费为什么这么快&lt;/code&gt;两方面，深入解析下Kafka主要的技术原理。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Kafka" scheme="https://pross.space/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>SparkStreaming之解析mapWithState</title>
    <link href="https://pross.space/blog/2019/12/10/analysis-of-sparkstreaming-mapwithstate.html"/>
    <id>https://pross.space/blog/2019/12/10/analysis-of-sparkstreaming-mapwithstate.html</id>
    <published>2019-12-10T01:56:59.000Z</published>
    <updated>2021-01-30T07:11:56.995Z</updated>
    
    <content type="html"><![CDATA[<p>最近经历挫折教育，今天闲得时间，整理状态管理之解析mapWithState。今天说道的mapWithState是从Spark1.6开始引入的一种新的状态管理机制，支持输出全量的状态和更新的状态，支持对状态超时的管理，和自主选择需要的输出。</p><a id="more"></a><h3 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> stateParse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Author: shawn pross</span></span><br><span class="line"><span class="comment">* Date: 2018/09/10</span></span><br><span class="line"><span class="comment">* Description: </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestMapWithState</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">conf.setAppName(<span class="string">s&quot;<span class="subst">$&#123;this.getClass.getSimpleName&#125;</span>&quot;</span>)</span><br><span class="line">conf.setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line">ssc.checkpoint(<span class="string">&quot;/checkpoint/&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> line = ssc.socketTextStream(<span class="string">&quot;127.0.0.1&quot;</span>,<span class="number">9999</span>)</span><br><span class="line"><span class="keyword">val</span> wordDStream = line.flatMap(_.split(<span class="string">&quot;,&quot;</span>)).map(x=&gt;(x,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">//状态更新函数，output是输出，state是状态</span></span><br><span class="line"><span class="keyword">val</span> mappingFunc = (userId:<span class="type">String</span>,value:<span class="type">Option</span>[<span class="type">Int</span>],state:<span class="type">State</span>[<span class="type">Int</span>])=&gt;&#123;</span><br><span class="line"><span class="keyword">val</span> sum= value.getOrElse(<span class="number">0</span>) + state.getOption().getOrElse(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">val</span> output = (userId,sum)</span><br><span class="line">state.update(sum)</span><br><span class="line">output</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//通过mapWithState更新状态，设置状态超时时间为1小时</span></span><br><span class="line"><span class="keyword">val</span> stateDStream = wordDStream.mapWithState(<span class="type">StateSpec</span>.function(mappingFunc).timeout(<span class="type">Minutes</span>(<span class="number">60</span>))).print()</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>mapWithState</code>接收的参数是一个<code>StateSpec</code>对象，在StateSpec中封装了状态管理的函数。我们定义了一个状态更新函数<code>mappingFunc</code>，该函数会更新指定用户的状态，同时会返回更新后的状态，将该函数传给<code>mapWithState</code>，并设置状态超时时间。SparkStreaming通过根据我们定义的更新函数，在每个计算时间间隔内更新内部维护的状态，同时返回经过<code>mappingFunc</code>处理后的结果数据流。</p><p>我们来看看它的实现方式。</p><h3 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h3><p>代码例子中可以看到，我们是在<code>StateSpec</code>中封装状态管理的函数，深入研究，看看怎么实现的。我们发现<code>mapWithState</code>函数会创建了<code>MapWithStateDStreamImpl</code>对象；继续往下寻找，其实<code>MapWithStateDStreamImp</code>是继承了<code>MapWithStateDStream</code>，而<code>MapWithStateDStream</code>的父类实际上是<code>DStream</code>。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// mapWithState函数中创建了MapWithStateDStreamImpl对象</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapWithState</span></span>[<span class="type">StateType</span>: <span class="type">ClassTag</span>, <span class="type">MappedType</span>: <span class="type">ClassTag</span>](</span><br><span class="line">      spec: <span class="type">StateSpec</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">StateType</span>, <span class="type">MappedType</span>]</span><br><span class="line">    ): <span class="type">MapWithStateDStream</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">StateType</span>, <span class="type">MappedType</span>] = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">MapWithStateDStreamImpl</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">StateType</span>, <span class="type">MappedType</span>](</span><br><span class="line">      self,</span><br><span class="line">      spec.asInstanceOf[<span class="type">StateSpecImpl</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">StateType</span>, <span class="type">MappedType</span>]]</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * MapWithStateDStreamImpl继承MapWithStateDStream</span></span><br><span class="line"><span class="comment">  * 创建InternalMapWithStateDStream类型对象的internalStream</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="keyword">private</span>[streaming] <span class="class"><span class="keyword">class</span> <span class="title">MapWithStateDStreamImpl</span>[</span></span><br><span class="line"><span class="class">    <span class="type">KeyType</span>: <span class="type">ClassTag</span>, <span class="type">ValueType</span>: <span class="type">ClassTag</span>, <span class="type">StateType</span>: <span class="type">ClassTag</span>, <span class="type">MappedType</span>: <span class="type">ClassTag</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    dataStream: <span class="type">DStream</span>[(<span class="type">KeyType</span>, <span class="type">ValueType</span></span>)],</span></span><br><span class="line"><span class="class">    <span class="title">spec</span></span>: <span class="type">StateSpecImpl</span>[<span class="type">KeyType</span>, <span class="type">ValueType</span>, <span class="type">StateType</span>, <span class="type">MappedType</span>])</span><br><span class="line">  <span class="keyword">extends</span> <span class="type">MapWithStateDStream</span>[<span class="type">KeyType</span>, <span class="type">ValueType</span>, <span class="type">StateType</span>, <span class="type">MappedType</span>](dataStream.context) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> internalStream =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">InternalMapWithStateDStream</span>[<span class="type">KeyType</span>, <span class="type">ValueType</span>, <span class="type">StateType</span>, <span class="type">MappedType</span>](dataStream, spec)</span><br><span class="line">      </span><br><span class="line">  ...</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(validTime: <span class="type">Time</span>): <span class="type">Option</span>[<span class="type">RDD</span>[<span class="type">MappedType</span>]] = &#123;</span><br><span class="line">    internalStream.getOrCompute(validTime).map &#123; _.flatMap[<span class="type">MappedType</span>] &#123; _.mappedData &#125; &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line"><span class="comment">//MapWithStateDStream的父类实际上是DStream</span></span><br><span class="line"><span class="keyword">sealed</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">MapWithStateDStream</span>[<span class="type">KeyType</span>, <span class="type">ValueType</span>, <span class="type">StateType</span>, <span class="type">MappedType</span>: <span class="type">ClassTag</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    ssc: <span class="type">StreamingContext</span></span>) <span class="keyword">extends</span> <span class="title">DStream</span>[<span class="type">MappedType</span>](<span class="params">ssc</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Return a pair DStream where each RDD is the snapshot of the state of all the keys. */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">stateSnapshots</span></span>(): <span class="type">DStream</span>[(<span class="type">KeyType</span>, <span class="type">StateType</span>)]</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>我们可以看到，MapWithStateDStreamImpl 中创建了一个<code>InternalMapWithStateDStream</code>类型对象<code>internalStream</code>，在MapWithStateDStreamImpl的<code>compute</code>方法中调用了internalStream的<code>getOrCompute</code>方法。</p><p>实际上，InternalMapWithStateDStream中没有getOrCompute方法，最终是调用父类 DStream 的getOrCpmpute方法，该方法中最终会调用InternalMapWithStateDStream中重写的Compute方法。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/** Method that generates an RDD for the given time */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(validTime: <span class="type">Time</span>): <span class="type">Option</span>[<span class="type">RDD</span>[<span class="type">MapWithStateRDDRecord</span>[<span class="type">K</span>, <span class="type">S</span>, <span class="type">E</span>]]] = &#123;</span><br><span class="line">    <span class="comment">// Get the previous state or create a new empty state RDD</span></span><br><span class="line">    <span class="keyword">val</span> prevStateRDD = getOrCompute(validTime - slideDuration) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(rdd) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (rdd.partitioner != <span class="type">Some</span>(partitioner)) &#123;</span><br><span class="line">          <span class="comment">// If the RDD is not partitioned the right way, let us repartition it using the</span></span><br><span class="line">          <span class="comment">// partition index as the key. This is to ensure that state RDD is always partitioned</span></span><br><span class="line">          <span class="comment">// before creating another state RDD using it</span></span><br><span class="line">          <span class="type">MapWithStateRDD</span>.createFromRDD[<span class="type">K</span>, <span class="type">V</span>, <span class="type">S</span>, <span class="type">E</span>](</span><br><span class="line">            rdd.flatMap &#123; _.stateMap.getAll() &#125;, partitioner, validTime)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          rdd</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">        <span class="type">MapWithStateRDD</span>.createFromPairRDD[<span class="type">K</span>, <span class="type">V</span>, <span class="type">S</span>, <span class="type">E</span>](</span><br><span class="line">          spec.getInitialStateRDD().getOrElse(<span class="keyword">new</span> <span class="type">EmptyRDD</span>[(<span class="type">K</span>, <span class="type">S</span>)](ssc.sparkContext)),</span><br><span class="line">          partitioner,</span><br><span class="line">          validTime</span><br><span class="line">        )</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Compute the new state RDD with previous state RDD and partitioned data RDD</span></span><br><span class="line">    <span class="comment">// Even if there is no data RDD, use an empty one to create a new state RDD</span></span><br><span class="line">    <span class="keyword">val</span> dataRDD = parent.getOrCompute(validTime).getOrElse &#123;</span><br><span class="line">      context.sparkContext.emptyRDD[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> partitionedDataRDD = dataRDD.partitionBy(partitioner)</span><br><span class="line">    <span class="keyword">val</span> timeoutThresholdTime = spec.getTimeoutInterval().map &#123; interval =&gt;</span><br><span class="line">      (validTime - interval).milliseconds</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">MapWithStateRDD</span>(</span><br><span class="line">      prevStateRDD, partitionedDataRDD, mappingFunction, validTime, timeoutThresholdTime))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">      </span><br></pre></td></tr></table></figure><p>InternalMapWithStateDStream中重写的Compute方法是关键。根据给定的时间生成一个<code>MapWithStateRDD</code>，首先获取了先前状态的RDD：preStateRDD和当前时间的RDD：dataRDD，然后对dataRDD基于先前状态RDD的分区器进行重新分区获取<code>partitionedDataRDD</code>，最后将<code>preStateRDD</code>，<code>partitionedDataRDD</code>，用户定义的函数<code>mappingFunction</code>和时间戳传给新生成的<code>MapWithStateRDD</code>对象，得出结果并返回。</p><p>我们再来看一下关键的MapWithStateRDD的<code>compute</code>方法。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(</span><br><span class="line">      partition: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">MapWithStateRDDRecord</span>[<span class="type">K</span>, <span class="type">S</span>, <span class="type">E</span>]] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stateRDDPartition = partition.asInstanceOf[<span class="type">MapWithStateRDDPartition</span>]</span><br><span class="line">    <span class="keyword">val</span> prevStateRDDIterator = prevStateRDD.iterator(</span><br><span class="line">      stateRDDPartition.previousSessionRDDPartition, context)</span><br><span class="line">    <span class="keyword">val</span> dataIterator = partitionedDataRDD.iterator(</span><br><span class="line">      stateRDDPartition.partitionedDataRDDPartition, context)</span><br><span class="line">    <span class="comment">//preRecord代表一个分区的数据</span></span><br><span class="line">    <span class="keyword">val</span> prevRecord = <span class="keyword">if</span> (prevStateRDDIterator.hasNext) <span class="type">Some</span>(prevStateRDDIterator.next()) <span class="keyword">else</span> <span class="type">None</span></span><br><span class="line">    <span class="keyword">val</span> newRecord = <span class="type">MapWithStateRDDRecord</span>.updateRecordWithData(</span><br><span class="line">      prevRecord,</span><br><span class="line">      dataIterator,</span><br><span class="line">      mappingFunction,</span><br><span class="line">      batchTime,</span><br><span class="line">      timeoutThresholdTime,</span><br><span class="line">      removeTimedoutData = doFullScan <span class="comment">// remove timed-out data only when full scan is enabled</span></span><br><span class="line">    )</span><br><span class="line">    <span class="type">Iterator</span>(newRecord)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p><code>MapWithStateRDDRecord</code> 对应MapWithStateRDD 的一个分区，<code>StateMap</code>存储了key的状态，mappedData存储了mappingFunc函数的返回值。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[streaming] <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">MapWithStateRDDRecord</span>[<span class="type">K</span>, <span class="type">S</span>, <span class="type">E</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    var stateMap: <span class="type">StateMap</span>[<span class="type">K</span>, <span class="type">S</span>], var mappedData: <span class="type">Seq</span>[<span class="type">E</span>]</span>)</span></span><br></pre></td></tr></table></figure><p>我们再来看下<code>MapWithStateRDDRecord.updateRecordWithData</code>方法，<code>newStateMap</code>是创建一个<code>StateMap</code>，从过去的Record中复制（如果存在），否则就创建新的StateMap对象。最终返回<code>MapWithSateRDDRecord</code>对象交给MapWithStateRDD的<code>compute</code>函数，MapWithStateRDD的compute函数将其封装成Iterator返回出去。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateRecordWithData</span></span>[<span class="type">K</span>: <span class="type">ClassTag</span>, <span class="type">V</span>: <span class="type">ClassTag</span>, <span class="type">S</span>: <span class="type">ClassTag</span>, <span class="type">E</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    prevRecord: <span class="type">Option</span>[<span class="type">MapWithStateRDDRecord</span>[<span class="type">K</span>, <span class="type">S</span>, <span class="type">E</span>]],</span><br><span class="line">    dataIterator: <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">V</span>)],</span><br><span class="line">    mappingFunction: (<span class="type">Time</span>, <span class="type">K</span>, <span class="type">Option</span>[<span class="type">V</span>], <span class="type">State</span>[<span class="type">S</span>]) =&gt; <span class="type">Option</span>[<span class="type">E</span>],</span><br><span class="line">    batchTime: <span class="type">Time</span>,</span><br><span class="line">    timeoutThresholdTime: <span class="type">Option</span>[<span class="type">Long</span>],</span><br><span class="line">    removeTimedoutData: <span class="type">Boolean</span></span><br><span class="line">  ): <span class="type">MapWithStateRDDRecord</span>[<span class="type">K</span>, <span class="type">S</span>, <span class="type">E</span>] = &#123;</span><br><span class="line">    <span class="comment">// Create a new state map by cloning the previous one (if it exists) or by creating an empty one</span></span><br><span class="line">    <span class="keyword">val</span> newStateMap = prevRecord.map &#123; _.stateMap.copy() &#125;. getOrElse &#123; <span class="keyword">new</span> <span class="type">EmptyStateMap</span>[<span class="type">K</span>, <span class="type">S</span>]() &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mappedData = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">E</span>]</span><br><span class="line">    <span class="keyword">val</span> wrappedState = <span class="keyword">new</span> <span class="type">StateImpl</span>[<span class="type">S</span>]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Call the mapping function on each record in the data iterator, and accordingly</span></span><br><span class="line">    <span class="comment">// update the states touched, and collect the data returned by the mapping function</span></span><br><span class="line">    dataIterator.foreach &#123; <span class="keyword">case</span> (key, value) =&gt;</span><br><span class="line">        <span class="comment">// 获取key对应的状态</span></span><br><span class="line">      wrappedState.wrap(newStateMap.get(key))</span><br><span class="line">        <span class="comment">// 调用mappingFunc获取返回值</span></span><br><span class="line">      <span class="keyword">val</span> returned = mappingFunction(batchTime, key, <span class="type">Some</span>(value), wrappedState)</span><br><span class="line">        <span class="comment">//维护newStateMap的值</span></span><br><span class="line">      <span class="keyword">if</span> (wrappedState.isRemoved) &#123;</span><br><span class="line">        newStateMap.remove(key)</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (wrappedState.isUpdated</span><br><span class="line">          || (wrappedState.exists &amp;&amp; timeoutThresholdTime.isDefined)) &#123;</span><br><span class="line">        newStateMap.put(key, wrappedState.get(), batchTime.milliseconds)</span><br><span class="line">      &#125;</span><br><span class="line">      mappedData ++= returned</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get the timed out state records, call the mapping function on each and collect the</span></span><br><span class="line">    <span class="comment">// data returned</span></span><br><span class="line">    <span class="keyword">if</span> (removeTimedoutData &amp;&amp; timeoutThresholdTime.isDefined) &#123;</span><br><span class="line">      newStateMap.getByTime(timeoutThresholdTime.get).foreach &#123; <span class="keyword">case</span> (key, state, _) =&gt;</span><br><span class="line">        wrappedState.wrapTimingOutState(state)</span><br><span class="line">        <span class="keyword">val</span> returned = mappingFunction(batchTime, key, <span class="type">None</span>, wrappedState)</span><br><span class="line">        mappedData ++= returned</span><br><span class="line">        newStateMap.remove(key)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">MapWithStateRDDRecord</span>(newStateMap, mappedData)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此，mapWithState方法源码执行过程水落石出。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近经历挫折教育，今天闲得时间，整理状态管理之解析mapWithState。今天说道的mapWithState是从Spark1.6开始引入的一种新的状态管理机制，支持输出全量的状态和更新的状态，支持对状态超时的管理，和自主选择需要的输出。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Spark" scheme="https://pross.space/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>SparkStreaming之解析updateStateByKey</title>
    <link href="https://pross.space/blog/2019/10/19/analysis-of-sparkstreaming-updatestatebykey.html"/>
    <id>https://pross.space/blog/2019/10/19/analysis-of-sparkstreaming-updatestatebykey.html</id>
    <published>2019-10-19T10:52:15.000Z</published>
    <updated>2021-01-30T07:11:56.710Z</updated>
    
    <content type="html"><![CDATA[<p>说到Spark Streaming的状态管理，就会想到updateStateByKey，还有mapWithState。今天整理了一下，着重了解一下前者。</p><h4 id="状态管理的需求"><a href="#状态管理的需求" class="headerlink" title="状态管理的需求"></a>状态管理的需求</h4><p>举一个最简单的需求例子来解释状态（state）管理，现在有这样的一个需求：计算从数据流开始到目前为止单词出现的次数。是不是看起来很眼熟，这其实就是一个升级版的wordcount，只不过需要在每个batchInterval计算当前batch的单词计数，然后对各个批次的计数进行累加。每一个批次的累积的计数就是当前的一个状态值。我们需要把这个状态保存下来，和后面批次单词的计数结果来进行计算，这样我们就能不断的在历史的基础上进行次数的更新。</p><p>SparkStreaming提供了两种方法来解决这个问题：updateStateByKey和mapWithState。mapWithState是1.6版本新增的功能，官方说性能较updateStateByKey提升10倍。</p><a id="more"></a><h4 id="updateStateByKey概述"><a href="#updateStateByKey概述" class="headerlink" title="updateStateByKey概述"></a>updateStateByKey概述</h4><p>updateStateByKey，统计全局的Key的状态，就算没有数据输入，也会在每一个批次的时候返回之前的key的状态。假设5s产生一个批次的数据，那么就是5s的时候就更新一次key的值，然后返回。如果数据量又比较大，又需要不断的更新每个Key的state， 那么就一定会涉及到状态的保存和容错。所以，要使用updateStateByKey就需要设置一个checkpoint目录，开启checkpoint机制。因为key的State是在内存中维护的，如果宕机，则重启之后之前维护的状态就没有了，所以要长期保存的话则需要启用<code>checkpoint</code>，以便于恢复数据。</p><h4 id="updateStateByKey代码例子"><a href="#updateStateByKey代码例子" class="headerlink" title="updateStateByKey代码例子"></a>updateStateByKey代码例子</h4><p>现在我们来看看怎么用的，首先看一个updateStateByKey使用的简单例子：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Author: shawn pross</span></span><br><span class="line"><span class="comment">  * Date: 2018/06/18</span></span><br><span class="line"><span class="comment">  * Description: test updateStateByKey op</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestUpdateStateByKey</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">conf.setAppName(<span class="string">s&quot;<span class="subst">$&#123;this.getClass.getSimpleName&#125;</span>&quot;</span>)</span><br><span class="line">conf.setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * 创建context,3 second batch size</span></span><br><span class="line"><span class="comment">* 创建一个接收器(ReceiverInputDStream),接收从机器上的端口，通过socket发过来的数据</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line"><span class="keyword">val</span> bathLine = ssc.socketTextStream(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">9999</span>)</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 传入updateStateByKey的函数</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* 源码定义：</span></span><br><span class="line"><span class="comment">* def updateStateByKey[S: ClassTag](</span></span><br><span class="line"><span class="comment">* updateFunc: (Seq[V], Option[S]) =&gt; Option[S]): DStream[(K, S)] = ssc.withScope &#123;</span></span><br><span class="line"><span class="comment">* updateStateByKey(updateFunc, defaultPartitioner())</span></span><br><span class="line"><span class="comment">* &#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">val</span> updateFunc = (currValues: <span class="type">Seq</span>[<span class="type">Int</span>], prevValueState: <span class="type">Option</span>[<span class="type">Int</span>]) =&gt; &#123;</span><br><span class="line"><span class="comment">//通过Spark内部的reduceByKey按key规约，然后这里传入某key当前批次的Seq/List,再计算当前批次的总和</span></span><br><span class="line"><span class="keyword">val</span> currentCount = currValues.sum</span><br><span class="line"><span class="comment">// 已累加的值</span></span><br><span class="line"><span class="keyword">val</span> previousCount = prevValueState.getOrElse(<span class="number">0</span>)</span><br><span class="line"><span class="comment">// 返回累加后的结果，是一个Option[Int]类型</span></span><br><span class="line"><span class="type">Some</span>(currentCount + previousCount)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//先聚合成键值对的形式</span></span><br><span class="line">bathLine.map(x=&gt;(x,<span class="number">1</span>)).updateStateByKey(updateFunc).print()</span><br><span class="line">        </span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码很简单，注释也比较详细。其中要说明的是<code>updateStateByKey</code>的参数还有几个可选项：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateStateByKey</span></span>[<span class="type">S</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    <span class="comment">//状态更新功能</span></span><br><span class="line">    updateFunc: (<span class="type">Seq</span>[<span class="type">V</span>], <span class="type">Option</span>[<span class="type">S</span>]) =&gt; <span class="type">Option</span>[<span class="type">S</span>],</span><br><span class="line">    <span class="comment">//用于控制新RDD中每个RDD的分区的分区程序</span></span><br><span class="line">    partitioner: <span class="type">Partitioner</span>,</span><br><span class="line">    <span class="comment">//是否记住生成的RDD中的分区对象</span></span><br><span class="line">    rememberPartitioner: <span class="type">Boolean</span>,  </span><br><span class="line">    <span class="comment">//每个键的初始状态值</span></span><br><span class="line">    initialRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">S</span>)],</span><br><span class="line">  ): <span class="type">DStream</span>[(<span class="type">K</span>, <span class="type">S</span>)] = ssc.withScope &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="updateStateByKey源码分析"><a href="#updateStateByKey源码分析" class="headerlink" title="updateStateByKey源码分析"></a>updateStateByKey源码分析</h4><p>通过上面简单的小例子可以知道，使用updateStateByKey是需要先转换为键值对的形式的，而map返回的是<code>MappedDStream</code>，而进入<code>MappedDStream</code>中也没有updateStateByKey方法，然后其父类DStream中也没有。但是DStream的半生对象中有一个隐式的转换函数<code>toPairDStreamFunctions</code>。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// map实现，返回MappedDStream</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](mapFunc: <span class="type">T</span> =&gt; <span class="type">U</span>): <span class="type">DStream</span>[<span class="type">U</span>] = ssc.withScope &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">MappedDStream</span>(<span class="keyword">this</span>, context.sparkContext.clean(mapFunc))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// MappedDStream父类是DStream</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MappedDStream</span>[<span class="type">T</span>: <span class="type">ClassTag</span>, <span class="type">U</span>: <span class="type">ClassTag</span>] (<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    parent: <span class="type">DStream</span>[<span class="type">T</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    mapFunc: <span class="type">T</span> =&gt; <span class="type">U</span></span></span></span><br><span class="line"><span class="class"><span class="params">  </span>) <span class="keyword">extends</span> <span class="title">DStream</span>[<span class="type">U</span>](<span class="params">parent.ssc</span>) </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// DStream中隐式的转换函数</span></span><br><span class="line"><span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">toPairDStreamFunctions</span></span>[<span class="type">K</span>, <span class="type">V</span>](stream: <span class="type">DStream</span>[(<span class="type">K</span>, <span class="type">V</span>)])</span><br><span class="line">      (<span class="keyword">implicit</span> kt: <span class="type">ClassTag</span>[<span class="type">K</span>], vt: <span class="type">ClassTag</span>[<span class="type">V</span>], ord: <span class="type">Ordering</span>[<span class="type">K</span>] = <span class="literal">null</span>):</span><br><span class="line">    <span class="type">PairDStreamFunctions</span>[<span class="type">K</span>, <span class="type">V</span>] = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">PairDStreamFunctions</span>[<span class="type">K</span>, <span class="type">V</span>](stream)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>看到<code>new PairDStreamFunctions</code>就不陌生了。<code>PairDStreamFunctions</code>中存在updateStateByKey方法，Seq[V]表示当前key对应的所有值，Option[S] 是当前key的历史状态，返回的是新的状态。也就是绕了一个圈子又回到原地。最后updateStateByKey最终会在这里面new出了一个<code>StateDStream</code>对象。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateStateByKey</span></span>[<span class="type">S</span>: <span class="type">ClassTag</span>](</span><br><span class="line">     updateFunc: (<span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">Seq</span>[<span class="type">V</span>], <span class="type">Option</span>[<span class="type">S</span>])]) =&gt; <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">S</span>)],</span><br><span class="line">     partitioner: <span class="type">Partitioner</span>,</span><br><span class="line">     rememberPartitioner: <span class="type">Boolean</span>,</span><br><span class="line">     initialRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">S</span>)]): <span class="type">DStream</span>[(<span class="type">K</span>, <span class="type">S</span>)] = ssc.withScope &#123;</span><br><span class="line">   <span class="keyword">val</span> cleanedFunc = ssc.sc.clean(updateFunc)</span><br><span class="line">   <span class="keyword">val</span> newUpdateFunc = (_: <span class="type">Time</span>, it: <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">Seq</span>[<span class="type">V</span>], <span class="type">Option</span>[<span class="type">S</span>])]) =&gt; &#123;</span><br><span class="line">     cleanedFunc(it)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">new</span> <span class="type">StateDStream</span>(self, newUpdateFunc, partitioner, rememberPartitioner, <span class="type">Some</span>(initialRDD))</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>继续进去<code>StateDStream</code>看看，在其<code>compute</code>方法中，会先获取上一个batch计算出的RDD（包含了至程序开始到上一个batch单词的累计计数），然后在获取本次batch中<code>StateDStream</code>的父类计算出的RDD（本次batch的单词计数）分别是<code>prevStateRDD</code>和<code>parentRDD</code>，然后在调用 <code>computeUsingPreviousRDD</code> 方法：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> [<span class="keyword">this</span>] <span class="function"><span class="keyword">def</span> <span class="title">computeUsingPreviousRDD</span></span>(</span><br><span class="line">    batchTime: <span class="type">Time</span>,</span><br><span class="line">    parentRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)],</span><br><span class="line">    prevStateRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">S</span>)]) = &#123;</span><br><span class="line">  <span class="comment">// Define the function for the mapPartition operation on cogrouped RDD;</span></span><br><span class="line">  <span class="comment">// first map the cogrouped tuple to tuples of required type,</span></span><br><span class="line">  <span class="comment">// and then apply the update function</span></span><br><span class="line">  <span class="keyword">val</span> updateFuncLocal = updateFunc</span><br><span class="line">  <span class="keyword">val</span> finalFunc = (iterator: <span class="type">Iterator</span>[(<span class="type">K</span>, (<span class="type">Iterable</span>[<span class="type">V</span>], <span class="type">Iterable</span>[<span class="type">S</span>]))]) =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> i = iterator.map &#123; t =&gt;</span><br><span class="line">      <span class="keyword">val</span> itr = t._2._2.iterator</span><br><span class="line">      <span class="keyword">val</span> headOption = <span class="keyword">if</span> (itr.hasNext) <span class="type">Some</span>(itr.next()) <span class="keyword">else</span> <span class="type">None</span></span><br><span class="line">      (t._1, t._2._1.toSeq, headOption)</span><br><span class="line">    &#125;</span><br><span class="line">    updateFuncLocal(batchTime, i)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">val</span> cogroupedRDD = parentRDD.cogroup(prevStateRDD, partitioner)</span><br><span class="line">  <span class="keyword">val</span> stateRDD = cogroupedRDD.mapPartitions(finalFunc, preservePartitioning)</span><br><span class="line">  <span class="type">Some</span>(stateRDD)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后返回<code>stateRDD</code>结果。至此，updateStateByKey方法源码执行过程水落石出。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;说到Spark Streaming的状态管理，就会想到updateStateByKey，还有mapWithState。今天整理了一下，着重了解一下前者。&lt;/p&gt;
&lt;h4 id=&quot;状态管理的需求&quot;&gt;&lt;a href=&quot;#状态管理的需求&quot; class=&quot;headerlink&quot; title=&quot;状态管理的需求&quot;&gt;&lt;/a&gt;状态管理的需求&lt;/h4&gt;&lt;p&gt;举一个最简单的需求例子来解释状态（state）管理，现在有这样的一个需求：计算从数据流开始到目前为止单词出现的次数。是不是看起来很眼熟，这其实就是一个升级版的wordcount，只不过需要在每个batchInterval计算当前batch的单词计数，然后对各个批次的计数进行累加。每一个批次的累积的计数就是当前的一个状态值。我们需要把这个状态保存下来，和后面批次单词的计数结果来进行计算，这样我们就能不断的在历史的基础上进行次数的更新。&lt;/p&gt;
&lt;p&gt;SparkStreaming提供了两种方法来解决这个问题：updateStateByKey和mapWithState。mapWithState是1.6版本新增的功能，官方说性能较updateStateByKey提升10倍。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Spark" scheme="https://pross.space/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Apache-Thrift-Thrift-Thrift</title>
    <link href="https://pross.space/blog/2019/09/09/apachethriftthriftthrift.html"/>
    <id>https://pross.space/blog/2019/09/09/apachethriftthriftthrift.html</id>
    <published>2019-09-09T15:10:18.000Z</published>
    <updated>2021-01-30T07:11:56.713Z</updated>
    
    <content type="html"><![CDATA[<p>接着上篇文章说。</p><p>我们知道了Apache Thrift主要用于各个服务之间的RPC通信，并且支持跨语言；包括C++，Java，Python，PHP，Ruby，Go，Node.js等等，还有一些都没听说过的语言；而且从上篇文章的RPC例子中可以发现，Thrift是一个典型的CS（客户端/服务端）架构；加上跨语言的特性，我们可以推断一下：客户端和服务端是可以使用不同的语言开发的。</p><p>如果CS端可以使用不同的语言来开发，那么一定是有一种中间语言来关联客户端和服务端（相同语言也需要关联客户端和服务端）。其实这个答案都知道，那就是接口定义语言：IDL（Interface Description Language）；下面我们从IDL进行开场表演，进行一次Thrift RPC的完整演出。</p><a id="more"></a><h3 id="接口描述语言IDL"><a href="#接口描述语言IDL" class="headerlink" title="接口描述语言IDL"></a>接口描述语言IDL</h3><p>依旧照例，搬来wiki的解释：</p><blockquote><p>接口描述语言（Interface Description Language，缩写IDL），是用来描述软件组件界面的一种计算机语言。IDL通过一种中立的方式来描述接口，使得在不同平台上运行的对象和用不同语言编写的程序可以相互通信交流；比如，一个组件用C++写成，另一个组件用Java写成。</p><p>IDL通常用于远程调用软件。在这种情况下，一般是由远程客户终端调用不同操作系统上的对象组件，并且这些对象组件可能是由不同计算机语言编写的。IDL建立起了两个不同操作系统间通信的桥梁。</p></blockquote><p>关于IDL数据类型和语法介绍，这里简单列举：</p><p><strong>基本类型</strong></p><ul><li>byte：8位有符号整数（byte）</li><li>i16：16位有符号整数（short）</li><li>i32：32位有符号整数（int）</li><li>i64：64位有符号整数（long）</li><li>double：64位浮点数（double）</li><li>string：字符串（string）</li><li>bool：布尔变量（boolean）</li></ul><blockquote><p>Thrift不支持无符号整数，因为不是所有的语言都支持无符号整数。</p></blockquote><p><strong>容器类型</strong></p><ul><li>list<T>：有序列表，元素可以重复</li><li>set<T>：无序集合，元素不可重复</li><li>map&lt;k,v&gt;：字典结构，键值对</li></ul><p><strong>结构体</strong></p><p>类似C语言的结构体。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// required和optional，必选和可选</span></span><br><span class="line">struct Example &#123;</span><br><span class="line">   <span class="number">1</span>: required string name;      </span><br><span class="line">   <span class="number">3</span>: optional i32 age;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>枚举类型</strong></p><p>可以像C/C++一样定义枚举类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">EnumType</span> </span>&#123;</span><br><span class="line">    NUMBER = <span class="number">2</span></span><br><span class="line">&#125;        </span><br><span class="line"></span><br><span class="line">struct exampleStruct &#123;</span><br><span class="line">    required i32 id;</span><br><span class="line">    required string userName;</span><br><span class="line">    optional EnumType enumType = EnumType.NUMBER;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>异常</strong></p><p>可以自定义异常，所定义的异常会继承对应语言的异常类，比如Java，就会继承<code>java.lang.Exception</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">exception RequestException &#123;</span><br><span class="line">   <span class="number">1</span>: required i32 code;</span><br><span class="line">   <span class="number">2</span>: optional string reason;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>服务</strong></p><p>相当于Java中创建接口（Interface）一样，创建的service经过Thrift代码生成客户端和服务端的框架。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service exampleService&#123;</span><br><span class="line">    <span class="function">string <span class="title">hello</span><span class="params">(<span class="number">1</span>:string username)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><p><strong>命名空间</strong></p><p>关键字<code>namespace</code>，相当于Java中的package，必须需要。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 代码路径：service.study.thrift</span></span><br><span class="line">namespace java service.study.thrift</span><br></pre></td></tr></table></figure><p><strong>常量</strong></p><p>定义常量，复杂的类型和结构体可以使用JSON来表示。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> i32 INT_CONST = <span class="number">20</span>;</span><br><span class="line"><span class="keyword">const</span> map&lt;i32,string&gt; MAP_CONST = &#123;<span class="number">1</span>:<span class="string">&quot;hello&quot;</span>,<span class="number">2</span>:<span class="string">&quot;world&quot;</span>&#125;;</span><br></pre></td></tr></table></figure><p><strong>注释</strong></p><p>支持<code>#</code>和<code>//</code>单行注释，和<code>/***/</code>多行注释。</p><p>我们用以上的的数据类型和语法规则，自定义生成一个Thrift文件，取名叫<code>hello.thrift</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">namespace java org.pross.thrift</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">RequestType</span> </span>&#123;</span><br><span class="line">   SAY_HELLO,   <span class="comment">//问好</span></span><br><span class="line">   QUERY_TIME,  <span class="comment">//询问时间</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct Request &#123;</span><br><span class="line">   <span class="number">1</span>: required RequestType type;  <span class="comment">// 请求的类型，必选</span></span><br><span class="line">   <span class="number">2</span>: required string name;       <span class="comment">// 发起请求的人的名字，必选</span></span><br><span class="line">   <span class="number">3</span>: optional i32 age;           <span class="comment">// 发起请求的人的年龄，可选</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 异常</span></span><br><span class="line">exception RequestException &#123;</span><br><span class="line">   <span class="number">1</span>: required i32 code;</span><br><span class="line">   <span class="number">2</span>: optional string reason;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 服务名，接口：addition()和sayHello()，将会使用到</span></span><br><span class="line">service HelloMethod&#123;</span><br><span class="line">    <span class="function">i32 <span class="title">division</span><span class="params">(<span class="number">1</span>:i32 param1,<span class="number">2</span>:i32 param2)</span> <span class="title">throws</span> <span class="params">(<span class="number">1</span>:RequestException re)</span> <span class="comment">//可能抛出异常</span></span></span><br><span class="line"><span class="function">    string <span class="title">sayHello</span><span class="params">(<span class="number">1</span>:string username)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><p>安装好thrift，在终端运行：<code>thrift --gen java hello.thrift</code>，则在当前目录下会生成一个<code>gen-java</code>目录，在该目录下会按照<code>namespace</code>定义路径名，生成文件夹；最终我们可以看到生成了4个Java类：<code>HelloMethod</code>，<code>Ruquest</code>，<code>RequestException</code>和<code>RequestType</code>。<code>hello.thrift</code>文件中定义的enum，struct，exception，service都相应地生成了一个Java类，这就是能支持Java语言通信的基本框架代码。</p><blockquote><p><code>thrift --gen java hello.thrift</code>，指定Java语言生成框架代码。</p><p>如果客户端和服务端使用不同的语言来编写，只需要对选择不同语言的生成框架代码即可。</p></blockquote><p>我们再来看看生成的<code>HelloMethod</code>类的具体结构，简单介绍一下：</p><p><img src="Apache-Thrift-Thrift-Thrift%5Cdir.png"></p><p>对于开发人员而言，需要关注几个核心内部接口/方法：</p><ul><li><p>Iface：服务端通过实现<code>HelloMethod.Iface</code>接口，向客户端提供同步调用业务逻辑的接口。</p></li><li><p>AsyncIface：服务端通过实现<code>HelloMethod.Iface</code>接口，向客户端提供异步调用，异步调用接口多了一个回调参数<code>AsyncMethodCallback&lt;String&gt;</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 同步调用接口  </span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Iface</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">division</span><span class="params">(<span class="keyword">int</span> param1, <span class="keyword">int</span> param2)</span> <span class="keyword">throws</span> RequestException, org.apache.thrift.TException</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">sayHello</span><span class="params">(String username)</span> <span class="keyword">throws</span> org.apache.thrift.TException</span>;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//异步调用接口</span></span><br><span class="line">  <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">AsyncIface</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">division</span><span class="params">(<span class="keyword">int</span> param1, <span class="keyword">int</span> param2, org.apache.thrift.async.AsyncMethodCallback&lt;Integer&gt; resultHandler)</span> <span class="keyword">throws</span> org.apache.thrift.TException</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sayHello</span><span class="params">(String username, org.apache.thrift.async.AsyncMethodCallback&lt;String&gt; resultHandler)</span> <span class="keyword">throws</span> org.apache.thrift.TException</span>;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li><li><p>Client/AsyncClient：客户端实例化<code>HelloMethod.Client</code>对象，以同步/异步的方式访问服务端提供的服务方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">// 提供工厂方法创建client对象</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Factory</span> <span class="keyword">implements</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">thrift</span>.<span class="title">TServiceClientFactory</span>&lt;<span class="title">Client</span>&gt; </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Factory</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> Client <span class="title">getClient</span><span class="params">(org.apache.thrift.protocol.TProtocol prot)</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">new</span> Client(prot);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> Client <span class="title">getClient</span><span class="params">(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot)</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">new</span> Client(iprot, oprot);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 接口方法的客户端代理</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">division</span><span class="params">(<span class="keyword">int</span> param1, <span class="keyword">int</span> param2)</span> <span class="keyword">throws</span> RequestException, org.apache.thrift.TException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      <span class="comment">// 发送方法调用请求</span></span><br><span class="line">      send_division(param1, param2);</span><br><span class="line">      <span class="comment">// 接收返回值</span></span><br><span class="line">      <span class="keyword">return</span> recv_division();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send_division</span><span class="params">(<span class="keyword">int</span> param1, <span class="keyword">int</span> param2)</span> <span class="keyword">throws</span> org.apache.thrift.TException</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      <span class="comment">// 创建方法参数对象，封装方法参数</span></span><br><span class="line">      division_args args = <span class="keyword">new</span> division_args();</span><br><span class="line">      args.setParam1(param1);</span><br><span class="line">      args.setParam2(param2);</span><br><span class="line">      <span class="comment">// 调用父类方法发送消息</span></span><br><span class="line">      sendBase(<span class="string">&quot;division&quot;</span>, args);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">...</span><br><span class="line">  <span class="comment">// org.apache.thrift.TServiceClient.sendBase</span></span><br><span class="line">      <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendBase</span><span class="params">(String methodName, TBase&lt;?, ?&gt; args, <span class="keyword">byte</span> type)</span> <span class="keyword">throws</span> TException </span>&#123;</span><br><span class="line">  <span class="comment">// 发送消息头（TProtocol）</span></span><br><span class="line">        <span class="keyword">this</span>.oprot_.writeMessageBegin(<span class="keyword">new</span> TMessage(methodName, type, ++<span class="keyword">this</span>.seqid_));</span><br><span class="line">  <span class="comment">// 发送消息体，由方法参数对象自己处理编码， write(TProtocol)</span></span><br><span class="line">        args.write(<span class="keyword">this</span>.oprot_);</span><br><span class="line">        <span class="keyword">this</span>.oprot_.writeMessageEnd();</span><br><span class="line">        <span class="keyword">this</span>.oprot_.getTransport().flush();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li><p>Processor：用来支持方法调用，每个服务实现类需要使用Processor来注册，这样服务器调用接口实现时能定位到具体的实现类。</p></li><li><p>方法参数的封装类：以方法名_args命名</p></li><li><p>方法返回值的封装类：以方法名_result命名</p></li></ul><p>以上就是通过IDL语法规则，生成的中间语言，用于客户端和服务端之间的通信交流。</p><h3 id="Thrift协议栈整体的架构"><a href="#Thrift协议栈整体的架构" class="headerlink" title="Thrift协议栈整体的架构"></a>Thrift协议栈整体的架构</h3><p>OK，我们已经搭建好了<code>Client</code>和<code>Server</code>端相互交流的桥梁了。接下来看看Thrift，了解下整体架构，在编写代码实现逻辑交互时，才能知其所以然。架构如下图：</p><p><img src="Apache-Thrift-Thrift-Thrift%5Cthrift.png" alt="thrift架构"></p><p>在Client和Server的最顶层都是用户自定义的处理逻辑。</p><p>Processor（TProcessor的子类）是服务器端从Thrift框架转入用户逻辑的关键流程，负责对Client的请求做出响应，包括RPC请求转发、调用参数解析、用户逻辑调用，返回值写回等；也对TServer中请求的InputProtocol和OutputTProtocol进行操作，从InputProtocol中读出Client的请求数据，向OutputProtcol中写入用户逻辑的返回值。</p><p>TServer主要任务就是高效的接受Client的请求，并将请求转发到Processor进行处理，主要有以下实现：</p><ul><li>TSimpleServer：简单的单线程网络阻塞模型，同时只能服务一个client连接，其他所有客户端在被服务器端接受之前都只能等待，主要用于测试。</li><li>TNonblockingServer：多线程服务模型，使用了NIO中的<code>Selector</code>选择器，通过调用<code>select()</code>，使得客户端的请求阻塞在多个连接上，而不是在单一的连接；可以服务多个客户端。</li><li>THsHaServer：使用单独的线程来处理网络I/O，一个独立的worker线程池来处理消息，只要有空闲的worker线程就会被立即处理。</li><li>TThreadedSelectorServer：维护了两个线程池，一个用来处理网络I/O，另一个用来进行请求的处理。当网络I/O是瓶颈的时候，TThreadedSelectorServer比THsHaServer的表现要好。</li><li>TThreadPoolServer：线程池网络模型，是将每一个请求都加入到<code>ThreadPoolExecutor</code>线程池中，并绑定其中一个worker线程去处理，直到关闭。</li></ul><p>TProtocol 是传输协议层，主要负责结构化数据，并组装成Message，或者从Message结构中读出结构化数据。将一个有类型的数据转化为字节流以交给TTransport进行传输，或者从TTransport中读取一定长度的字节数据转化为特定类型的数据。如int32会被TBinaryProtocol Encode为一个四字节的字节数据，或者TBinaryProtocol从TTransport中取出四个字节的数据Decode为int32。</p><blockquote><p>传输协议包括：TBinaryProtocol（基于二进制编码传输的协议），TCompactProtocol（紧凑，高效的二进制传输协议，使用Variable-Length Quantity (VLQ) 编码对数据编码压缩，主要是对整数采用可变长度），TJSONProtocol（使用JSON格式编码的传输协议），TDebugProtocol（文本格式，方便抓包Debug）。</p></blockquote><p>TTransport 传输层负责以字节流方式发送和接收Message，是底层IO模块在Thrift框架中的实现，每一个底层IO模块都会有一个对应TTransport来负责Byte Stream（字节流）数据在该IO模块上的传输，有以下TTransport的实现：</p><ul><li>TSocket：阻塞型 socket，是最常见的模式，用于客户端，采用系统函数 read 和 write 进行读写数据</li><li>TServerSocket：非阻塞型 socket，用于服务器端，accecpt 到的 socket 类型都是 TSocket</li><li>THttpTransport：采用HTTP传输协议进行传输，非阻塞式中使用</li><li>TFramedTransport：按块的大小进行传输，支持定长数据发送和接收</li><li>TFileTransport：用于写数据到文件，以文件形式进行传输</li><li>TMemoryBuffer：从一个缓冲区中读写数据，Java实现使用的是<code>ByteArrayOutputStream</code></li><li>TZlibTransport：Java中采用<code>java.util.zip</code>包，来进行压缩和解压缩</li></ul><p>底层IO模块，负责实际的数据传输，包括Socket，文件，或者压缩数据流等。</p><h3 id="Show-me-your-code"><a href="#Show-me-your-code" class="headerlink" title="Show me your code"></a>Show me your code</h3><p>项目需要引入<code>libthrift</code>依赖：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;libthrift&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.12.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>创建接口实现类实现<code>HelloMethod.Iface</code>接口，并实现相应方法的处理逻辑和返回。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloThriftImpl</span> <span class="keyword">implements</span> <span class="title">HelloMethod</span>.<span class="title">Iface</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 除法，整除</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">division</span><span class="params">(<span class="keyword">int</span> param1, <span class="keyword">int</span> param2)</span> <span class="keyword">throws</span> RequestException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> value = param1 / param2;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// say + username</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">sayHello</span><span class="params">(String username)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;hello &quot;</span>+username;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建 <code>ThriftServer.java</code> 实现服务端，关键代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThriftServer</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">initServer</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 设置多线程服务模型</span></span><br><span class="line">            TNonblockingServerSocket socket = <span class="keyword">new</span> TNonblockingServerSocket(<span class="number">9090</span>);</span><br><span class="line">            <span class="comment">// 关联业务处理器TProcessor</span></span><br><span class="line">            TProcessor processor = <span class="keyword">new</span> HelloMethod.Processor(<span class="keyword">new</span> HelloThriftImpl());</span><br><span class="line">            <span class="comment">// 设置二进制传输协议，TFramedTransport传输方式和关联业务处理</span></span><br><span class="line">            TNonblockingServer.Args arg = <span class="keyword">new</span> TNonblockingServer.Args(socket);</span><br><span class="line">            arg.protocolFactory(<span class="keyword">new</span> TBinaryProtocol.Factory());</span><br><span class="line">            arg.transportFactory(<span class="keyword">new</span> TFramedTransport.Factory());</span><br><span class="line">            arg.processorFactory(<span class="keyword">new</span> TProcessorFactory(processor));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 开启服务</span></span><br><span class="line">            TServer server = <span class="keyword">new</span> TNonblockingServer (arg);</span><br><span class="line">            System.out.println(<span class="string">&quot;start server port 9090 ...&quot;</span>);</span><br><span class="line">            server.serve();</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (TTransportException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        initServer();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建<code>ThriftClient.java</code>实现客户端：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThriftClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sendServerRequest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 创建客户端连接，url，port，timeout</span></span><br><span class="line">            TSocket socket = <span class="keyword">new</span> TSocket(<span class="string">&quot;localhost&quot;</span>, <span class="number">9090</span>, <span class="number">3000</span>);</span><br><span class="line">            <span class="comment">// 设置TFramedTransport传输方式，二进制传输协议</span></span><br><span class="line">            TTransport transport = <span class="keyword">new</span> TFramedTransport(socket);</span><br><span class="line">            TProtocol protocol = <span class="keyword">new</span> TBinaryProtocol(transport);</span><br><span class="line">            <span class="comment">// open client</span></span><br><span class="line">            socket.open();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 实例客户端业务处理，调用方法,返回结果</span></span><br><span class="line">            HelloMethod.Client client = <span class="keyword">new</span> HelloMethod.Client(protocol);</span><br><span class="line">            <span class="comment">// hello + pross</span></span><br><span class="line">            String hello = client.sayHello(<span class="string">&quot;pross&quot;</span>);</span><br><span class="line">          <span class="comment">// 3/1 =3</span></span><br><span class="line">            <span class="keyword">int</span> value = client.division(<span class="number">3</span>, <span class="number">1</span>);</span><br><span class="line">            System.out.println(hello);</span><br><span class="line">            System.out.println(<span class="string">&quot;division value:&quot;</span>+value);</span><br><span class="line">          </span><br><span class="line">          socket.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (TTransportException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (RequestException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (TException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        sendServerRequest();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>先运行服务端，出现提示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start server port 9090 ...</span><br></pre></td></tr></table></figure><p>然后运行客户端，控制台打印出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hello pross</span><br><span class="line">division value:3</span><br></pre></td></tr></table></figure><p>看到了预料之中的结果，Thrift演出毕。</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><p><a href="http://zheming.wang/blog/2014/08/28/94D1F945-40EC-45E4-ABAF-3B32DFFE4043/">Thrift RPC详解</a></p><p><a href="%5Bhttp://diwakergupta.github.io/thrift-missing-guide/thrift.pdf%5D(http://diwakergupta.github.io/thrift-missing-guide/thrift.pdf)">Thrift: The Missing Guide</a></p><p><a href="https://thrift.apache.org/">Apache Thrift</a></p><p>完。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;接着上篇文章说。&lt;/p&gt;
&lt;p&gt;我们知道了Apache Thrift主要用于各个服务之间的RPC通信，并且支持跨语言；包括C++，Java，Python，PHP，Ruby，Go，Node.js等等，还有一些都没听说过的语言；而且从上篇文章的RPC例子中可以发现，Thrift是一个典型的CS（客户端/服务端）架构；加上跨语言的特性，我们可以推断一下：客户端和服务端是可以使用不同的语言开发的。&lt;/p&gt;
&lt;p&gt;如果CS端可以使用不同的语言来开发，那么一定是有一种中间语言来关联客户端和服务端（相同语言也需要关联客户端和服务端）。其实这个答案都知道，那就是接口定义语言：IDL（Interface Description Language）；下面我们从IDL进行开场表演，进行一次Thrift RPC的完整演出。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>HDFS NameNode内存全景</title>
    <link href="https://pross.space/blog/2019/08/23/hdfs-namenode-memory-panorama.html"/>
    <id>https://pross.space/blog/2019/08/23/hdfs-namenode-memory-panorama.html</id>
    <published>2019-08-23T02:55:52.000Z</published>
    <updated>2021-01-30T07:11:56.718Z</updated>
    
    <content type="html"><![CDATA[<p>在HDFS系统架构中，NameNode管理着整个文件系统的元数据，维护整个集群的机架感知信息和DataNode和Block的信息，Lease管理以及集中式缓存引入的缓存管理等等。从整个HDFS系统架构上来看，NameNode是最重要、最复杂也是最容易出现问题的地方。</p><h4 id="NameNode概述"><a href="#NameNode概述" class="headerlink" title="NameNode概述"></a>NameNode概述</h4><p>NameNode管理的HDFS文件系统的元数据分为两个层次：NameSpace管理层，负责管理文件系统中的树状目录结构以及文件与数据块之间的映射关系；块管理层，负责管理文件系统中文件的物理块与实际存储位置的映射关系（BlockMap）。</p><a id="more"></a><p>NameSpace管理的元数据除内存常驻外，也会周期Flush到持久化设备fsimage文件上（core-site.xml中配置<code>hadoop.tmp.dir</code>目录下的dfs/name/current中）；BlockMap元数据只存在于内存中；当NameNode发生重启，首先从持久化设备中读取fsimage，构建NameSpace的元数据信息，之后根据DataNode的汇报信息重新构造BlockMap，这两部分数据是占据NamNode大部分JVM Heap空间。</p><h4 id="NameNode内存结构"><a href="#NameNode内存结构" class="headerlink" title="NameNode内存结构"></a>NameNode内存结构</h4><p><img src="./namenode.png" alt="namenode"></p><p>NameNode常驻内存主要被NameSpace和BlockManager使用，二者使用占比分别接近50%。其它部分内存开销较小且相对固定，与NameSpace和BlockManager相比基本可以忽略。</p><h4 id="NameNode内存分析"><a href="#NameNode内存分析" class="headerlink" title="NameNode内存分析"></a>NameNode内存分析</h4><h5 id="NameSpace"><a href="#NameSpace" class="headerlink" title="NameSpace"></a>NameSpace</h5><p><img src="./namespace.png" alt="namespace"></p><p>HDFS文件系统的目录结构也是按照树状结构维护，NameSpace保存了目录树以及每个目录/文件节点的属性。在整个NameSpace目录树中存在两种不同类型的INode数据结构：<code>INodeDirectory</code>和<code>INodeFile</code>。其中INodeDirectory表示的是目录树中的目录，INodeFile表示的是目录树中的文件。<br><img src="./inode.png" alt="inode"></p><p>INodeDirectory和INodeFile均继承自INode，所以具备大部分相同的公共信息INodeWithAddititionalFields，除常用基础属性外，其中还提供了扩展属性features（如Quota，Snapshot等），如果以后出现新属性也可以通过feature扩展。不同的是，INodeFile特有的标识副本数和数据块大小组合的<code>header</code>（2.61之后新增了标识存储策略ID的信息）以及该文件包含的有序Block的数组；INodeDirectory特有的是列表<code>children</code>，children默认是大小为5的ArrayList类型，按照子节点name有序存储，在插入时会损失一部分写入的性能，但是可以方便后续快速二分查找提高读的性能，对于一般的存储系统，读操作比写操作占比要高。</p><h5 id="BlockManager"><a href="#BlockManager" class="headerlink" title="BlockManager"></a>BlockManager</h5><p>NameNode概述中介绍的负责管理文件系统中文件的物理块与实际存储位置的映射关系（BlockMap）就是由BlockManager来统一管理。NameSpace和BlockMap之间通过前面提到的INodeFile有序Blocks数组关联到一起。<br><img src="./blockinfo.png" alt="blockinfo"></p><p>每一个INodeFile都会包含数量不等的Block，具体数量由文件大小及每一个Block的大小比值决定，这些Block按照所在的文件的先后顺序组成BlockInfo数组，BlockInfo维护的是Block的元数据，数据本身是由DataNode管理，所以BlockInfo需要包含实际数据且由DataNode管理的信息是名为triplets的Object数组，大小为3*replicas（replicas是Block副本数量，默认为3），从图中可以知道，BlockInfo包含了哪些Block，这些Block分别存储在哪些DataNode上。</p><p>如何快速的通过BlockId快速定位到Block，这里还需要BlocksMap。</p><p>BlocksMap底层通过LightWeightGSet实现，本质是一个链式解决冲突的Hash表。事实上，BlocksMap里所有的BlockInfo就是INodeFile中对应BlockInfo的引用，通过Block查找对应BlockInfo时，也是先对Block计算HashCode，根据结果快速定位到对应的BlockInfo信息。</p><p><img src="./blocksMap.png" alt="blocksMap"></p><p>这里还涉及到几个核心的数据结构：excessReplicateMap（多余的副本存放） ，neededReplications（需要补充Block的副本存放处，是一个优先级队列，缺少副本数越多的Block会优先处理），invalidateBlocks（删除的副本存放处） ，corruptReplicas（某些Block不可用暂存处）等。 </p><p>相比Namespace，BlockManager管理的数据要复杂的多。</p><h5 id="NetworkTopology"><a href="#NetworkTopology" class="headerlink" title="NetworkTopology"></a>NetworkTopology</h5><p>Hadoop在设计考虑到数据的安全和高效，默认存放三份副本。存储策略是本地一份，同机架内其他某一个节点上一份，不同机架的某一节点上一份，这样如果本地数据损坏了，节点可以从同一机架内的相邻节点拿到数据，速度肯定比从跨机架节点上拿到的数据要快；为了降低整体的带宽消耗和读取延时时间，HDFS会尽快让读取程序读取离它最近的副本。那么Hadoop确定任意两个节点是位于同一机架还是不同的机架呢？这就需要机架拓扑NetworkTopology，也叫作机架感知。<br>默认情况下，NameNode启动时日志信息是这样的：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2018-05-09 19:27:26,423 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node:  /default-rack/ 192.168.123.102:50010</span><br></pre></td></tr></table></figure><p>每个IP对应的机架ID都是/default-rack，说明Hadoop的机架感知没有被启用。<br><strong>配置机架感知</strong><br>配置机架感知也很简单，NameNode所在的节点中，在<code>core-site.xml</code>文件中配置<code>topology.script.name</code>，value通常是一个shell脚本，该脚本接受一个参数，输出一个值。接受的参数通常为某台DataNode的IP地址，而输出的值通常为该IP地址对应的DataNode所在的rack。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>topology.script.file.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/apps/hadoop-2.6.5/etc/hadoop/topology.sh<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br></pre></td></tr></table></figure><p><code>topology.sh</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span>  </span><br><span class="line">HADOOP_CONF=/home/bigdata/apps/hadoop/etc/hadoop  </span><br><span class="line">while [ $# -gt 0 ] ; do  </span><br><span class="line">  nodeArg=$1  </span><br><span class="line">  exec&lt;$&#123;HADOOP_CONF&#125;/topology.data</span><br><span class="line">  result=&quot;&quot;  </span><br><span class="line">  while read line ; do  </span><br><span class="line">    ar=( $line )  </span><br><span class="line">    if [ &quot;$&#123;ar[0]&#125;&quot; = &quot;$nodeArg&quot; ]||[ &quot;$&#123;ar[1]&#125;&quot; = &quot;$nodeArg&quot; ]; then  </span><br><span class="line">      result=&quot;$&#123;ar[2]&#125;&quot;  </span><br><span class="line">    fi  </span><br><span class="line">  done  </span><br><span class="line">  shift  </span><br><span class="line">  if [ -z &quot;$result&quot; ] ; then  </span><br><span class="line">    echo -n &quot;/default-rack&quot;  </span><br><span class="line">  else  </span><br><span class="line">    echo -n &quot;$result&quot;  </span><br><span class="line">  fi  </span><br><span class="line">  done  </span><br></pre></td></tr></table></figure><p><code>topology.data</code>格式为：节点（IP或主机名） /交换机xx/机架xx</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">192.168.123.102 hadoop02 /switch/rack2</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>配置后，NameNode启动时日志信息是这样的：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2018-05-09 19:27:26,423 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node:  /switch/rack2/ 192.168.123.102:50010</span><br></pre></td></tr></table></figure><p>说明Hadoop的机架感知已经被启用了。查看Hadoop机架信息的命令<code>hadoop dfsadmin -printTopology </code></p><h5 id="LeaseManager"><a href="#LeaseManager" class="headerlink" title="LeaseManager"></a>LeaseManager</h5><p>Lease 机制是重要的分布式协议，广泛应用于各种实际的分布式系统中。HDFS支持Write-Once-Read-Many，对文件写操作的互斥同步靠Lease实现。<br>Lease实际上是时间约束锁，其主要特点是排他性。客户端写文件时需要先申请一个Lease，一旦有客户端持有了某个文件的Lease，其它客户端就不可能再申请到该文件的Lease，这就保证了同一时刻对一个文件的写操作只能发生在一个客户端。<br>NameNode的LeaseManager是Lease机制的核心，维护了文件与Lease、客户端与Lease的对应关系，这类信息会随写数据的变化实时发生对应改变。 </p><blockquote><p>本文是根据<a href="https://tech.meituan.com/namenode.html?_blank">美团点评技术团队中《HDFS NameNode内存全景》</a>整理总结</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;在HDFS系统架构中，NameNode管理着整个文件系统的元数据，维护整个集群的机架感知信息和DataNode和Block的信息，Lease管理以及集中式缓存引入的缓存管理等等。从整个HDFS系统架构上来看，NameNode是最重要、最复杂也是最容易出现问题的地方。&lt;/p&gt;
&lt;h4 id=&quot;NameNode概述&quot;&gt;&lt;a href=&quot;#NameNode概述&quot; class=&quot;headerlink&quot; title=&quot;NameNode概述&quot;&gt;&lt;/a&gt;NameNode概述&lt;/h4&gt;&lt;p&gt;NameNode管理的HDFS文件系统的元数据分为两个层次：NameSpace管理层，负责管理文件系统中的树状目录结构以及文件与数据块之间的映射关系；块管理层，负责管理文件系统中文件的物理块与实际存储位置的映射关系（BlockMap）。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>远程过程调用</title>
    <link href="https://pross.space/blog/2019/08/17/remote-procedure-call.html"/>
    <id>https://pross.space/blog/2019/08/17/remote-procedure-call.html</id>
    <published>2019-08-16T16:13:44.000Z</published>
    <updated>2021-01-30T07:11:57.182Z</updated>
    
    <content type="html"><![CDATA[<p>啊，原本是写一篇Apache Thrift in HiveServer，改写JDBC连接Hive相关应用的推文，因为HiveServer是使用Thrift提供服务创建网络RPC的多种语言客户端；单独拿出来说，使用Thrift也可以轻松构建RPC服务器，是轻量级的跨语言的远程服务调用框架。说到远程过程调用，感觉又要解释很多，所以就先上个前菜，说一说远程过程调用（RPC）；并加了一份佐料：关于JDBC连接Hive的实现。</p><a id="more"></a><h4 id="远程过程调用（RPC）"><a href="#远程过程调用（RPC）" class="headerlink" title="远程过程调用（RPC）"></a>远程过程调用（RPC）</h4><p>照例搬了wiki的解释：</p><blockquote><p>远程过程调用是分布式计算的客户端-服务器（Client/Server）的例子，它简单而又广受欢迎。远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。</p><p>为了允许不同的客户端均能访问服务器，许多标准化的RPC框架应运而生。其中大部分采用接口描述语言（Interface Description Language，IDL），方便跨平台的远程过程调用。</p></blockquote><p>举一个栗子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">()</span></span>&#123;</span><br><span class="line">       String param1 = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">       String param2 = <span class="string">&quot;world&quot;</span>;</span><br><span class="line">       String result = appendStr(param1, param2);</span><br><span class="line">       System.out.println(<span class="string">&quot;result:&quot;</span> + result);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">appendStr</span><span class="params">(String param1,String param2)</span></span>&#123;</span><br><span class="line">       <span class="keyword">return</span> param1+<span class="string">&quot; &quot;</span>+param2;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>这是本地函数调用代码，调用方法和被调用的方法都在一个程序内部，是属于进程内的调用。CPU在执行<code>invoke</code>方法的时候（称为<code>调用方法</code>），会去执行被调用的<code>appendStr</code>这个方法（称为<code>被调用方法</code>），执行完成后，切换回来继续执行后续的代码。对于调用方法而言，执行被调用方法时会阻塞，直到被调用方法执行完毕。画一个简单的过程调用图如下：</p><p><img src="Remote-Procedure-Call%5Clocal.jpg"></p><p>接下来看一下RPC调用（Thrift）的栗子🌰：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">()</span> <span class="keyword">throws</span> TTransportException </span>&#123;</span><br><span class="line">        TCLIService.Client client = getClient(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">8088</span>);</span><br><span class="line">        String param1 = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">        String param2 = <span class="string">&quot;world&quot;</span>;</span><br><span class="line">        String result = client.appendStr(param1, param2);</span><br><span class="line">        System.out.println(<span class="string">&quot;result:&quot;</span> + result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// get thrift client</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> TCLIService.<span class="function">Client <span class="title">getClient</span><span class="params">(String host,<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> TTransportException </span>&#123;</span><br><span class="line">        <span class="comment">// host port timeout</span></span><br><span class="line">        TSocket tSocket = <span class="keyword">new</span> TSocket(host, port,<span class="number">10000</span>);</span><br><span class="line">        TTransport transport = <span class="keyword">new</span> TFramedTransport(tSocket);</span><br><span class="line">        transport.open();</span><br><span class="line">        TProtocol protocol = <span class="keyword">new</span> TBinaryProtocol(transport);</span><br><span class="line">        TCLIService.Client client = <span class="keyword">new</span> TCLIService.Client(protocol);</span><br><span class="line">        <span class="keyword">return</span>  client;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这是一个进程间的调用，调用方法和被调用方法不在一个进程，甚至不是相同的服务，或者不同的服务器。进程之间的调用需要通过网络来传输数据，调用方法在执行RPC调用时会阻塞知道调用结果返回结果菜继续执行后续代码。过程调用图如下：</p><p><img src="Remote-Procedure-Call%5Crpc.jpg"></p><p>总结：RPC是一种通过网络从远程计算机程序上请求服务的方法。</p><h4 id="延伸：Apache-Thrift在JDBC的应用"><a href="#延伸：Apache-Thrift在JDBC的应用" class="headerlink" title="延伸：Apache Thrift在JDBC的应用"></a>延伸：Apache Thrift在JDBC的应用</h4><p>一般来说，JDBC连接数据源开发的步骤：加载驱动类-&gt;创建数据库连接-&gt;创建statement-&gt;执行SQL语句-&gt;处理结果。前段时间研究的JDBC连接Hive数据源，底层也是采用Thrift（源码在：org.apache.hive.jdbc）。前面初始化的连接会得到<code>TCLIService.Iface client</code>和 <code>TSessionHandle sessionHandle</code>。具体的执行<code>execute(String sql)</code>代码如下，我分为三步：检查是否满足执行SQL的条件，初始化查询条件并异步执行SQL，等待执行得到结果。</p><p><strong>检查条件</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">execute</span><span class="params">(String sql)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">       <span class="comment">// statement是否被关闭，如果关闭报SQLException：Can&#x27;t execute after statement has been closed</span></span><br><span class="line">    checkConnection(<span class="string">&quot;execute&quot;</span>);</span><br><span class="line">    <span class="comment">// 如果stmtHandle不为空，则关闭stmtHandle</span></span><br><span class="line">    closeClientOperation();</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始话标志状态</span></span><br><span class="line"><span class="comment">     * 如是否已经取消执行(isCancelled)=false，sql语句查询是否关闭(isQueryClosed)=false</span></span><br><span class="line"><span class="comment">     * 是否生成查询日志(isLogBeingGenerated)=true，sql是否已经提交执行(isExecuteStatementFailed)=false</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    initFlags();</span><br><span class="line">   </span><br><span class="line">    ...</span><br><span class="line">      </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p><strong>初始化查询条件并执行SQL</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">execute</span><span class="params">(String sql)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">      </span><br><span class="line"><span class="comment">// 初始话 statement request，可以维持sessionhandle，添加sql执行</span></span><br><span class="line">    TExecuteStatementReq execReq = <span class="keyword">new</span> TExecuteStatementReq(sessHandle, sql);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置异步执行</span></span><br><span class="line">    execReq.setRunAsync(<span class="keyword">true</span>);</span><br><span class="line">    execReq.setConfOverlay(sessConf);</span><br><span class="line">    <span class="comment">//获取reentrant lock，同一个时间点只能被一个线程锁持有，确保提交执行唯一</span></span><br><span class="line">    transportLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// client执行SQL</span></span><br><span class="line">      TExecuteStatementResp execResp = client.ExecuteStatement(execReq);</span><br><span class="line">      <span class="comment">// 验证是否成功提交</span></span><br><span class="line">      Utils.verifySuccessWithInfo(execResp.getStatus());</span><br><span class="line">      <span class="comment">// execResp 获取OperationHandle</span></span><br><span class="line">      stmtHandle = execResp.getOperationHandle();</span><br><span class="line">      <span class="comment">// 正常执行-&gt;改变sql是否已经提交执行的状态为false </span></span><br><span class="line">      isExecuteStatementFailed = <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (SQLException eS) &#123;</span><br><span class="line">      <span class="comment">// 异常执行：改变sql是否已经提交执行的状态为true</span></span><br><span class="line">      isExecuteStatementFailed = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">throw</span> eS;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">      isExecuteStatementFailed = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> SQLException(ex.toString(), <span class="string">&quot;08S01&quot;</span>, ex);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="comment">// 异常退出：释放锁区域代码</span></span><br><span class="line">      transportLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p><strong>等待执行得到结果</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">execute</span><span class="params">(String sql)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">      </span><br><span class="line"><span class="comment">// 正常执行 拿到状态handle</span></span><br><span class="line">    TGetOperationStatusReq statusReq = <span class="keyword">new</span> TGetOperationStatusReq(stmtHandle);</span><br><span class="line">    <span class="comment">// 操作是否完成的状态，初始化状态false</span></span><br><span class="line">    <span class="keyword">boolean</span> operationComplete = <span class="keyword">false</span>;</span><br><span class="line">    TGetOperationStatusResp statusResp;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// while循环，通过操作是否完成的状态，手动维护一个阻塞队列，如果执行完成则退出</span></span><br><span class="line">    <span class="keyword">while</span> (!operationComplete) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 获取reentrant lock，确保执行过程状态</span></span><br><span class="line">        transportLock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">// 拿到执行状态</span></span><br><span class="line">          statusResp = client.GetOperationStatus(statusReq);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          <span class="comment">// 释放锁</span></span><br><span class="line">          transportLock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        Utils.verifySuccessWithInfo(statusResp.getStatus());</span><br><span class="line">        <span class="comment">// 获取状态，做出相应的回应</span></span><br><span class="line">        <span class="keyword">if</span> (statusResp.isSetOperationState()) &#123;</span><br><span class="line">          <span class="keyword">switch</span> (statusResp.getOperationState()) &#123;</span><br><span class="line">          <span class="keyword">case</span> CLOSED_STATE:</span><br><span class="line">          <span class="comment">// 执行完成，改变状态，退出while循环</span></span><br><span class="line">          <span class="keyword">case</span> FINISHED_STATE:</span><br><span class="line">            operationComplete = <span class="keyword">true</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          <span class="comment">// 执行取消</span></span><br><span class="line">          <span class="keyword">case</span> CANCELED_STATE:</span><br><span class="line">            <span class="comment">// 01000 -&gt; warning</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> SQLException(<span class="string">&quot;Query was cancelled&quot;</span>, <span class="string">&quot;01000&quot;</span>);</span><br><span class="line">          <span class="comment">// 错误状态</span></span><br><span class="line">          <span class="keyword">case</span> ERROR_STATE:</span><br><span class="line">            <span class="comment">// Get the error details from the underlying exception</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> SQLException(statusResp.getErrorMessage(),</span><br><span class="line">                statusResp.getSqlState(), statusResp.getErrorCode());</span><br><span class="line">          <span class="comment">// 未知错误状态</span></span><br><span class="line">          <span class="keyword">case</span> UKNOWN_STATE:</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> SQLException(<span class="string">&quot;Unknown query&quot;</span>, <span class="string">&quot;HY000&quot;</span>);</span><br><span class="line">          <span class="comment">// 正在初始化，正在pending，正在运行（退出switch循环），继续while循环</span></span><br><span class="line">          <span class="keyword">case</span> INITIALIZED_STATE:</span><br><span class="line">          <span class="keyword">case</span> PENDING_STATE:</span><br><span class="line">          <span class="keyword">case</span> RUNNING_STATE:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">        <span class="comment">// 执行过程中异常，获取执行日志false</span></span><br><span class="line">        isLogBeingGenerated = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="comment">// 执行过程中异常，获取执行日志false</span></span><br><span class="line">        isLogBeingGenerated = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> SQLException(e.toString(), <span class="string">&quot;08S01&quot;</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 执行完成，获取执行日志false</span></span><br><span class="line">    isLogBeingGenerated = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 流程到这里，说明已经执行完成，可以拿到结果，没有结果返回false</span></span><br><span class="line">    <span class="keyword">if</span> (!stmtHandle.isHasResultSet()) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 有结果，获取结果，并封装成ResultSet全局变量</span></span><br><span class="line">    resultSet =  <span class="keyword">new</span> HiveQueryResultSet.Builder(<span class="keyword">this</span>).setClient(client).setSessionHandle(sessHandle)</span><br><span class="line">        .setStmtHandle(stmtHandle).setMaxRows(maxRows).setFetchSize(fetchSize)</span><br><span class="line">        .setScrollable(isScrollableResultset).setTransportLock(transportLock)</span><br><span class="line">        .build();</span><br><span class="line">    <span class="comment">// 有结果，返回ture</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>以上就是JDBC连接Hive数据源，并执行SQL的代码。但是，如果想要一个会话窗口维持一个Session设置，如设置执行队列，设置Job Name等，采用JDBC方式是不可取的。所以我们可以将Thrift底层从JDBC剥离出来，把初始化过程中的<code>TSessionHandle sessionHandle</code>暴露，自己手动维护起来就可以了。</p><p>完。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;啊，原本是写一篇Apache Thrift in HiveServer，改写JDBC连接Hive相关应用的推文，因为HiveServer是使用Thrift提供服务创建网络RPC的多种语言客户端；单独拿出来说，使用Thrift也可以轻松构建RPC服务器，是轻量级的跨语言的远程服务调用框架。说到远程过程调用，感觉又要解释很多，所以就先上个前菜，说一说远程过程调用（RPC）；并加了一份佐料：关于JDBC连接Hive的实现。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>理解Spark核心之RDD</title>
    <link href="https://pross.space/blog/2019/05/29/understand-the-rdd-at-core-of-spark.html"/>
    <id>https://pross.space/blog/2019/05/29/understand-the-rdd-at-core-of-spark.html</id>
    <published>2019-05-29T09:04:41.000Z</published>
    <updated>2021-01-30T07:11:57.301Z</updated>
    
    <content type="html"><![CDATA[<p>Spark是围绕RDD的概念展开的，RDD是可以并行操作的容错元素集合。RDD全称是Resilient Distributed Datasets（弹性分布式数据集）</p><h4 id="理解RDD"><a href="#理解RDD" class="headerlink" title="理解RDD"></a>理解RDD</h4><p>如果你在Spark集群中加载了一个很大的文本数据，Spark就会将该文本抽象为一个RDD，这个RDD根据你定义的分区策略（比如HashKey）可以分为数个Partition，这样就可以对各个分区进行并行处理，从而提高效率。</p><p>RDD是一个容错的，并行的数据结构，可以让用户显示地将数据存储到磁盘和内存中，并能控制数据的分区。同时，RDD还提供了一组丰富的操作来操作这些数据。在这些操作中，比如Map、flatMap、filter等转换操作实现了monad模式（Monad是一种设计模式，表示将一个运算过程，通过函数拆解成互相连接的多个步骤；你只要提供下一步运算所需的函数，整个运算就会自动进行下去。），很好的切合了Scala的集合操作。另外，RDD还提供了比如join，groupBy，reduceByKey（action操作）等更为方便的操作，用来支持常见的数据运算。</p><p>RDD是一系列只读分区的集合，它只能从文件中读取并创建，或者从旧的RDD生成新的RDD。RDD的每一次变换操作都会生成新的RDD，而不是在原来的基础上进行修改，这种粗粒度的数据操作方式为RDD带来了容错和数据共享方面的优势，但是在面对大数据集中频繁的小操作的时候，显得效率比较低下。</p><a id="more"></a><h4 id="RDD原理"><a href="#RDD原理" class="headerlink" title="RDD原理"></a>RDD原理</h4><p>RDD实际上是一个类（sc.textFile()方法返回一个RDD对象，然后用line接收这个对象），而这个RDD类中也定义了一系列的用于操作的方法，也就是一些算子操作。</p><p>这个类为了实现对数据的操作，里面有分区信息，用于记录特定RDD的分区情况；依赖关系，指向其父RDD；一个函数，用于记录父RDD到自己的转换操作；划分策略和数据位置的元数据。在DAG中这样的RDD就可以看成一个个节点，RDD中的存储的依赖关系就是DAG的边。在Spark中，数据在物理上被划分为一个个的block，这些block由blockmanager统一管理的。</p><p>在设计RDD之间的依赖关系时，设计者将RDD之间的依赖关系分为两类：窄依赖和宽依赖。RDD作为数据结构，本质上是一个只读的分区记录集合。一个RDD可以包含多个分区，每个分区就是一个DataSet片段。RDD可以相互依赖，如果RDD的每个分区最多只能被一个Child RDD的一个分区使用，则称之位narrow dependency（窄依赖）；若多个Child RDD分区都可以依赖，则称为wide dependency（宽依赖），而join操作则会产生wide dependency。</p><p><img src="./narrowAndwide.jpg" alt="narrow和wide"></p><p><img src="./rdd-dependencies.png" alt="narrow和wide的区别"></p><blockquote><p>Spark之所以将依赖分为narrow与wide，基于以下两点原因：</p><p>narrow dependecies可以支持在同一个cluster node上，并且以管道形式执行多行命令，例如在执行了map操作后，紧接着执行filter。相反，wide dependencies需要所有的父分区都是可用的，可能还需要调用类似MapReduce之类的操作进行跨节点传递。</p><p>其次从失败恢复的角度考虑，narrow dependencies的失败恢复更有效，因为它只需要重新计算丢失的parent partition即可，而且可以并行的在不同节点进行重计算。而wide dependencies牵涉到RDD各级的多个parent partitions。</p></blockquote><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>RDD是Spark的核心，也是整个Spark架构的基础，特性总结如下：</p><ul><li>不变的数据结构存储</li><li>支持跨集群的分布式数据结构</li><li>可以根据数据记录的Key对结构进行分区</li><li>提供了粗粒度的操作，且这些操作支持分区</li><li>它将数据存储在内存中，从而提供了低延迟性</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;Spark是围绕RDD的概念展开的，RDD是可以并行操作的容错元素集合。RDD全称是Resilient Distributed Datasets（弹性分布式数据集）&lt;/p&gt;
&lt;h4 id=&quot;理解RDD&quot;&gt;&lt;a href=&quot;#理解RDD&quot; class=&quot;headerlink&quot; title=&quot;理解RDD&quot;&gt;&lt;/a&gt;理解RDD&lt;/h4&gt;&lt;p&gt;如果你在Spark集群中加载了一个很大的文本数据，Spark就会将该文本抽象为一个RDD，这个RDD根据你定义的分区策略（比如HashKey）可以分为数个Partition，这样就可以对各个分区进行并行处理，从而提高效率。&lt;/p&gt;
&lt;p&gt;RDD是一个容错的，并行的数据结构，可以让用户显示地将数据存储到磁盘和内存中，并能控制数据的分区。同时，RDD还提供了一组丰富的操作来操作这些数据。在这些操作中，比如Map、flatMap、filter等转换操作实现了monad模式（Monad是一种设计模式，表示将一个运算过程，通过函数拆解成互相连接的多个步骤；你只要提供下一步运算所需的函数，整个运算就会自动进行下去。），很好的切合了Scala的集合操作。另外，RDD还提供了比如join，groupBy，reduceByKey（action操作）等更为方便的操作，用来支持常见的数据运算。&lt;/p&gt;
&lt;p&gt;RDD是一系列只读分区的集合，它只能从文件中读取并创建，或者从旧的RDD生成新的RDD。RDD的每一次变换操作都会生成新的RDD，而不是在原来的基础上进行修改，这种粗粒度的数据操作方式为RDD带来了容错和数据共享方面的优势，但是在面对大数据集中频繁的小操作的时候，显得效率比较低下。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>Spark的运行模式</title>
    <link href="https://pross.space/blog/2019/03/15/spark-operating-mode.html"/>
    <id>https://pross.space/blog/2019/03/15/spark-operating-mode.html</id>
    <published>2019-03-15T12:56:12.000Z</published>
    <updated>2021-01-30T07:11:57.011Z</updated>
    
    <content type="html"><![CDATA[<p>Spark是新一代基于内存的计算框架，是用于大规模数据处理的同意分析引擎。相比于Hadoop MapReduce计算框架，Spark将中间计算结果保留在内存中，速度提升10~100倍；同时采用弹性分布式数据集（RDD）实现迭代计算，更好的适用于数据挖掘、机器学习，极大的提升开发效率。</p><p>Spark的运行模式，它不仅支持单机模式，同时支持集群模式运行；这里具体的总结一下Spark的各种运行模式的区分。</p><h4 id="Local模式"><a href="#Local模式" class="headerlink" title="Local模式"></a>Local模式</h4><p>Local模式又称本地模式，通过Local模式运行非常简单，只需要把Spark的安装包解压后，改一些常用的配置即可使用，而不用启动Spark的Master、Worker进程（只有集群的Standalone模式运行时，才需要这两个角色），也不用启动Hadoop的服务，除非你需要用到HDFS。</p><a id="more"></a><p><strong>运行实例</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master local[2] \</span><br><span class="line">lib/spark-examples-1.0.0-hadoop2.2.0.jar  \</span><br><span class="line">100</span><br><span class="line"></span><br><span class="line"># 1）--master local 就可以确定是单机的local模式了，[2]意思是分配2个cores运行</span><br><span class="line"># 2）--lib/spark-examples-1.0.0-hadoop2.2.0.jar：jar包的路径（application-jar）</span><br><span class="line"># 3）--100：传递给主类的主要方法的可选参数（application-arguments）</span><br></pre></td></tr></table></figure><p>这里的spark-submit进程既是客户端提交任务的Client进程，又是Spark的Driver程序，还充当着Spark执行Task的Executor角色。所有的程序都运行在一个JVM中，主要用于开发时测试。</p><h4 id="本地伪集群运行模式（单机模拟集群）"><a href="#本地伪集群运行模式（单机模拟集群）" class="headerlink" title="本地伪集群运行模式（单机模拟集群）"></a>本地伪集群运行模式（单机模拟集群）</h4><p>这种模式，和Local[N]很像，不同的是它会在单机的环境下启动多个进程来模拟集群下的分布式场景，而不像Local[N]这种多个线程只能在一个进程下委曲求全的共享资源。通常也是用来验证开发出来的应用程序逻辑上有没有出现问题，或者想使用Spark计算框架而没有太多资源的情况下。</p><p><strong>运行实例</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">--master local-cluster[2,3,1024]</span><br><span class="line"></span><br><span class="line"># --master local-cluster[2,3,1024]：在本地模拟集群下使用2个Executor进程，每个进程分配3个cores和1024M的内存来运行程序</span><br></pre></td></tr></table></figure><p>这里的spark-submit依然充当全能角色，又是Client进程，又是Driver程序，也负责资源管理。运行该模式很简单，只需要把Spark安装包解压后，修改一些常用的配置，不用启动Spark的Master、Worker守护进程，也不用启动Hadoop的服务，除非你是需要用到HDFS。</p><h4 id="Standalone模式（集群）"><a href="#Standalone模式（集群）" class="headerlink" title="Standalone模式（集群）"></a>Standalone模式（集群）</h4><p>Standalone是集群模式，这里就需要在执行应用程序前，先启动Spark的Master和Worker守护进程，不用启动Hadoop的服务，除非你需要使用HDFS。</p><p><strong>运行实例</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master spark://207.184.161.138:7077 \</span><br><span class="line">  --executor-memory 8G \</span><br><span class="line">  --total-executor-cores 10 \</span><br><span class="line">  /path/to/examples.jar \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"># 1) --master spark://207.184.161.138:7077:采用Standalone模式运行，后面是集群地址和端口</span><br><span class="line"># 2) --executor-memory 20G:配置executor进程内存为8G</span><br><span class="line"># 3）--total-executor-cores 100：配置cores数为10个</span><br></pre></td></tr></table></figure><p>Master进程作为cluster manager，用来对应用程序申请的资源进行管理；spark-submit做为Client端和运行Driver程序。Standalone模式是Spark实现的资源调度框架，其主要的节点有Client节点，Master节点和Worker节点。其中Driver既可以运行在Master节点上，也可以运行在本地的Client端。</p><p>当用spark-shell交互式工具提交Spark的Job时，Driver在Master节点上运行；当使用spark-submit工具提交Job或者在Eclipse、IDEA等开发平台上使用<code>new SparkConf.setManager(&quot;spark://master:7077&quot;)</code>方式运行Spark任务时，Driver是运行在本地Client端上的。 </p><p><strong>运行流程</strong></p><ul><li>SparkContext连接到Master，向Master注册并申请资源（CPU Core和Memory）</li><li>Master根据SparkContext的资源申请要求和Worker心跳周期内报告的信息决定在哪个Worker上分配资源，然后在该Worker上获取资源，然后启动StandaloneExecutorBackend</li><li>StandaloneExecutorBackend向SparkContext注册</li><li>SparkContext将Application代码发给StandaloneExecutorBackend；并且SparkContext解析Application代码，构建DAG图，提交给DAG Scheduler分解成Stage（当碰到Action操作时，就会产生Job；每个Job中含有一个或多个Stage，Stage一般在获取外部数据和shuffle之前产生），然后Stage（又称为TaskSet）提交Task Scheduler，负责将Task分配到相应的Worker，最后提交给StandaloneExecutorBackend执行</li><li>StandaloneExecutorBackend会构建Executor线程池，开始执行Task，并向SparkContext报告，直至Task完成</li><li>所有Task完成后，SparkContext向Master注销，释放资源</li></ul><h4 id="on-yarn-client模式（集群）"><a href="#on-yarn-client模式（集群）" class="headerlink" title="on yarn client模式（集群）"></a>on yarn client模式（集群）</h4><p>越来越多的场景，都是Spark跑在Hadoop集群中，所以为了做到资源能够均衡调度，会使用YARN来做为Spark的Cluster Manager，来为Spark的应用程序分配资源。</p><p><strong>运行实例</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode client \</span><br><span class="line">lib/spark-examples-1.0.0-hadoop2.2.0.jar </span><br><span class="line"></span><br><span class="line"># 1) --master yarn：采用yarn进行资源调度</span><br><span class="line"># 2) --deploy-mode client：client环境运行</span><br></pre></td></tr></table></figure><p>在执行Spark应用程序前，要启动Hadoop的各种服务，由于已经有了资源管理器，所以不需要启动Spark的Master，Worker守护进程。</p><p><strong>运行流程</strong></p><ul><li>Spark Yarn Client向Yarn的ResourceManager申请启动Application Master，同时在SparkContext初始化中创建DAG Scheduler和Task Scheduler，由于我们选择是Yarn Client模式，程序会选择启动YarnClientClusterScheduler和YarnClientSchedulerBackend</li><li>ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster；与YarnCluster区别是在该ApplicationMaster中不运行SparkContext，只与SparkContext进行联系进行资源的分配</li><li>Client中的SparkContext初始化完成后，与ApplicationMaster建立通讯，向ResourceManager注册，根据任务信息向ResourceManager申请资源（Container）</li><li>一旦ApplicationMaster申请到资源（也就是Container）后，便于对应的NodeManager通信，要求它在获得的Container中开始向SparkContext注册并申请执行Task任务</li><li>Client中的SparkContext分配给Container的Task开始执行，并向Driver汇报运行的状态和进度，让Client随时掌握各个任务的运行状态，从而可以在任务失败时重启任务</li><li>应用程序完成后，Client的SparkContext向ResourceManager申请注销并关闭自己</li></ul><h4 id="on-yarn-cluster模式（集群）"><a href="#on-yarn-cluster模式（集群）" class="headerlink" title="on yarn cluster模式（集群）"></a>on yarn cluster模式（集群）</h4><p><strong>运行实例</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--driver-memory 4g \</span><br><span class="line">--executor-memory 2g \</span><br><span class="line">--executor-cores 1 \</span><br><span class="line">examples/jars/spark-examples*.jar \</span><br><span class="line">10</span><br><span class="line"></span><br><span class="line"># --driver-memory 4g：集群模式下Yarn Application Master的内存大小</span><br></pre></td></tr></table></figure><p><strong>运行流程</strong></p><ul><li>SparkYarnClient向YARN中ResourceManager提交应用程序，包括ApplicationMaster程序、启动ApplicationMaster的命令、需要在Executor中运行的程序</li><li>ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，其中ApplicationMaster中进行SparkContext的初始化</li><li>ApplicationMaster向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将采用轮询的方式通过RPC协议为各个任务申请资源，并监控它们的运行状态直到运行结束</li><li>一旦ApplicationMaster申请到资源（也就是Container）后，便于对应的NodeManager通信，要求它在获得的Container中开始向SparkContext注册并申请执行Task任务</li><li>SparkContext分配给Container的Task开始执行，并向Driver汇报运行的状态和进度，让Client随时掌握各个任务的运行状态，从而可以在任务失败时重启任务</li><li>应用程序运行完成后，ApplicationMaster向ResourceManager申请注销并关闭自己</li></ul><h4 id="Mesos模式"><a href="#Mesos模式" class="headerlink" title="Mesos模式"></a>Mesos模式</h4><p>Mesos是Apache下的开源分布式资源管理框架，它被称为是分布式系统的内核。Mesos最初是由加州大学伯克利分校的AMPLab开发的，后在Twitter得到广泛使用。Apache Mesos是一个通用的集群管理器，起源于 Google 的数据中心资源管理系统Borg。</p><p>Mesos模式接触较少，这里不作为展开。</p><h4 id="Kubernetes模式（K8S）"><a href="#Kubernetes模式（K8S）" class="headerlink" title="Kubernetes模式（K8S）"></a>Kubernetes模式（K8S）</h4><p>Kubernetes调度器目前是实验性的。在未来的版本中，可能会出现配置，容器图像和入口点的行为变化。 （Spark2.3.0）</p><p>Kubernetes模式接触较少，这里不作为展开。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Spark是新一代基于内存的计算框架，是用于大规模数据处理的同意分析引擎。相比于Hadoop MapReduce计算框架，Spark将中间计算结果保留在内存中，速度提升10~100倍；同时采用弹性分布式数据集（RDD）实现迭代计算，更好的适用于数据挖掘、机器学习，极大的提升开发效率。&lt;/p&gt;
&lt;p&gt;Spark的运行模式，它不仅支持单机模式，同时支持集群模式运行；这里具体的总结一下Spark的各种运行模式的区分。&lt;/p&gt;
&lt;h4 id=&quot;Local模式&quot;&gt;&lt;a href=&quot;#Local模式&quot; class=&quot;headerlink&quot; title=&quot;Local模式&quot;&gt;&lt;/a&gt;Local模式&lt;/h4&gt;&lt;p&gt;Local模式又称本地模式，通过Local模式运行非常简单，只需要把Spark的安装包解压后，改一些常用的配置即可使用，而不用启动Spark的Master、Worker进程（只有集群的Standalone模式运行时，才需要这两个角色），也不用启动Hadoop的服务，除非你需要用到HDFS。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Spark" scheme="https://pross.space/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>使用Swagger2构建RESTful API</title>
    <link href="https://pross.space/blog/2019/02/02/use-swagger2-to-build-a-restful-api.html"/>
    <id>https://pross.space/blog/2019/02/02/use-swagger2-to-build-a-restful-api.html</id>
    <published>2019-02-01T17:00:44.000Z</published>
    <updated>2021-01-30T07:11:56.885Z</updated>
    
    <content type="html"><![CDATA[<p>吐槽了一阵公司提供的记录接口文档工具后，抽个空档时间搭了个RESTful风格的API文档Demo，感觉还不错，在这里记录一下，技术栈使用Spring Boot+Swagger2。</p><p>Swagger可以很轻松的整合到Spring Boot中，在代码里根据swagger语法打些标签，生成可预览的Api文档，减少了很多时间写API接口文档上，让维护文档和修改代码整合一体了，并且可以与Spring MVC程序配合组织出强大RESTful API文档，也能提供了强大的页面测试功能来调试测试每个接口。</p><a id="more"></a><p>![](使用Swagger2构建RESTful-API\使用Swagger2构建RESTful API.jpg)</p><p>下面分步骤走一遍，简单记录一下。</p><h4 id="创建Spring-Boot项目，添加Swagger2依赖"><a href="#创建Spring-Boot项目，添加Swagger2依赖" class="headerlink" title="创建Spring Boot项目，添加Swagger2依赖"></a>创建Spring Boot项目，添加Swagger2依赖</h4><p>在IDEA中创建Spring Boot项目，记得依赖勾选<code>web</code>，项目是由<code>maven</code>管理，在<code>pom.xml</code>文件中添加依赖：springfox-swagger2和spring-swagger-ui，版本这里选择的2.5.0。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">&lt;!-- springfox swagger --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger2<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- swagger-ui --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger-ui<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="创建Swagger2配置类"><a href="#创建Swagger2配置类" class="headerlink" title="创建Swagger2配置类"></a>创建Swagger2配置类</h4><p>在Application.java同级创建Swagger2的配置类Swagger2Config。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 通过`<span class="doctag">@Configuration</span>`注解，让Spring来加载该类配置</span></span><br><span class="line"><span class="comment"> * 通过`<span class="doctag">@EnableSwagger</span>2`注解来启用Swagger</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableSwagger2</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Swagger2Config</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * createRestApi函数创建Docket的Bean</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean(&quot;welcome&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Docket <span class="title">createRestApi</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Docket(DocumentationType.SWAGGER_2)</span><br><span class="line">                .apiInfo(apiInfo())</span><br><span class="line">                <span class="comment">// 指定模块区分</span></span><br><span class="line">                .groupName(<span class="string">&quot;欢迎模块&quot;</span>)</span><br><span class="line">                <span class="comment">// select()函数返回一个ApiSelectorBuilder实例用来控制哪些接口暴露给Swagger-ui来展现</span></span><br><span class="line">                .select()</span><br><span class="line">                <span class="comment">// 采用指定扫描的包路径来定义，Swagger2会扫描该包下所有Controller定义的API，并产生文档内容</span></span><br><span class="line">                <span class="comment">// 除了被@ApiIgnore指定的请求外</span></span><br><span class="line">                .apis(RequestHandlerSelectors.basePackage(<span class="string">&quot;com.space.controller&quot;</span>))</span><br><span class="line">                .paths(PathSelectors.any())</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * apiInfo创建该Api的基本信息（这些基本信息会展现在文档页面中）</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> ApiInfo <span class="title">apiInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ApiInfoBuilder()</span><br><span class="line">                .title(<span class="string">&quot;Spring Boot中使用Swagger2构建RESTful APIs&quot;</span>)</span><br><span class="line">                .description(<span class="string">&quot;这是一个Demo项目&quot;</span>)</span><br><span class="line">                .termsOfServiceUrl(<span class="string">&quot;http://localhost:9999/swagger-ui.html&quot;</span>)</span><br><span class="line">                .contact(<span class="keyword">new</span> Contact(<span class="string">&quot;pross&quot;</span>,<span class="string">&quot;https://pross.space&quot;</span>,<span class="string">&quot;&quot;</span>))</span><br><span class="line">                .version(<span class="string">&quot;1.0&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="在代码中添加文档内容"><a href="#在代码中添加文档内容" class="headerlink" title="在代码中添加文档内容"></a>在代码中添加文档内容</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/welcome&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过@ApiOperation注解来给API增加说明</span></span><br><span class="line">    <span class="meta">@ApiOperation(value = &quot;第一个接口&quot;,notes = &quot;欢迎语&quot;)</span></span><br><span class="line">    <span class="comment">// 通过@ApiImplicitParams、@ApiImplicitParam注解来给参数增加说明。</span></span><br><span class="line">    <span class="meta">@ApiImplicitParam(name = &quot;name&quot;,value = &quot;姓名&quot;,required = true,dataType = &quot;String&quot;, paramType = &quot;query&quot;)</span></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;/hello&quot;,method = RequestMethod.GET)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">(<span class="meta">@RequestParam(name=&quot;name&quot;,defaultValue = &quot;pross&quot;)</span> String name)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;hello &quot;</span>+name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过@ApiOperation注解来给API增加说明</span></span><br><span class="line">    <span class="meta">@ApiOperation(value = &quot;第二个接口&quot;,notes = &quot;欢迎语2&quot;)</span></span><br><span class="line">    <span class="comment">// 通过@ApiImplicitParams注解来给参数增加说明</span></span><br><span class="line">    <span class="meta">@ApiImplicitParams(&#123;</span></span><br><span class="line"><span class="meta">            @ApiImplicitParam(name = &quot;name1&quot;,value = &quot;姓名1&quot;,required = true,dataType = &quot;String&quot;,paramType = &quot;query&quot;),</span></span><br><span class="line"><span class="meta">            @ApiImplicitParam(name = &quot;name2&quot;,value = &quot;姓名2&quot;,required = true,dataType = &quot;String&quot;,paramType = &quot;query&quot;)</span></span><br><span class="line"><span class="meta">    &#125;)</span></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;/hello2&quot;,method = RequestMethod.POST)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">hello2</span><span class="params">(<span class="meta">@RequestParam(name=&quot;name1&quot;,defaultValue = &quot;pross1&quot;)</span> String name1,</span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="meta">@RequestParam(name=&quot;name2&quot;,defaultValue = &quot;pross2&quot;)</span> String name2)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;hello &quot;</span>+name1+<span class="string">&quot; and &quot;</span>+name2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里踩了一个坑，关于paramType参数的设置，这个属性是指定参数放的位置的。接口使用<code>@RequestParam</code>获取参数的话需要指定<code>paramType = &quot;query&quot;</code>。接口使用<code>@PathVariable</code>获取，需指定<code>paramType=path</code>。如果<code>POST</code>请求，则包装的实体类需要<code>@ApiModel</code>注解，字段需要<code>@ApiModelProperty</code>注解。</p><p>完成上述步骤上，启动Spring Boot程序，访问<code>http://localhost:8080/swagger-ui.html</code>（自动替换端口），就能看到文章开头展示的RESTful API的页面。我们可以再点开具体的API请求，看到我们定义的各种API信息。</p><h4 id="API文档访问与调试"><a href="#API文档访问与调试" class="headerlink" title="API文档访问与调试"></a>API文档访问与调试</h4><p>Swagger除了查看接口功能外，还提供了调试测试功能，我们可以在上图定义的白色空白出填写传入的name值即可，点击下方<code>Try it out！</code>按钮，即可完成了一次请求调用！</p><p>完。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;吐槽了一阵公司提供的记录接口文档工具后，抽个空档时间搭了个RESTful风格的API文档Demo，感觉还不错，在这里记录一下，技术栈使用Spring Boot+Swagger2。&lt;/p&gt;
&lt;p&gt;Swagger可以很轻松的整合到Spring Boot中，在代码里根据swagger语法打些标签，生成可预览的Api文档，减少了很多时间写API接口文档上，让维护文档和修改代码整合一体了，并且可以与Spring MVC程序配合组织出强大RESTful API文档，也能提供了强大的页面测试功能来调试测试每个接口。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>散列表</title>
    <link href="https://pross.space/blog/2019/01/13/hash-table.html"/>
    <id>https://pross.space/blog/2019/01/13/hash-table.html</id>
    <published>2019-01-13T14:55:23.000Z</published>
    <updated>2021-01-30T07:11:56.932Z</updated>
    
    <content type="html"><![CDATA[<p>关于算法系列，在前面已经整理过大O表示法和排序算法相关的文章，今天接着上次的话说一说散列表（Hash Table，也叫哈希表），顺便穿插和另外两种基本的数据结构，数组和链表比较；并在最后介绍良好的散列函数——SHA函数的使用。这三种基本数据结构，可简可繁，在写代码时候都是比较频繁使用的，那我们先从散列表开始入手。</p><p>散列表是根据键（Key）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做<code>散列函数</code>，存放记录的数组称做<code>散列表</code>。散列表是最有用的基本数据结构之一，我们需要总结散列表：实现、冲突和散列函数。</p><a id="more"></a><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p>举个例子：为了查找电话薄中某人的号码，可以创建一个按照人名首字母顺序排列的表，即建立人名<code>x</code>到首字母<code>F(x)</code>的一个函数关系。在首字母为p的表中查找姓”彭”的电话号码，那么就可以直接调用这样的函数关系，查找的就快很多。这里使用人名作为了关键字，也就是键（Key）；”取首字母”是这个例子中散列函数的函数法则<code>F()</code>，存放首字母的表对应<code>散列表</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用dict创建散列表phone_list</span></span><br><span class="line">In [<span class="number">1</span>]: phone_list = <span class="built_in">dict</span>()</span><br><span class="line">In [<span class="number">2</span>]: phone_list[<span class="string">&quot;pross&quot;</span>] = <span class="number">15013637180</span></span><br><span class="line"><span class="comment"># 映射关系输出</span></span><br><span class="line">In [<span class="number">3</span>]: print(phone_list[<span class="string">&quot;pross&quot;</span>])</span><br><span class="line"><span class="number">15013637180</span></span><br></pre></td></tr></table></figure><p>在代码中，散列表是由键和值组成，在散列表<code>phone_list</code>中，键为姓名，值为电话号码。散列表将键映射到值。为了对比性能，我们先介绍下数组。</p><h5 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h5><p>在计算机科学中，<code>数据数据结构(array date structure)</code>，简称为数组；是由相同类型的元素的集合所组成的数据结构，分配一块<code>连续的内存</code>来存储，可以利用元素的索引可以计算出该元素对应的存储地址。</p><p>还是举个例子：现在有个需求，要编写一个管理待办事项的应用程序，需要将这些待办事项存储在内存中，如果我们选用数组来存储，那么意味着所有的待办事项在内存中都是相连的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义数组</span></span><br><span class="line">In [<span class="number">7</span>]: do_list_tup = ()</span><br><span class="line">In [<span class="number">8</span>]: do_list_tup = (<span class="string">&#x27;1.doing homework&#x27;</span>,<span class="string">&#x27;2.have dinner&#x27;</span>)</span><br><span class="line"><span class="comment"># 输出索引为1的待办事项</span></span><br><span class="line">In [<span class="number">9</span>]: print(do_list_tup[<span class="number">1</span>])</span><br><span class="line"><span class="number">2.</span>have dinner</span><br><span class="line"><span class="comment"># 输出所有待办事项</span></span><br><span class="line">In [<span class="number">10</span>]: print(do_list_tup)</span><br><span class="line">(<span class="string">&#x27;1.doing homework&#x27;</span>, <span class="string">&#x27;2.have dinner&#x27;</span>)</span><br></pre></td></tr></table></figure><p>如果现在我要先玩滑板，在写作业呢？那么就需要把后面的每一个待办事项都得挪一个位置才行，如果待办事项有很多很多，这种操作就有点麻烦了。接下来，我们得继续看看<code>链表(Linked list)</code>。</p><h5 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h5><p>链表中的元素可以存储在任何地方，链表的每个元素都存储了下一个元素的地址，从而使一系列的随机内存地址串在了一起。这就很方便的上面出现的问题了：直接在前面插入玩滑板，链表会存储一个标记表示下一个待办事项是写作业。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义列表</span></span><br><span class="line">In [<span class="number">11</span>]: do_list = []</span><br><span class="line">In [<span class="number">12</span>]: do_list = [<span class="string">&#x27;1.doing homework&#x27;</span>,<span class="string">&#x27;2.have dinner&#x27;</span>]</span><br><span class="line"><span class="comment"># 取出索引为1的元素</span></span><br><span class="line">In [<span class="number">13</span>]: print(do_list[<span class="number">1</span>])</span><br><span class="line"><span class="number">2.</span>have dinner</span><br><span class="line"><span class="comment"># 插入插入待办事项</span></span><br><span class="line">In [<span class="number">15</span>]: do_list.insert(<span class="number">0</span>,<span class="string">&#x27;3.Skateboarding&#x27;</span>)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">In [<span class="number">16</span>]: print(do_list)</span><br><span class="line">[<span class="string">&#x27;3.Skateboarding&#x27;</span>, <span class="string">&#x27;1.doing homework&#x27;</span>, <span class="string">&#x27;2.have dinner&#x27;</span>]</span><br></pre></td></tr></table></figure><p>链表的优势在插入元素方面，数组的优势在于查找，散列表的优势又是什么呢？</p><h5 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h5><p>在这里对这三种基本数据结构做一个对比总结，还记得前面说过的大O表示法么？</p><p>在平均情况下，散列表执行各种操作的时间都为O(1)，O(1)被称为<code>常量时间</code>。简单的查找的运行时间为线性时间，二分查找的速度更快，所需要的时间为对数时间，在散列表中查找所花费的时间是常量时间。这意味着无论散列表包含一个元素还是一亿个元素，从其中获取数据所需要的时间都是相同；其实从数组中获取一个元素所需要的时间也是固定的。</p><p>我们来将散列表同数组，链表来比较一下：</p><p><img src="%E6%95%A3%E5%88%97%E8%A1%A8%5Cpic.jpg"></p><p>在平均情况下，散列表的查找速度和数组一样快，而插入和删除速度与链表一样快，在最糟的情况下，散列表的各种操作的速度都很慢。因此在使用散列表时，需要避开最糟糕的情况，也就是需要避开冲突。</p><h4 id="冲突"><a href="#冲突" class="headerlink" title="冲突"></a>冲突</h4><p>散列表中存在冲突，什么冲突？就是散列函数不可能总是将不同的键均匀的映射到数组的不同的位置。拿在开头举的一个例子，为了查找电话薄中某人的号码，我们创建一个按照人名首字母顺序排列的表，以p开头姓名存储到对应的散列表位置中，但是以p开头的姓名也不是只有一个，就需要给多个键分配到了同一个位置，这样就会造成冲突。</p><p>最简单的是：如果两个键映射到同一个位置，就在这个位置存储一个链表。这样<code>pross</code>和<code>paul</code>都会映射到同一个位置，在访问以p开头的姓名时，速度依然很快。但需要查询pross的电话号码时，速度就慢一些；如果散列表存储的链表很长，散列表的速度也将急剧的下降。</p><p>处理冲突比较好的办法有：较低的填充因子和良好的散列函数。</p><p><strong>填充因子</strong></p><p>散列表的填充因子很容易计算：</p><pre><code>        $$填装因子 = \frac&#123;散列表包含的元素数&#125;&#123;位置总数&#125;$$    </code></pre><p>散列表使用数组来存储数据，因此需要计算数组中被占用的位置数，填装因子大于1，意味着元素超过了位置总数。一旦填充因子开始增大，就需要在散列表中添加位置，也就是<code>调整长度(resizing)</code>，长度增加，填装因子就变低，发生的冲突的可能性越小，散列表的性能也就越高。</p><blockquote><p>一个不错的经验规则是：一旦填充因子大于0.7，就需要调整列表的长度。</p><p>调整长度的时间开销很大。</p></blockquote><p><strong>良好的散列函数</strong></p><p>一个糟糕的散列函数就会让值扎堆，导致大量的冲突；选择一个良好的散列函数，能够让数组中的值呈均匀分布，解决冲突。这里介绍<code>SHA函数</code>，这也是扩展知识中的心动之处。</p><p><code>安全散列算法</code>（英语：Secure Hash Algorithm，缩写为SHA）是一个密码散列函数家族（SHA-0，SHA-1，SHA-2，SHA-3），能计算出一个数字消息所对应到的，长度固定的字符串的算法（又称消息摘要）。且若输入的消息不同，它们对应到不同字符串的机率极高。</p><p>SHA是一个散列函数，它生成一个散列值，用于创建散列表的散列函数根据字符串生成数组索引，而SHA根据字符串生成另外一个字符串，对于每个字符串，SHA生成的散列值极大可能不同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">20</span>]: <span class="keyword">import</span> hashlib</span><br><span class="line"><span class="comment"># 使用sha256</span></span><br><span class="line">In [<span class="number">21</span>]: <span class="built_in">hash</span> = hashlib.sha256()</span><br><span class="line">In [<span class="number">22</span>]: <span class="built_in">hash</span>.update(<span class="string">&#x27;pross&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">In [<span class="number">24</span>]: <span class="built_in">hash</span>.hexdigest()</span><br><span class="line">Out[<span class="number">25</span>]: <span class="string">&#x27;58f8b4db8a8d80bc485de70a57912ddcf8a2fa93e698e2ce346f9f54d859af5f&#x27;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><strong>扩展</strong>：密钥导出和扩展算法是为安全密码散列设计的，类似<code>hashlib.sha256()</code>这种简单算法不能有效抵御暴力破解，一个好的密码散列函数必须是可调节的，耗时的，并包含盐。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">26</span>]: <span class="keyword">import</span> hashlib</span><br><span class="line"><span class="comment"># 密钥导出，pbkdf2_hmac(hash_name, password, salt, iterations, dklen=None)提供了使用PKCS#5填充的pbkdf2算法，使用HMAC作为伪随机函数</span></span><br><span class="line">In [<span class="number">27</span>]: dk = hashlib.pbkdf2_hmac(<span class="string">&#x27;sha256&#x27;</span>,<span class="string">b&#x27;pross&#x27;</span>,<span class="string">b&#x27;salt&#x27;</span>,<span class="number">1000</span>)</span><br><span class="line">In [<span class="number">28</span>]: <span class="keyword">import</span> binascii</span><br><span class="line">In [<span class="number">29</span>]: binascii.hexlify(dk)</span><br><span class="line">Out[<span class="number">29</span>]: <span class="string">b&#x27;07c8f073bc2484c6163cd7c44d8d35f0b6ffc16e3b907df16bf8d292ccd176f9&#x27;</span></span><br></pre></td></tr></table></figure><p>字符串hash_name是HMAC的哈希摘要算法的所需名称，例如：sha1或sha256；password和salt为字节的缓冲区，所以应该将password限制在合理的长度（1024）；iterations的数量基于散列算法和计算能力来选择。截至2013年，建议至少100,000次迭代的SHA-256；dklen是导出密钥的长度，如果dklen=None，则使用散列算法hash_name的摘要大小，例如，64为SHA-512的摘要大小。</p><p>快乐的时光总是短暂的，散列表及其各种天马行空的扩展知识就介绍到这。</p><p>完。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;关于算法系列，在前面已经整理过大O表示法和排序算法相关的文章，今天接着上次的话说一说散列表（Hash Table，也叫哈希表），顺便穿插和另外两种基本的数据结构，数组和链表比较；并在最后介绍良好的散列函数——SHA函数的使用。这三种基本数据结构，可简可繁，在写代码时候都是比较频繁使用的，那我们先从散列表开始入手。&lt;/p&gt;
&lt;p&gt;散列表是根据键（Key）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做&lt;code&gt;散列函数&lt;/code&gt;，存放记录的数组称做&lt;code&gt;散列表&lt;/code&gt;。散列表是最有用的基本数据结构之一，我们需要总结散列表：实现、冲突和散列函数。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据结构" scheme="https://pross.space/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>几种定时调度的介绍与实现</title>
    <link href="https://pross.space/blog/2019/01/01/introduction-and-realization-of-several-timing-scheduling.html"/>
    <id>https://pross.space/blog/2019/01/01/introduction-and-realization-of-several-timing-scheduling.html</id>
    <published>2019-01-01T04:01:53.000Z</published>
    <updated>2021-01-30T07:11:56.766Z</updated>
    
    <content type="html"><![CDATA[<p>由需求产出的一篇文章，憋了很久。以下将会看到，使用Timer进行任务调度，用ScheduledExecutor和Calendar实现任务调度，Spring中的任务调度TaskScheduler，开源工具包Quartz的简单介绍。</p><h4 id="使用Timer任务调度"><a href="#使用Timer任务调度" class="headerlink" title="使用Timer任务调度"></a>使用Timer任务调度</h4><p>Timer是<code>java.util.Timer</code>提供的比较简单的调度工具，实现任务调度的核心是Timer和TimerTask。其中Timer负责在<code>schedule</code>方法中设定TimerTask任务，以及任务执行的起始时间<code>delay</code>和间隔执行的时间<code>period</code>；TimerTask负责创建需要调度的任务，开发者需要实现<code>run</code>方法，然后将其丢给Timer去执行即可。</p><a id="more"></a><p>下面这个例子，用不同的方法实现了两个任务调度，其中一个任务达到条件后使用<code>cancel</code>方法终止了调度。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.Timer;</span><br><span class="line"><span class="keyword">import</span> java.util.TimerTask;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@describe</span>: timer调度</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:彭爽pross</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>: 2018/12/28</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimerDemo</span> <span class="keyword">extends</span> <span class="title">TimerTask</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> String taskName=<span class="string">&quot;&quot;</span>;</span><br><span class="line"><span class="comment">//构造方法</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="title">TimerDemo</span><span class="params">(String taskName)</span> </span>&#123;</span><br><span class="line"><span class="keyword">super</span>();</span><br><span class="line"><span class="keyword">this</span>.taskName=taskName;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">&quot;TimerTask &quot;</span>+taskName+<span class="string">&quot;,&quot;</span>+<span class="keyword">new</span> Date());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">Timer timer = <span class="keyword">new</span> Timer();</span><br><span class="line"><span class="keyword">long</span> delay1 = <span class="number">1</span> * <span class="number">1000</span>;</span><br><span class="line"><span class="keyword">long</span> period1 = <span class="number">1000</span>;</span><br><span class="line">timer.schedule(<span class="keyword">new</span> TimerDemo(<span class="string">&quot;task 1&quot;</span>),delay1,period1);</span><br><span class="line"></span><br><span class="line"><span class="keyword">long</span> delay2 = <span class="number">2</span> * <span class="number">1000</span>;</span><br><span class="line"><span class="keyword">long</span> period2 = <span class="number">1000</span>;</span><br><span class="line">timer.schedule(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">String taskName = <span class="string">&quot;task 2&quot;</span>;</span><br><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">i++;</span><br><span class="line">System.out.println(<span class="string">&quot;TimerTask &quot;</span>+taskName+<span class="string">&quot;,&quot;</span>+<span class="keyword">new</span> Date());</span><br><span class="line"><span class="keyword">if</span>(i&gt;<span class="number">2</span>)&#123;</span><br><span class="line">cancel();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;,delay2,period2);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>控制变量<code>i</code>大于等于2后，任务调度被终止，只剩下一个任务。输出结果：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">TimerTask task <span class="number">1</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">25</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">2</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">26</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">1</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">26</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">2</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">27</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">1</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">27</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">2</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">28</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">1</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">28</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">1</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">29</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">1</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">30</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">1</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">31</span> CST <span class="number">2018</span></span><br><span class="line">TimerTask task <span class="number">1</span>,Sat Dec <span class="number">29</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">32</span> CST <span class="number">2018</span></span><br></pre></td></tr></table></figure><p>如果调整调度周期，会发现所有的任务都是同一个线程来调度的，多个任务是串行执行，前一个任务的延迟或异常都将会影响到之后的任务。下图是Timer类的结构。</p><p><img src="./timer.jpg"></p><p>我们从执行开始追溯源码，先进入<code>schedule</code>方法，发现最终是调用的<code>sched</code>方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">schedule</span><span class="params">(TimerTask task, <span class="keyword">long</span> delay, <span class="keyword">long</span> period)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (delay &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;Negative delay.&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (period &lt;= <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;Non-positive period.&quot;</span>);</span><br><span class="line">    <span class="comment">// schedule方法，最终调用sched()</span></span><br><span class="line">        sched(task, System.currentTimeMillis()+delay, -period);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里我们发现了<code>queue</code>和<code>thread</code>的踪影，给<code>queue</code>加上控制线程同步<code>synchronized</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> TaskQueue queue = <span class="keyword">new</span> TaskQueue();</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> TimerThread thread = <span class="keyword">new</span> TimerThread(queue);</span><br><span class="line">...</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sched</span><span class="params">(TimerTask task, <span class="keyword">long</span> time, <span class="keyword">long</span> period)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (time &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;Illegal execution time.&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (Math.abs(period) &gt; (Long.MAX_VALUE &gt;&gt; <span class="number">1</span>))</span><br><span class="line">            period &gt;&gt;= <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">synchronized</span>(queue) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!thread.newTasksMayBeScheduled)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">&quot;Timer already cancelled.&quot;</span>);</span><br><span class="line">            <span class="keyword">synchronized</span>(task.lock) &#123;</span><br><span class="line">                <span class="keyword">if</span> (task.state != TimerTask.VIRGIN)</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(</span><br><span class="line">                        <span class="string">&quot;Task already scheduled or cancelled&quot;</span>);</span><br><span class="line">                task.nextExecutionTime = time;</span><br><span class="line">                task.period = period;</span><br><span class="line">                task.state = TimerTask.SCHEDULED;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 满足执行条件，加入queue</span></span><br><span class="line">            queue.add(task);</span><br><span class="line">            <span class="keyword">if</span> (queue.getMin() == task)</span><br><span class="line">                queue.notify();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>我们继续看TaskThread的执行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//执行mainLoop()开始调度任务</span></span><br><span class="line">            mainLoop();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">synchronized</span>(queue) &#123;</span><br><span class="line">               <span class="comment">/** </span></span><br><span class="line"><span class="comment">                * 当newTasksMayBeScheduled是false时</span></span><br><span class="line"><span class="comment">                * 在上面sched方法中会抛出IllegalStateException异常</span></span><br><span class="line"><span class="comment">                * 所以只能同一时间执行一个任务</span></span><br><span class="line"><span class="comment">                */</span></span><br><span class="line">                newTasksMayBeScheduled = <span class="keyword">false</span>;</span><br><span class="line">                queue.clear(); </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><code>mainLoop</code>方法就不展开，这里展示核心代码段。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">synchronized</span>(task.lock) &#123;</span><br><span class="line">    <span class="comment">// 查看任务状态</span></span><br><span class="line">    <span class="keyword">if</span> (task.state == TimerTask.CANCELLED) &#123;</span><br><span class="line">        queue.removeMin();</span><br><span class="line">        <span class="keyword">continue</span>;  <span class="comment">// No action required, poll queue again</span></span><br><span class="line">    &#125;</span><br><span class="line">    currentTime = System.currentTimeMillis();</span><br><span class="line">    executionTime = task.nextExecutionTime;</span><br><span class="line">    <span class="comment">// 比较时间</span></span><br><span class="line">    <span class="keyword">if</span> (taskFired = (executionTime&lt;=currentTime)) &#123;</span><br><span class="line">        <span class="comment">// 调度周期为0，removemin</span></span><br><span class="line">        <span class="keyword">if</span> (task.period == <span class="number">0</span>) &#123; <span class="comment">// Non-repeating, remove</span></span><br><span class="line">            queue.removeMin();</span><br><span class="line">            task.state = TimerTask.EXECUTED;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// Repeating task, reschedule</span></span><br><span class="line">            queue.rescheduleMin(</span><br><span class="line">                task.period&lt;<span class="number">0</span> ? currentTime - task.period : executionTime + task.period);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>最后总结下，Timer 的设计核心是一个<code>TaskQueue</code>和一个<code>TaskThread</code>。Timer 将接收到的任务丢到自己的<code>TaskQueue</code>中，TaskQueue按照Task的最初执行时间进行排序。TimerThread在创建Timer时会启动成为一个守护线程。这个线程会轮询所有任务，找到一个最近要执行的任务，然后休眠，当到达最近要执行任务的开始时间点，TimerThread被唤醒并执行该任务。之后TimerThread更新最近一个要执行的任务，继续休眠。</p><p>Timer的优点在于简单易用，缺点除了单线程调度问题，还有使用的场景比较单一。比如，设置每星期二的16:38:10执行任务，Timer就不是太适用。</p><h4 id="用ScheduledExecutor和Calendar实现任务调度"><a href="#用ScheduledExecutor和Calendar实现任务调度" class="headerlink" title="用ScheduledExecutor和Calendar实现任务调度"></a>用ScheduledExecutor和Calendar实现任务调度</h4><p>这是两个东西组合使用，所以先简单介绍下<code>ScheduledExecutor</code></p><h5 id="ScheduledExecutor"><a href="#ScheduledExecutor" class="headerlink" title="ScheduledExecutor"></a>ScheduledExecutor</h5><p>与Timer比较，优化了任务执行方式，采用线程池并行执行，说到线程池，上篇文章有过一点介绍了。这里直接上代码例子，介绍看注释。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ScheduledExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@describe</span>: ScheduledExecutor 任务调度</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:彭爽pross</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>: 2018/12/28</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScheduledExecutorDemo</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">&quot;task 1&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 初始化线程池</span></span><br><span class="line">ScheduledExecutorService service = Executors.newScheduledThreadPool(<span class="number">10</span>);</span><br><span class="line"><span class="comment">// task 1 ，scheduleAtFixedRate方法，需要指明时间单位，实现的是runnable</span></span><br><span class="line">        <span class="comment">// 所以每一个任务都是单独的一个线程</span></span><br><span class="line">service.scheduleAtFixedRate(<span class="keyword">new</span> ScheduledExecutorDemo(),<span class="number">1000</span>,<span class="number">1000</span>, TimeUnit.SECONDS);</span><br><span class="line"><span class="comment">// task 2</span></span><br><span class="line">service.scheduleAtFixedRate(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">&quot;task 2&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;,<span class="number">1000</span>,<span class="number">1000</span>,TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于日历类<code>Calendar</code>就不做详细讲解，我们来看看怎么Calendar+ScheduledExecutor解决较为复杂的调度。</p><h5 id="实现每周五12点调度任务"><a href="#实现每周五12点调度任务" class="headerlink" title="实现每周五12点调度任务"></a>实现每周五12点调度任务</h5><p>代码一现，其义自见。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Calendar;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ScheduledExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@describe</span>:</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:彭爽pross</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>: 2018/12/27</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScheduledExecuteCalendar</span> </span>&#123;</span><br><span class="line"><span class="comment">// 初始化线程池</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> ScheduledExecutorService service = Executors.newScheduledThreadPool(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 计算从当前时间currentDate开始，</span></span><br><span class="line"><span class="comment"> * 满足条件dayOfWeek, hourOfDay,minuteOfHour, secondOfMinite的最近时间</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Calendar <span class="title">getEarliestDate</span><span class="params">(Calendar currentDate, <span class="keyword">int</span> dayOfWeek,</span></span></span><br><span class="line"><span class="function"><span class="params">                                <span class="keyword">int</span> hourOfDay, <span class="keyword">int</span> minuteOfHour, <span class="keyword">int</span> secondOfMinite)</span> </span>&#123;</span><br><span class="line"><span class="comment">//计算当前时间的WEEK_OF_YEAR,DAY_OF_WEEK, HOUR_OF_DAY, MINUTE,SECOND等各个字段值</span></span><br><span class="line"><span class="keyword">int</span> currentWeekOfYear = currentDate.get(Calendar.WEEK_OF_YEAR);</span><br><span class="line"><span class="keyword">int</span> currentDayOfWeek = currentDate.get(Calendar.DAY_OF_WEEK);</span><br><span class="line"><span class="keyword">int</span> currentHour = currentDate.get(Calendar.HOUR_OF_DAY);</span><br><span class="line"><span class="keyword">int</span> currentMinute = currentDate.get(Calendar.MINUTE);</span><br><span class="line"><span class="keyword">int</span> currentSecond = currentDate.get(Calendar.SECOND);</span><br><span class="line"></span><br><span class="line"><span class="comment">//如果输入条件中的dayOfWeek小于当前日期的dayOfWeek,则WEEK_OF_YEAR需要推迟一周</span></span><br><span class="line"><span class="keyword">boolean</span> weekLater = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">if</span> (dayOfWeek &lt; currentDayOfWeek) &#123;</span><br><span class="line">weekLater = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//当输入条件与当前日期的dayOfWeek相等时，输入条件中的 hourOfDay小于当前日期的 currentHour，则WEEK_OF_YEAR需要推迟一周</span></span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (dayOfWeek == currentDayOfWeek) &#123;</span><br><span class="line"><span class="keyword">if</span> (hourOfDay &lt; currentHour) &#123;</span><br><span class="line">weekLater = <span class="keyword">true</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (hourOfDay == currentHour) &#123;</span><br><span class="line"><span class="comment">//当输入条件与当前日期的dayOfWeek, hourOfDay相等时，输入条件中的minuteOfHour小于当前日期currentMinute，则WEEK_OF_YEAR需要推迟一周</span></span><br><span class="line"><span class="keyword">if</span> (minuteOfHour &lt; currentMinute) &#123;</span><br><span class="line">weekLater = <span class="keyword">true</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (minuteOfHour == currentSecond) &#123;</span><br><span class="line"><span class="comment">//当输入条件与当前日期的dayOfWeek, hourOfDay，minuteOfHour相等时，如果输入条件中的secondOfMinite小于当前日期的currentSecond，则WEEK_OF_YEAR需要推迟一周</span></span><br><span class="line"><span class="keyword">if</span> (secondOfMinite &lt; currentSecond) &#123;</span><br><span class="line">weekLater = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (weekLater) &#123;</span><br><span class="line"><span class="comment">//设置当前日期中的WEEK_OF_YEAR为当前周推迟一周</span></span><br><span class="line">currentDate.set(Calendar.WEEK_OF_YEAR, currentWeekOfYear + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 设置当前日期中的DAY_OF_WEEK,HOUR_OF_DAY,MINUTE,SECOND为输入条件中的值。</span></span><br><span class="line">currentDate.set(Calendar.DAY_OF_WEEK, dayOfWeek);</span><br><span class="line">currentDate.set(Calendar.HOUR_OF_DAY, hourOfDay);</span><br><span class="line">currentDate.set(Calendar.MINUTE, minuteOfHour);</span><br><span class="line">currentDate.set(Calendar.SECOND, secondOfMinite);</span><br><span class="line"><span class="keyword">return</span> currentDate;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">ScheduledExecuteCalendar test = <span class="keyword">new</span> ScheduledExecuteCalendar();</span><br><span class="line"><span class="comment">// 获取当前时间</span></span><br><span class="line">Calendar currentDate = Calendar.getInstance();</span><br><span class="line"><span class="keyword">long</span> currentDateLong = currentDate.getTime().getTime();</span><br><span class="line">System.out.println(<span class="string">&quot;当前日期： &quot;</span> + currentDate.getTime().toString());</span><br><span class="line"><span class="comment">// 计算满足条件的最近一次执行时间</span></span><br><span class="line">Calendar earliestDate = test.getEarliestDate(currentDate, <span class="number">6</span>, <span class="number">12</span>, <span class="number">00</span>, <span class="number">00</span>);</span><br><span class="line"><span class="comment">//计算第一次执行延迟时间</span></span><br><span class="line"><span class="keyword">long</span> earliestDateLong = earliestDate.getTime().getTime();</span><br><span class="line"><span class="keyword">long</span> delay = earliestDateLong - currentDateLong;</span><br><span class="line">System.out.println(<span class="string">&quot;下一次执行时间：&quot;</span>+earliestDate.getTime().toString());</span><br><span class="line"><span class="comment">//计算执行周期为一星期</span></span><br><span class="line"><span class="keyword">long</span> period = <span class="number">7</span> * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span> * <span class="number">1000</span>;</span><br><span class="line">System.out.println(<span class="string">&quot;等待执行...&quot;</span>);</span><br><span class="line">service.scheduleAtFixedRate(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">&quot;Task ScheduledExecute&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;, delay, period, TimeUnit.MILLISECONDS); </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Spring中的任务调度TaskScheduler"><a href="#Spring中的任务调度TaskScheduler" class="headerlink" title="Spring中的任务调度TaskScheduler"></a>Spring中的任务调度TaskScheduler</h4><p>TaskScheduler用于对Runnable的任务进行调度，其中包含多种实现，多数对任务进行调度的实现是<code>ThreadPoolTaskScheduler</code>；另外需要用到<code>Trigger</code>接口计算任务的下次执行时间；我们先看下Trigger接口的实现。</p><h5 id="Trigger"><a href="#Trigger" class="headerlink" title="Trigger"></a>Trigger</h5><p>Trigger接口定义如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Trigger</span> </span>&#123;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Determine the next execution time according to the given trigger context.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> triggerContext context object encapsulating last execution times</span></span><br><span class="line"><span class="comment"> * and last completion time</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> the next execution time as defined by the trigger,</span></span><br><span class="line"><span class="comment"> * or &#123;<span class="doctag">@code</span> null&#125; if the trigger won&#x27;t fire anymore</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Nullable</span></span><br><span class="line"><span class="function">Date <span class="title">nextExecutionTime</span><span class="params">(TriggerContext triggerContext)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中提供了一个接口：<code>nextExecutionTime</code>来获取下次执行时间，接受的参数为TirggerContxt对象，这个参数对象能获取上次原本的计划时间 / 实际的执行时间 / 实际的完成时间，你问我是怎么知道？点进去看源码呀！</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">TriggerContext</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return the last &lt;i&gt;scheduled&lt;/i&gt; execution time of the task,</span></span><br><span class="line"><span class="comment"> * or &#123;<span class="doctag">@code</span> null&#125; if not scheduled before.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Nullable</span></span><br><span class="line"><span class="function">Date <span class="title">lastScheduledExecutionTime</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return the last &lt;i&gt;actual&lt;/i&gt; execution time of the task,</span></span><br><span class="line"><span class="comment"> * or &#123;<span class="doctag">@code</span> null&#125; if not scheduled before.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Nullable</span></span><br><span class="line"><span class="function">Date <span class="title">lastActualExecutionTime</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return the last completion time of the task,</span></span><br><span class="line"><span class="comment"> * or &#123;<span class="doctag">@code</span> null&#125; if not scheduled before.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Nullable</span></span><br><span class="line"><span class="function">Date <span class="title">lastCompletionTime</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>继续返回来，来看看有哪些实现类继承Trigger接口（IDEA中快捷键，<code>option + command +B</code> / <code>ctrl + alt + B</code> ）；第一个是<code>CronTrigger</code>，通过<code>Crob</code>表达式来生成的调度计划，还可以选择是否加上时区。</p><p>举例：工作日的9-17点之间，每隔30分钟执行一次；</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> CronTrigger(<span class="string">&quot;0 0/30 9-17 * * MON-FRI&quot;</span>)</span><br></pre></td></tr></table></figure><p>第二个实现类是<code>PeriodicTrigger</code>，也用于定期执行，有两种模式可以选择：<code>setFixedRate</code>，boolean类型，默认是false。和 <code>setInitialDelay</code>，long类型，表示启动任务后延迟多长时间开始执行第一次任务。最后就是构造方法，参数<code>period</code>，long类型，表示间隔时长；参数<code>timeUnit</code>，TimeUnit类型，指定时长单位。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Specify whether the periodic interval should be measured between the</span></span><br><span class="line"><span class="comment"> * scheduled start times rather than between actual completion times.</span></span><br><span class="line"><span class="comment"> * The latter, &quot;fixed delay&quot; behavior, is the default.</span></span><br><span class="line"><span class="comment"> * 简明总结为：两次任务开始时间的间隔为指定的时长(period)。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFixedRate</span><span class="params">(<span class="keyword">boolean</span> fixedRate)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.fixedRate = fixedRate;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Specify the delay for the initial execution. It will be evaluated in</span></span><br><span class="line"><span class="comment"> * terms of this trigger&#x27;s &#123;<span class="doctag">@link</span> TimeUnit&#125;. If no time unit was explicitly</span></span><br><span class="line"><span class="comment"> * provided upon instantiation, the default is milliseconds.</span></span><br><span class="line"><span class="comment"> * 简明总结为：设置启动调度后，设置执行第一次任务的延迟时间。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setInitialDelay</span><span class="params">(<span class="keyword">long</span> initialDelay)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.initialDelay = <span class="keyword">this</span>.timeUnit.toMillis(initialDelay);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>TaskScheduler</strong></p><p>TaskScheduler接口的实现类有ThreadPoolTaskScheduler，其中还有ConcurrentTaskScheduler，DefaultManagedTaskScheduler，TimerManagerTaskScheduler，这里重要说下默认的实现类ThreadPoolTaskScheduler。</p><p>在大多数场景下都使用它来进行任务调度，除了实现TaskScheduler接口外，还包含了一些对ThreadPoolTaskScheduler进行操作的接口：<code>AsyncListenableTaskExecutor</code>和<code>SchedulingTaskExecutor</code>。其常用的方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置线程池大小，默认为poolsize=1。</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPoolSize</span><span class="params">(<span class="keyword">int</span> poolSize)</span> </span>&#123;</span><br><span class="line">Assert.isTrue(poolSize &gt; <span class="number">0</span>, <span class="string">&quot;&#x27;poolSize&#x27; must be 1 or higher&quot;</span>);</span><br><span class="line"><span class="keyword">this</span>.poolSize = poolSize;</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">this</span>.scheduledExecutor <span class="keyword">instanceof</span> ScheduledThreadPoolExecutor) &#123;</span><br><span class="line">((ScheduledThreadPoolExecutor) <span class="keyword">this</span>.scheduledExecutor).setCorePoolSize(poolSize);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 异常处理起</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setErrorHandler</span><span class="params">(ErrorHandler errorHandler)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.errorHandler = errorHandler;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取当前活动的线程数</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getActiveCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">this</span>.scheduledExecutor == <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="comment">// Not initialized yet: assume no active threads.</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> getScheduledThreadPoolExecutor().getActiveCount();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 提交执行任务，需继承必须重写的方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Runnable task)</span> </span>&#123;</span><br><span class="line">Executor executor = getScheduledExecutor();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">executor.execute(errorHandlingTask(task, <span class="keyword">false</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span> (RejectedExecutionException ex) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> TaskRejectedException(<span class="string">&quot;Executor [&quot;</span> + executor + <span class="string">&quot;] did not accept task: &quot;</span> + task, ex);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 提交执行一次的任务，并且返回一个Future对象供判断任务状态使用</span></span><br><span class="line"><span class="comment">// submit/submitListenable</span></span><br><span class="line"><span class="keyword">public</span> Future&lt;?&gt; submit(Runnable task) &#123;</span><br><span class="line">ExecutorService executor = getScheduledExecutor();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">return</span> executor.submit(errorHandlingTask(task, <span class="keyword">false</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span> (RejectedExecutionException ex) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> TaskRejectedException(<span class="string">&quot;Executor [&quot;</span> + executor + <span class="string">&quot;] did not accept task: &quot;</span> + task, ex);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Spring中提供<code>Scheduled</code>注解来实现快捷的任务调度，需要注意的是必须使用<code>@EnableScheduling</code>注解启用对<code>@Scheduled</code>注解的支持，@EnableScheduling必须使用在项目中某一个被<code>@Configuration</code>注解的类上，比如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableScheduling</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DBConfiguration</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Scheduled注解用在方法下，用户表示这个方法将会被调度，所注解的方法返回类型最好是<code>void</code>类型，否则它的返回值将不会被TaskScheduler所使用。同时，如果需要参数对象，需要通过依赖注入的方式引用，其中包含：</p><ul><li>cron：使用cron语法来指定调度计划</li><li>zone：指定时区，默认为本时区</li><li>fixedDelay：指定fixedDelay的值，默认单位是毫秒</li><li>fixedRate：指定上一次任务开始时间到下一次任务开始时间的间隔时间，单位默认是毫秒</li><li>initialDelay：设置初始延迟时间</li></ul><p>其中cron / fixedDelay / fixedRate三个属性必须且只能出现一个，下面举个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScheduleService</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(ScheduleService.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Scheduled(fixedRate = 4000)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testSchedule</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        logger.info(<span class="string">&quot;TestSchedule begins to execute!&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            logger.error(<span class="string">&quot;TestSchedule has been interrupted!&quot;</span>, e);</span><br><span class="line">            <span class="keyword">return</span>;  </span><br><span class="line">        &#125;</span><br><span class="line">        logger.info(<span class="string">&quot;TestSchedule execution was completed!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还有一个直接在Spring Boot中使用<code>@Autowired</code>注解的方式，直接实现threadPoolTaskScheduler，实现动态的添加、修改、删除定时任务，也是实现需求考虑的方案。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.ScheduledFuture;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.support.CronTrigger;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@describe</span>:</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:彭爽pross</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>: 2018/12/28</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicTaskController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ThreadPoolTaskScheduler threadPoolTaskScheduler;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在ScheduledFuture中cancel可以停止定时任务。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> ScheduledFuture&lt;?&gt; future;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * ThreadPoolTaskScheduler：线程池任务调度类，能够开启线程池进行任务调度。</span></span><br><span class="line"><span class="comment">     * ThreadPoolTaskScheduler.schedule()方法会创建一个定时计划ScheduledFuture，在这个方法需要添加两个参数，Runnable（线程接口类） 和CronTrigger（定时任务触发器）</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ThreadPoolTaskScheduler <span class="title">threadPoolTaskScheduler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolTaskScheduler();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启动任务，每五秒钟执行一次</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@RequestMapping(&quot;/startTask&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">startCron</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       future = threadPoolTaskScheduler.schedule(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">&quot;execute task&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;, <span class="keyword">new</span> CronTrigger(<span class="string">&quot;0/5 * * * * *&quot;</span>));</span><br><span class="line">       System.out.println(<span class="string">&quot;DynamicTaskController.startCron()&quot;</span>);</span><br><span class="line">       <span class="keyword">return</span> <span class="string">&quot;startTask&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启此任务</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@RequestMapping(&quot;/stopTask&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">stopCron</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (future != <span class="keyword">null</span>) &#123;</span><br><span class="line">           future.cancel(<span class="keyword">true</span>);</span><br><span class="line">       &#125;</span><br><span class="line">       System.out.println(<span class="string">&quot;DynamicTaskController.stopCron()&quot;</span>);</span><br><span class="line">       <span class="keyword">return</span> <span class="string">&quot;stopTask&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 变更任务间隔，再次启动</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@RequestMapping(&quot;/changeCron&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">changeCron</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="comment">// 先停止，在开启</span></span><br><span class="line">       stopCron();</span><br><span class="line">       future = threadPoolTaskScheduler.schedule(<span class="keyword">new</span> MyRunnable(), <span class="keyword">new</span> CronTrigger(<span class="string">&quot;*/10 * * * * *&quot;</span>));</span><br><span class="line">       System.out.println(<span class="string">&quot;DynamicTaskController.changeCron()&quot;</span>);</span><br><span class="line">       <span class="keyword">return</span> <span class="string">&quot;changeCron&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="简单介绍开源工具包Quartz"><a href="#简单介绍开源工具包Quartz" class="headerlink" title="简单介绍开源工具包Quartz"></a>简单介绍开源工具包Quartz</h4><p>Quartz 可以满足更多更复杂的调度需求，设计的核心类包括 Scheduler，Job 以及Trigger。其中Job 负责定义需要执行的任务，Trigger 负责设置调度策略，Scheduler 将二者组装在一起，并触发任务开始执行，除了Job其它的核心类大多已经简单介绍过，下面看看Job。</p><p><strong>Job</strong></p><p>使用者只需要创建一个 Job 的继承类，实现<code>execute</code>方法。<code>JobDetail</code>负责封装 Job 以及 Job 的属性，并将其提供给 Scheduler 作为参数。每次 Scheduler 执行任务时，首先会创建一个 Job 的实例，然后再调用 execute 方法执行。Quartz 没有为 Job 设计带参数的构造函数，因此需要通过额外的 JobDataMap 来存储 Job 的属性。JobDataMap 可以存储任意数量的 Key，Value键值对。</p><p>举个例子。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.quartz.Job;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobDetail;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionContext;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionException;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Scheduler;</span><br><span class="line"><span class="keyword">import</span> org.quartz.SchedulerFactory;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Trigger;</span><br><span class="line"><span class="keyword">import</span> org.quartz.helpers.TriggerUtils;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@describe</span>: 创建一个MyJob类，实现Job接口</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:彭爽pross</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>: 2018/12/29</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyJob</span> <span class="keyword">implements</span> <span class="title">Job</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">Scheduler scheduler = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">// 创建一个JobDetail实例</span></span><br><span class="line">JobBuilder jobBuilder = JobBuilder.newJob(MyJob.class);</span><br><span class="line">jobBuilder.withDescription(<span class="string">&quot;test read desc.&quot;</span>);</span><br><span class="line">JobDetail jobDetail = jobBuilder.build();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个调度规则, 每3s运行一次</span></span><br><span class="line">SimpleScheduleBuilder simpleBuilder = SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(<span class="number">3</span>).repeatForever();</span><br><span class="line">Trigger trigger = TriggerBuilder.newTrigger().withSchedule(simpleBuilder).startNow().build();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从工厂中获取一个调度器Scheduler</span></span><br><span class="line">SchedulerFactory schedulerFactory = <span class="keyword">new</span> StdSchedulerFactory();</span><br><span class="line">scheduler = schedulerFactory.getScheduler();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册jobDetail, trigger到调度器Scheduler</span></span><br><span class="line">scheduler.scheduleJob(jobDetail, trigger);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 开始执行Job</span></span><br><span class="line">scheduler.start();</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e1) &#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">// 出异常了, 停止执行Job</span></span><br><span class="line">scheduler.shutdown();</span><br><span class="line">&#125; <span class="keyword">catch</span> (SchedulerException e2) &#123;</span><br><span class="line">e2.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">e1.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext jobExecutionContext)</span> <span class="keyword">throws</span> JobExecutionException</span>&#123;</span><br><span class="line">String description = jobExecutionContext.getJobDetail().getDescription();</span><br><span class="line">System.out.println(<span class="string">&quot;定时Job开始运行: &quot;</span> + description);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Quartz还可以和Spring整合使用，需要创建一个具体的作业任务的实现类，使用JobDetailFactoryBean来管理作业任务。具体就不细致展开，这篇文章篇幅已经够长了，</p><p>几种定时调度的介绍和实现暂时就写这么多。</p><p>完。 </p>]]></content>
    
    
    <summary type="html">&lt;p&gt;由需求产出的一篇文章，憋了很久。以下将会看到，使用Timer进行任务调度，用ScheduledExecutor和Calendar实现任务调度，Spring中的任务调度TaskScheduler，开源工具包Quartz的简单介绍。&lt;/p&gt;
&lt;h4 id=&quot;使用Timer任务调度&quot;&gt;&lt;a href=&quot;#使用Timer任务调度&quot; class=&quot;headerlink&quot; title=&quot;使用Timer任务调度&quot;&gt;&lt;/a&gt;使用Timer任务调度&lt;/h4&gt;&lt;p&gt;Timer是&lt;code&gt;java.util.Timer&lt;/code&gt;提供的比较简单的调度工具，实现任务调度的核心是Timer和TimerTask。其中Timer负责在&lt;code&gt;schedule&lt;/code&gt;方法中设定TimerTask任务，以及任务执行的起始时间&lt;code&gt;delay&lt;/code&gt;和间隔执行的时间&lt;code&gt;period&lt;/code&gt;；TimerTask负责创建需要调度的任务，开发者需要实现&lt;code&gt;run&lt;/code&gt;方法，然后将其丢给Timer去执行即可。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>Java线程池</title>
    <link href="https://pross.space/blog/2018/12/22/java-thread-pool.html"/>
    <id>https://pross.space/blog/2018/12/22/java-thread-pool.html</id>
    <published>2018-12-22T15:59:18.000Z</published>
    <updated>2021-01-30T07:11:56.994Z</updated>
    
    <content type="html"><![CDATA[<p>虽然之前学习了不少相关知识，但是只有在实践中踩坑才能印象深刻。今天看了半天的java对线程池的处理，额外兴致来，周五总结一份java线程池相关。</p><a id="more"></a><h4 id="线程池的后果"><a href="#线程池的后果" class="headerlink" title="线程池的后果"></a>线程池的后果</h4><h5 id="Java提供的工具类-Executors"><a href="#Java提供的工具类-Executors" class="headerlink" title="Java提供的工具类-Executors"></a>Java提供的工具类-Executors</h5><p>Executors是一个Java中的工具类，提供工厂方法来创建不同类型的线程池。 提供方法如下：</p><p><img src="Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%5CExecutors.jpg"></p><p>然后阿里巴巴Java开发手册中这样提到：</p><blockquote><ol><li><p>【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让同学更加明确线程池的运行规则，规避资源耗尽的风险。 </p><pre><code>说明:Executors 返回的线程池对象的弊端如下:   1）FixedThreadPool 和 SingleThreadPool: 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。    2)CachedThreadPool 和 ScheduledThreadPool: 允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 </code></pre></li></ol></blockquote><p>第一个关键词：OOM。怎么导致OOM的呢，那就show codes，一起来看看：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@describe</span>: Executors线程池创建，证明使用Executors会造成oom</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:彭爽pross</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>: 2018/12/21</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExecutorsDemo</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> ExecutorService executor = Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;Integer.MAX_VALUE;i++)&#123;</span><br><span class="line">executor.execute(<span class="keyword">new</span> subThread());</span><br><span class="line">            System.out.println(<span class="string">&quot;Thread count：&quot;</span>+i);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">subThread</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码里刻意调整线程数量，启动时故意设置内存大小（模拟上限内存）：<code>-Xmx8m -Xms8m</code>。运行结果：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">&quot;main&quot;</span> java.lang.OutOfMemoryError: GC overhead limit exceeded</span><br><span class="line">at java.util.concurrent.LinkedBlockingQueue.offer(LinkedBlockingQueue.java:<span class="number">416</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:<span class="number">1371</span>)</span><br><span class="line">at org.pross.threadPool.ExecutorsDemo.main(ExecutorsDemo.java:<span class="number">18</span>)</span><br></pre></td></tr></table></figure><p>错误就是很明显的，OOM问题。再出现OOM之前，会一直有打印输出，一直达到内存上限为止。为什么使用Executors创建线程池就会错误，那我们就来追溯Java创建线程池造成OOM的原因。</p><h5 id="Executors为什么存在缺陷"><a href="#Executors为什么存在缺陷" class="headerlink" title="Executors为什么存在缺陷"></a>Executors为什么存在缺陷</h5><p>往上面结果看一眼，最终执行错误代码到了这一行：<code>java.util.concurrent.LinkedBlockingQueue.offer(LinkedBlockingQueue.java:416)</code>。敲黑板划一下第二个关键词：<code>LinkedBlockingQueue</code>，点进<code>newFixedThreadPool</code> 可以发现关键词的踪影：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/*</span></span><br><span class="line"><span class="comment"> * @param nThreads the number of threads in the pool</span></span><br><span class="line"><span class="comment"> * @return the newly created thread pool</span></span><br><span class="line"><span class="comment"> * @throws IllegalArgumentException if &#123;@code nThreads &lt;= 0&#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newFixedThreadPool</span><span class="params">(<span class="keyword">int</span> nThreads)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(nThreads, nThreads,</span><br><span class="line">                                  <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                  <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里就需要继续说下Java的堵塞队列。Java中的<code>BlockingQueue</code>主要的实现方式是<code>ArrayBlockingQueue</code>，<code>LinkedBlockingQueue</code>。ArrayBlockingQueue是一个用数组实现的有界的阻塞队列，必须设置容量。但是我们默认的LinkedBlockingQueue是一个用链表实现的有界阻塞队列，容量可以选择行进行设置，不设置的话，就是一个无边界的阻塞队列，最大长度为<code>Integer.MAX_VALUE</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates a &#123;<span class="doctag">@code</span> LinkedBlockingQueue&#125; with a capacity of</span></span><br><span class="line"><span class="comment"> * &#123;<span class="doctag">@link</span> Integer#MAX_VALUE&#125;.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LinkedBlockingQueue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(Integer.MAX_VALUE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以就很简单的找到了问题所在，不设置LinkedBlockingQueue容量大小的话就是默认是Integer.MAX_VALUE。而最开始创建newFixedThreadPool时候，并没有可以指定的字段。所以出现OOM是正常的，阿里巴巴Java开发手册中不允许使用 Executors 去创建是正常的。 那我们想使用线程池怎么去创建呢？</p><h5 id="创建线程池的正确姿势"><a href="#创建线程池的正确姿势" class="headerlink" title="创建线程池的正确姿势"></a>创建线程池的正确姿势</h5><p>我们继续往前看newFixedThreadPool是怎么实现的那段源码，继续敲第三个关键词：<code>ThreadPoolExecutor</code>，是直接返回ThreadPoolExecutor对象，创建包含各个字段信息，其中就有LinkedBlockingQueue。那我们能不能直接调用ThreadPoolExecutor的构造函数来自己创建线程池，在创建的同时，给LinkedBlockingQueue指定容量呢？这个问答必须是Yes。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> ExecutorService executor = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">5</span>, <span class="number">200</span>, <span class="number">0L</span>, </span><br><span class="line">TimeUnit.MILLISECONDS, <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;(<span class="number">1024</span>));</span><br></pre></td></tr></table></figure><p>如上代码直接调用ThreadPoolExecutor来自己创建线程池。我们替换掉前面写的Demo中创建的方式，启动运行，结果如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">&quot;main&quot;</span> java.util.concurrent.RejectedExecutionException: Task org.pross.threadPool.subThreadPool@2e5d6d97 rejected from java.util.concurrent.ThreadPoolExecutor@238e0d81[Running, pool size = <span class="number">200</span>, active threads = <span class="number">200</span>, queued tasks = <span class="number">1024</span>, completed tasks = <span class="number">0</span>]</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:<span class="number">2063</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:<span class="number">830</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:<span class="number">1379</span>)</span><br><span class="line">at org.pross.threadPool.ThreadPoolExecutorDemo.main(ThreadPoolExecutorDemo.java:<span class="number">18</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>结果还是有问题，和上次不同的是，这次是抛出的异常信息，但是异常（Exception）总比发生错误（Error）要好，敲黑板划一下第四个关键词：<code>ThreadPoolExecutor$AbortPolicy.rejectedExecution</code>。这个关键词代表的信息很简单，是因为当前线程池使用的队列是有边界队列，队列已经满了便无法继续处理新的请求，所以就会抛出rejectedExecution，所以这次打印输出只到<code>Thread count：1224</code>，1224即队列最大数加上最大线程池数之和。</p><h4 id="线程池的前因"><a href="#线程池的前因" class="headerlink" title="线程池的前因"></a>线程池的前因</h4><p>如果只看结果和使用，那么到这里就结束了。如果我们深入思考一步，发现这个BlockingQueue队列似乎最开始就默认需要了，但是为什么需要队列，Have you thought about it？这个就要道道线程池的工作原理。</p><h5 id="我们需要了解的Java线程池工作原理"><a href="#我们需要了解的Java线程池工作原理" class="headerlink" title="我们需要了解的Java线程池工作原理"></a>我们需要了解的Java线程池工作原理</h5><p>线程池内的线程数的大小相关的概念有两个，一个是核心池大小（corePoolSize），还有最大线程池大小（maximumPoolSize）。如果当前的线程个数比核心池个数小，当线程任务到来，会优先创建一个新的线程并执行任务。当已经到达核心池大小，则把任务放入队列，为了资源不被耗尽，队列的最大容量可能也是有上限的，如果达到队列上限则考虑继续创建新线程执行任务，如果此刻线程的个数已经到达最大线程池的上限话，则考虑把任务丢弃。</p><p>然后我从网上随便找了张图，放到这方便理解。</p><p><img src="Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%5CThreadPool.png"></p><p>所以这就比较方便理解上面调用ThreadPoolExecutor来自己创建线程池中的一些参数了。当然，ThreadPoolExecutor的构造函数有四种，我选取一个参数最完整的构造方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                              <span class="keyword">int</span> maximumPoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                              <span class="keyword">long</span> keepAliveTime,</span></span></span><br><span class="line"><span class="function"><span class="params">                              TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">                              BlockingQueue&lt;Runnable&gt; workQueue,</span></span></span><br><span class="line"><span class="function"><span class="params">                              ThreadFactory threadFactory,</span></span></span><br><span class="line"><span class="function"><span class="params">                              RejectedExecutionHandler handler)</span></span></span><br></pre></td></tr></table></figure><p>那一起来看一下这些参数的具体意思。</p><p><strong>corePoolSize</strong>：核心池大小，需要注意的是在初创建线程池时线程不会立即启动，直到有任务提交才开始启动线程并逐渐时线程数目达到corePoolSize。若想一开始就创建所有核心线程需调用<code>prestartAllCoreThreads</code>方法。</p><p><strong>maximumPoolSize</strong>：池中允许的最大线程数。需要注意的是当核心线程满且阻塞队列也满时才会判断当前线程数是否小于最大线程数，并决定是否创建新线程。</p><p><strong>keepAliveTime</strong>：当线程数大于核心时，多于的空闲线程最多存活时间。</p><p><strong>unit</strong> ：keepAliveTime 参数的时间单位。</p><p><strong>workQueue</strong> ：当线程数目超过核心线程数时用于保存任务的队列。主要有3种类型的BlockingQueue可供选择：无界队列，有界队列和同步移交。（重要）</p><p><strong>threadFactory</strong> ：执行程序创建新线程时使用的工厂。</p><p><strong>handler</strong> ：阻塞队列已满且线程数达到最大值时所采取的饱和策略。java默认提供了4种饱和策略的实现方式：中止、抛弃、抛弃最旧的、调用者运行。将在下文中详细阐述。（重要）</p><p>我们选取比较复杂和重要的两个参数来介绍一下。（我也是翻阅的资料）</p><h5 id="阻塞队列BlockingQueue"><a href="#阻塞队列BlockingQueue" class="headerlink" title="阻塞队列BlockingQueue"></a>阻塞队列BlockingQueue</h5><p>如果运行的线程少于corePoolSize，则Executor会首先添加新的线程直接去运行，不会进入BlockingQueue排队等候；如果运行的线程大于等于corePoolSize，则Executor就会将新任务请求加入BlockingQueue排队等候。而BlockingQueue主要有三种类型：<code>无界队列</code>，<code>有界队列</code>，<code>同步移交队列</code>。</p><p><strong>无界队列</strong></p><p>队列的大小无限制，就是前面提到过不指定容量默认使用的LinkedBlockingQueue，如果不指定容量大小的话，当任务线程池中耗时较长就会导致大量新任务在队列中堆积导致OOM。</p><p><strong>有界队列</strong></p><p>有界队列也存在两类：遵循FIFO原则的队列（ArrayBlockingQueue，LinkedBlockingQueue）和优先级队列（PriorityBlockingQueue），优先级由任务的Comparator决定。使用有界队列时队列大小需要和线程池大小相配合，线程池较小，有界队列较大时可以减少内存消耗，降低CPU使用率，但是会限制QPS。</p><p><strong>同步移交队列</strong></p><p>如果不希望任务在队列中等待而是希望将任务直接移交给工作线程，可使用<code>SynchronousQueue</code>作为等待队列。SynchronousQueue不是一个真正的队列，而是一种线程之间移交的机制。要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素。只有在使用无界线程池或者有饱和策略时才建议使用该队列。</p><h5 id="饱和策略RejectedExecutionHandler"><a href="#饱和策略RejectedExecutionHandler" class="headerlink" title="饱和策略RejectedExecutionHandler"></a>饱和策略RejectedExecutionHandler</h5><p>JDK提供四种饱和策略，都作为静态内部类在ThreadPoolExcutor中进行实现。</p><p><strong>AbortPolicy终止策略</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">AbortPolicy</span> <span class="keyword">implements</span> <span class="title">RejectedExecutionHandler</span> </span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="title">AbortPolicy</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">     <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * Always throws RejectedExecutionException.</span></span><br><span class="line"><span class="comment">      *</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> r the runnable task requested to be executed</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> e the executor attempting to execute this task</span></span><br><span class="line"><span class="comment">      * <span class="doctag">@throws</span> RejectedExecutionException always</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">         <span class="keyword">throw</span> <span class="keyword">new</span> RejectedExecutionException(<span class="string">&quot;Task &quot;</span> + r.toString() +</span><br><span class="line">                                              <span class="string">&quot; rejected from &quot;</span> +</span><br><span class="line">                                              e.toString());</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>通过代码可以看出，该策略是默认饱和策略。使用该策略时在饱和时会抛出RejectedExecutionException（继承自RuntimeException），调用者可捕获该异常自行处理。</p><p><strong>DiscardPolicy抛弃策略</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">DiscardPolicy</span> <span class="keyword">implements</span> <span class="title">RejectedExecutionHandler</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DiscardPolicy</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Does nothing, which has the effect of discarding task r.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> r the runnable task requested to be executed</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> e the executor attempting to execute this task</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不作任何处理，相当于直接抛弃任务。</p><p><strong>DiscardOldestPolicy抛弃旧任务策略</strong></p><p>如代码，先将阻塞队列中的头元素出队抛弃（poll），再尝试提交任务（execute）。如果此时阻塞队列使用PriorityBlockingQueue优先级队列，将会导致优先级最高的任务被抛弃，因此不建议将该种策略配合优先级队列使用。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">DiscardOldestPolicy</span> <span class="keyword">implements</span> <span class="title">RejectedExecutionHandler</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DiscardOldestPolicy</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Obtains and ignores the next task that the executor</span></span><br><span class="line"><span class="comment">     * would otherwise execute, if one is immediately available,</span></span><br><span class="line"><span class="comment">     * and then retries execution of task r, unless the executor</span></span><br><span class="line"><span class="comment">     * is shut down, in which case task r is instead discarded.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> r the runnable task requested to be executed</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> e the executor attempting to execute this task</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!e.isShutdown()) &#123;</span><br><span class="line">            e.getQueue().poll();</span><br><span class="line">            e.execute(r);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>CallerRunsPolicy调用者运行策略</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">CallerRunsPolicy</span> <span class="keyword">implements</span> <span class="title">RejectedExecutionHandler</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CallerRunsPolicy</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Executes task r in the caller&#x27;s thread, unless the executor</span></span><br><span class="line"><span class="comment">     * has been shut down, in which case the task is discarded.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> r the runnable task requested to be executed</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> e the executor attempting to execute this task</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!e.isShutdown()) &#123;</span><br><span class="line">            r.run();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>既不抛弃任务也不抛出异常，直接运行任务的run方法，换言之将任务回退给调用者来直接运行。使用该策略时线程池饱和后将由调用线程池的主线程自己来执行任务，因此在执行任务的这段时间里主线程无法再提交新任务，从而使线程池中工作线程有时间将正在处理的任务处理完成。</p><p>Java线程池就介绍到这里。</p><p>完。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;虽然之前学习了不少相关知识，但是只有在实践中踩坑才能印象深刻。今天看了半天的java对线程池的处理，额外兴致来，周五总结一份java线程池相关。&lt;/p&gt;</summary>
    
    
    
    
    <category term="技术" scheme="https://pross.space/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>大O表示法</title>
    <link href="https://pross.space/blog/2018/12/16/big-o-notation.html"/>
    <id>https://pross.space/blog/2018/12/16/big-o-notation.html</id>
    <published>2018-12-16T14:44:52.000Z</published>
    <updated>2021-01-30T07:11:57.766Z</updated>
    
    <content type="html"><![CDATA[<p>前面有两篇总结了排序算法，最近刚好在看《算法图解》，想由表及里整理一份算法系列。每次介绍算法时，都会讨论其运行时间，一般而言，应选择效率最高的算法，以最大限度地减少运行时间或占用空间。那怎么表示算法的速度呢，今天来了解一下：大O表示法。</p><h5 id="理解大O表示法"><a href="#理解大O表示法" class="headerlink" title="理解大O表示法"></a>理解大O表示法</h5><p>大O表示法是一种特殊的表示法，指出了算法的速度有多快。我们举个例子：假设列表包含n个元素，简单的查询需要检查每个元素，因此需要执行n次操作。使用大O表示法，这个运行时间为：O(n)。单位？没有，大O表示法指的是算法运行时间的增速，不需要单位来描述。</p><a id="more"></a><p>我们再来看一个例子：为检查长度为n的列表元素，我们来使用二分查找，需要执行(log n)次操作。那么使用大O表示法，这个运行时间为：O(log n)，这指出了算法需要执行的操作数。</p><h5 id="大O表示法指出最糟糕情况下的运行时间"><a href="#大O表示法指出最糟糕情况下的运行时间" class="headerlink" title="大O表示法指出最糟糕情况下的运行时间"></a>大O表示法指出最糟糕情况下的运行时间</h5><p>又举个例子：假如使用简单查找的方法，上面说过，简单查找的运行时间为O(n)，这意味着在最糟的情况下，必须查看每一个元素。如果我们要找到1024这个数字，刚好第一个数字就是我们要找的，那这种算法的运行时间是O(n)还是O(1)呢？这里我们总结一下，简单查找的运行时间总是为O(n)，查找1024元素时，一次就找到了，这是最佳的情况，但大O表示法表示的是最糟的情形。我们可以这样说：简单查找的运行时间不可能超过O(n)。</p><blockquote><p>除了最糟的情况下的运行时间，我们还得考虑平均情况的运行时间。</p></blockquote><h4 id="一些常见的大O的运行时间"><a href="#一些常见的大O的运行时间" class="headerlink" title="一些常见的大O的运行时间"></a>一些常见的大O的运行时间</h4><ul><li>O(log n)，也叫<code>对数时间</code>，这样的算法包括二分查找。</li><li>O(n)，也叫<code>线性时间</code>，这样的算法包括简单查找。</li><li>O(n * log n)，这样的算法包括快速排序。</li><li>O(n^2)，这样的算法包括选择排序。</li><li>O(n!)，这样的算法包括旅行商问题的解决方案，也是我即将学习的。</li><li>……</li></ul><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>当然了，我们在前面是将大O运行时间表示转换为操作数来理解，我们小结一下：</p><ul><li>算法的速度指的并非时间，而是操作数的增速。</li><li>谈论算法的速度时，我们说的是随着输入的增加，其运行时间将以什么样的速度增加。</li><li>算法的运行时间用法大O表示法表示。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前面有两篇总结了排序算法，最近刚好在看《算法图解》，想由表及里整理一份算法系列。每次介绍算法时，都会讨论其运行时间，一般而言，应选择效率最高的算法，以最大限度地减少运行时间或占用空间。那怎么表示算法的速度呢，今天来了解一下：大O表示法。&lt;/p&gt;
&lt;h5 id=&quot;理解大O表示法&quot;&gt;&lt;a href=&quot;#理解大O表示法&quot; class=&quot;headerlink&quot; title=&quot;理解大O表示法&quot;&gt;&lt;/a&gt;理解大O表示法&lt;/h5&gt;&lt;p&gt;大O表示法是一种特殊的表示法，指出了算法的速度有多快。我们举个例子：假设列表包含n个元素，简单的查询需要检查每个元素，因此需要执行n次操作。使用大O表示法，这个运行时间为：O(n)。单位？没有，大O表示法指的是算法运行时间的增速，不需要单位来描述。&lt;/p&gt;</summary>
    
    
    
    
    <category term="数据结构" scheme="https://pross.space/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>你所忽视的排序算法（下）</title>
    <link href="https://pross.space/blog/2018/11/11/sorting-algorithm-that-you-overlooked-below.html"/>
    <id>https://pross.space/blog/2018/11/11/sorting-algorithm-that-you-overlooked-below.html</id>
    <published>2018-11-11T10:13:16.000Z</published>
    <updated>2021-01-30T07:11:57.305Z</updated>
    
    <content type="html"><![CDATA[<p>你所不知道的排序算法下篇更新啦，相比于上篇介绍的，下篇的几种排序算法相对来说比较少见。最近也花了一点时间来理解。话不多说，我们进入正文。</p><p>今天出场的是：快速排序，堆排序，计数排序，桶排序。</p><a id="more"></a><h4 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h4><p>快速排序（Quicksort），又称划分交换排序（partition-exchange sort），简称<strong>快排</strong>。最早是由东尼·霍尔提出来。快速排序的基本思想是使用<a href="https://zh.wikipedia.org/wiki/%E5%88%86%E6%B2%BB%E6%B3%95">分治法</a>（Divide and conquer）策略来把一个<a href="https://zh.wikipedia.org/wiki/%E5%BA%8F%E5%88%97">序列</a>（list）分为两个子序列（sub-lists）。其中一个序列关键字均比另一个序列关键字小，则可分别对这两个子序列继续进行排序，已达到整个序列有序。</p><h5 id="逻辑描述"><a href="#逻辑描述" class="headerlink" title="逻辑描述"></a>逻辑描述</h5><ul><li>从数列中挑出一个元素，称为“基准”（pivot）</li><li>重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任何一边）。在这个分割结束之后，该基准就处于数列的中间位置。这个称为<strong>分割（partition）</strong>操作。</li><li><a href="https://zh.wikipedia.org/wiki/%E9%80%92%E5%BD%92">递归</a>地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序</li></ul><p>递归到最底部时，数列的大小是零或一，也就是已经排序好了。这个算法一定会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。</p><h5 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">quickSort</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> head, <span class="keyword">int</span> tail)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (head &gt;= tail || arr == <span class="keyword">null</span> || arr.length &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> i = head, j = tail;</span><br><span class="line">    <span class="keyword">int</span> pivot = arr[(head + tail) / <span class="number">2</span>];</span><br><span class="line">        <span class="keyword">while</span> (i &lt;= j) &#123;</span><br><span class="line">            <span class="keyword">while</span> (arr[i] &lt; pivot) &#123;</span><br><span class="line">                ++i;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">while</span> (arr[j] &gt; pivot) &#123;</span><br><span class="line">                --j;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; j) &#123;</span><br><span class="line">                <span class="keyword">int</span> t = arr[i];</span><br><span class="line">                arr[i] = arr[j];</span><br><span class="line">                arr[j] = t;</span><br><span class="line">                ++i;</span><br><span class="line">                --j;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (i == j) &#123;</span><br><span class="line">                ++i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        quickSort(arr, head, j);</span><br><span class="line">        quickSort(arr, i, tail);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a>算法分析</h4><p>快速排序是<a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91">二叉查找树</a>（二叉搜索树）的一个空间最优化版本。不是循序地把数据项插入到一个明确的树中，而是由快速排序组织这些数据项到一个由递归调用所隐含的树中。快速排序的最直接竞争者是<a href="https://zh.wikipedia.org/wiki/%E5%A0%86%E6%8E%92%E5%BA%8F">堆排序</a>（Heapsort）。堆排序比快速排序稍微慢，但是最坏情况的运行时间总是<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9d2320768fb54880ca4356e61f60eb02a3f9d9f1" alt="{\displaystyle O(n\log n)}"></p><h4 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h4><p>堆排序（Heapsort）是指利用<a href="https://zh.wikipedia.org/wiki/%E5%A0%86_(%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)">堆</a>这种数据结构所设计的一种排序算法。堆是一个近似<a href="https://zh.wikipedia.org/wiki/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91">完全二叉树</a>的结构，并同时满足堆积的性质：即子节点的键值或索引总是小于（或者大于）它的父节点。</p><p>这里多一句嘴来帮助理解一下堆有关的操作。</p><p>堆节点的访问：通常堆是通过一维数组来实现的，在数组起始位置为0的情况下：</p><ul><li>父节点i的左子节点在位置2i+1；</li><li>父节点i的右子节点在位置2i+2；</li><li>子节点i的父节点在位置floor((i-1)/2)；</li></ul><p>堆的操作：在堆的数据结构中，堆中的最大值总是位于根节点（在优先队列中使用堆的话，队中的最小值位于根节点）。堆中定义一下几种操作：</p><ul><li>最大堆调整（Max Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点</li><li>创建最大堆（Build Max Heap）：将堆中的所有数据重新排序</li><li>堆排序（Heap Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算</li></ul><h5 id="逻辑描述-1"><a href="#逻辑描述-1" class="headerlink" title="逻辑描述"></a>逻辑描述</h5><ul><li>将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区</li><li>将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]&lt;=r[n]</li><li>由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成</li></ul><h5 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.pross.sort;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Author: shawn pross</span></span><br><span class="line"><span class="comment"> * Date: 2018/11/9</span></span><br><span class="line"><span class="comment"> * Description: 堆排序</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HeapSort</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span>[] arr;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">HeapSort</span><span class="params">(<span class="keyword">int</span>[] arr)</span></span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.arr = arr;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             *  第一步：将数组堆化</span></span><br><span class="line"><span class="comment">             *  beginIndex = 第一个非叶子节点。</span></span><br><span class="line"><span class="comment">             *  从第一个非叶子节点开始即可。无需从最后一个叶子节点开始。</span></span><br><span class="line"><span class="comment">             *  叶子节点可以看作已符合堆要求的节点，根节点就是它自己且自己以下值为最大。</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">int</span> len = arr.length - <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">int</span> beginIndex = (len - <span class="number">1</span>) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = beginIndex; i &gt;= <span class="number">0</span>; i--)&#123;</span><br><span class="line">                maxHeapify(i, len);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * 第二步：对堆化数据排序</span></span><br><span class="line"><span class="comment">             * 每次都是移出最顶层的根节点A[0]，与最尾部节点位置调换，同时遍历长度 - 1。</span></span><br><span class="line"><span class="comment">             * 然后从新整理被换到根节点的末尾元素，使其符合堆的特性。</span></span><br><span class="line"><span class="comment">             * 直至未排序的堆长度为 0。</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = len; i &gt; <span class="number">0</span>; i--)&#123;</span><br><span class="line">                swap(<span class="number">0</span>, i);</span><br><span class="line">                maxHeapify(<span class="number">0</span>, i - <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">            <span class="keyword">int</span> temp = arr[i];</span><br><span class="line">            arr[i] = arr[j];</span><br><span class="line">            arr[j] = temp;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**堆调整</span></span><br><span class="line"><span class="comment">         * 调整索引为 index 处的数据，使其符合堆的特性。</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> index 需要堆化处理的数据的索引</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> len 未排序的堆（数组）的长度</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">maxHeapify</span><span class="params">(<span class="keyword">int</span> index,<span class="keyword">int</span> len)</span></span>&#123;</span><br><span class="line">            <span class="comment">// 左子节点索引</span></span><br><span class="line">            <span class="keyword">int</span> li = (index &lt;&lt; <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">            <span class="comment">// 右子节点索引</span></span><br><span class="line">            <span class="keyword">int</span> ri = li + <span class="number">1</span>;</span><br><span class="line">            <span class="comment">// 子节点值最大索引，默认左子节点。</span></span><br><span class="line">            <span class="keyword">int</span> cMax = li;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 左子节点索引超出计算范围，直接返回。</span></span><br><span class="line">            <span class="keyword">if</span>(li &gt; len) <span class="keyword">return</span>;</span><br><span class="line">            <span class="comment">// 先判断左右子节点，哪个较大。</span></span><br><span class="line">            <span class="keyword">if</span>(ri &lt;= len &amp;&amp; arr[ri] &gt; arr[li])</span><br><span class="line">                cMax = ri;</span><br><span class="line">            <span class="keyword">if</span>(arr[cMax] &gt; arr[index])&#123;</span><br><span class="line">                <span class="comment">// 如果父节点被子节点调换，</span></span><br><span class="line">                swap(cMax, index);</span><br><span class="line">                <span class="comment">// 则需要继续判断换下后的父节点是否符合堆的特性。</span></span><br><span class="line">                maxHeapify(cMax, len);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">3</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">8</span>,<span class="number">6</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">7</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">7</span>,<span class="number">4</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">6</span>&#125;;</span><br><span class="line">            <span class="keyword">new</span> HeapSort(arr).sort();</span><br><span class="line">            System.out.println(Arrays.toString(arr));</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序</h4><p><strong>计数排序</strong>（CountingSort）是一种稳定的<a href="https://zh.wikipedia.org/wiki/%E7%B7%9A%E6%80%A7%E6%99%82%E9%96%93">线性时间</a><a href="https://zh.wikipedia.org/wiki/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95">排序算法</a>。其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中，作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。</p><h5 id="逻辑描述-2"><a href="#逻辑描述-2" class="headerlink" title="逻辑描述"></a>逻辑描述</h5><ul><li>找出待排序的数组中最大和最小的元素</li><li>统计数组中每个值为i的元素出现的次数，存入数组C的第i项</li><li>对所有的计数累加（从数组C中的第一个元素开始，每一项和前一项相加）</li><li>反向填充目标数组：将每个元素i在新数组的第C(i)项，每放一个元素就将C(i)减去1</li></ul><h5 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.pross.sort;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Author: shawn pross</span></span><br><span class="line"><span class="comment"> * Date: 2018/11/9</span></span><br><span class="line"><span class="comment"> * Description: 计数排序</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountingSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] countingSort(<span class="keyword">int</span>[] A) &#123;</span><br><span class="line">        <span class="keyword">int</span>[] B = <span class="keyword">new</span> <span class="keyword">int</span>[A.length];</span><br><span class="line">        <span class="comment">// 假设A中的数据a&#x27;有，0&lt;=a&#x27; &amp;&amp; a&#x27; &lt; k并且k=100</span></span><br><span class="line">        <span class="keyword">int</span> k = <span class="number">100</span>;</span><br><span class="line">        countingSort(A, B, k);</span><br><span class="line">        <span class="keyword">return</span> B;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">countingSort</span><span class="params">(<span class="keyword">int</span>[] A, <span class="keyword">int</span>[] B, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] C = <span class="keyword">new</span> <span class="keyword">int</span>[k];</span><br><span class="line">        <span class="comment">// 计数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; A.length; j++) &#123;</span><br><span class="line">            <span class="keyword">int</span> a = A[j];</span><br><span class="line">            C[a] += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 求计数和</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; k; i++) &#123;</span><br><span class="line">            C[i] = C[i] + C[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 整理</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = A.length - <span class="number">1</span>; j &gt;= <span class="number">0</span>; j--) &#123;</span><br><span class="line">            <span class="keyword">int</span> a = A[j];</span><br><span class="line">            B[C[a] - <span class="number">1</span>] = a;</span><br><span class="line">            C[a] -= <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] A = CountingSort.countingSort(<span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">16</span>, <span class="number">4</span>, <span class="number">10</span>, <span class="number">14</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">1</span>&#125;);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> digint : A) &#123;</span><br><span class="line">            System.out.print(digint + <span class="string">&quot;,&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="算法分析-1"><a href="#算法分析-1" class="headerlink" title="算法分析"></a>算法分析</h5><p>计数排序是一个稳定的排序算法。当输入的元素是n个0到k之间的整数时，时间复杂度是O(n+k)，空间复杂度也是O(n+k)，其排序速度快于任何比较排序算法。</p><h4 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h4><p><strong>桶排序</strong>（Bucket sort）或所谓的<strong>箱排序</strong>，是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。</p><h5 id="逻辑描述-3"><a href="#逻辑描述-3" class="headerlink" title="逻辑描述"></a>逻辑描述</h5><ul><li>设置一个定量的数组当作空桶</li><li>遍历输入数据，并且把数据一个一个放到对应的桶里去</li><li>对每个不是空的桶进行排序</li><li>从不是空的桶里把排好序的数据拼接起来。</li></ul><h5 id="代码实现-3"><a href="#代码实现-3" class="headerlink" title="代码实现"></a>代码实现</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.pross.sort;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Author: shawn pross</span></span><br><span class="line"><span class="comment"> * Date: 2018/11/10</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BucketSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">indexFor</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> min, <span class="keyword">int</span> step)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (a - min) / step;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] bucketSort(<span class="keyword">int</span>[] array) &#123;</span><br><span class="line">        <span class="keyword">int</span> max = array[<span class="number">0</span>], min = array[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> a : array) &#123;</span><br><span class="line">            <span class="keyword">if</span> (max &lt; a)</span><br><span class="line">                max = a;</span><br><span class="line">            <span class="keyword">if</span> (min &gt; a)</span><br><span class="line">                min = a;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// bucketNum的值可以根据实际情况选择</span></span><br><span class="line">        <span class="keyword">int</span> bucketNum = max / <span class="number">10</span> - min / <span class="number">10</span> + <span class="number">1</span>;</span><br><span class="line">        List buckList = <span class="keyword">new</span> ArrayList&lt;List&lt;Integer&gt;&gt;();</span><br><span class="line">        <span class="comment">// create bucket</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= bucketNum; i++) &#123;</span><br><span class="line">            buckList.add(<span class="keyword">new</span> ArrayList&lt;Integer&gt;());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// push into the bucket</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; array.length; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> index = indexFor(array[i], min, <span class="number">10</span>);</span><br><span class="line">            ((ArrayList&lt;Integer&gt;) buckList.get(index)).add(array[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        ArrayList&lt;Integer&gt; bucket = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; bucketNum; i++) &#123;</span><br><span class="line">            bucket = (ArrayList&lt;Integer&gt;) buckList.get(i);</span><br><span class="line">            insertSort(bucket);</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> k : bucket) &#123;</span><br><span class="line">                array[index++] = k;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> array;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 把桶內元素插入排序</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">insertSort</span><span class="params">(List&lt;Integer&gt; bucket)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; bucket.size(); i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> temp = bucket.get(i);</span><br><span class="line">            <span class="keyword">int</span> j = i - <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span> (; j &gt;= <span class="number">0</span> &amp;&amp; bucket.get(j) &gt; temp; j--) &#123;</span><br><span class="line">                bucket.set(j + <span class="number">1</span>, bucket.get(j));</span><br><span class="line">            &#125;</span><br><span class="line">            bucket.set(j + <span class="number">1</span>, temp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] array = &#123;<span class="number">100</span>, <span class="number">93</span>, <span class="number">97</span>, <span class="number">92</span>, <span class="number">96</span>, <span class="number">99</span>, <span class="number">92</span>, <span class="number">89</span>, <span class="number">93</span>, <span class="number">97</span>, <span class="number">90</span>, <span class="number">94</span>, <span class="number">92</span>, <span class="number">95</span>&#125;;</span><br><span class="line">        <span class="keyword">int</span>[] sort = bucketSort(array);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> digint:sort)&#123;</span><br><span class="line">            System.out.print(digint+<span class="string">&quot;,&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="算法分析-2"><a href="#算法分析-2" class="headerlink" title="算法分析"></a>算法分析</h5><p>桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;你所不知道的排序算法下篇更新啦，相比于上篇介绍的，下篇的几种排序算法相对来说比较少见。最近也花了一点时间来理解。话不多说，我们进入正文。&lt;/p&gt;
&lt;p&gt;今天出场的是：快速排序，堆排序，计数排序，桶排序。&lt;/p&gt;</summary>
    
    
    
    
    <category term="算法" scheme="https://pross.space/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>你所忽视的排序算法（上）</title>
    <link href="https://pross.space/blog/2018/10/27/sorting-algorithm-that-you-overlooked-on.html"/>
    <id>https://pross.space/blog/2018/10/27/sorting-algorithm-that-you-overlooked-on.html</id>
    <published>2018-10-27T15:12:58.000Z</published>
    <updated>2021-01-30T07:11:57.011Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>算法（algorithm），在数学（算学）和计算机科学之中，为任何良定义的具体计算步骤的一个序列，常用语计算，数据处理和自动推理。精确而言，算法是一个表示为有限长列表的有效方法。算法应包含清晰定义的指令用于计算函数。</p><p>——<a href="https://zh.wikipedia.org/wiki/%E7%AE%97%E6%B3%95">维基百科</a></p></blockquote><p>程序猿圈子里似乎都默然这样的一个等式：程序=数据结构+算法。思考起来，就感觉相当于：作文=语法+词语。这句话相当出名，因为这是1986年尼古拉斯赵四（逃）在获得图灵奖时说的一句话，现在听起来，似乎没有什么不正确的。当然，这就好比当年牛顿在1687年提出万有引力一样，现在看起来是废话一样，但是当时这句话确定奠定了程序的基础概念。</p><a id="more"></a><p>所以我们就来讲讲算法，那么问题来了，什么是算法呢？喏，开头已经引用了维基百科的对算法的定义，下面接而来了一段解释：</p><blockquote><p>算法中的指令描述的是一个<a href="https://zh.wikipedia.org/wiki/%E8%A8%88%E7%AE%97">计算</a>，当其运行时能从一个初始状态和初始输入（可能为空）开始，经过一系列<strong>有限</strong>而清晰定义的状态最终产生<strong>输出</strong>并<strong>停止</strong>于一个终态。一个状态到另一个状态的转移不一定是确定的。随机化算法在内的一些算法，包含了一些随机输入。</p></blockquote><p>看懂了吗？别急别急，没看懂没关系，我也不是很理解；不过没关系，我们用一句通俗的话来阐释一下：<strong>算法（Algorithm）就是解决问题的方法</strong>。所以我们就这样来理解就好了。</p><p>在InfoQ上有一篇文章《计算机科学最重要的32个算法》，介绍了二分查找法（Binary Search），快速傅里叶变换（Fast Fourier transform，FFT），哈希算法（Hashing），堆排序（Heaps）等等，有兴趣的可以看看。当然，我也是在学习中。今天这篇文章是算法系列的第一篇，我们先从排序算法（Sort）开始。</p><p>计划是来介绍十大常见的排序算法，为了控制文章篇幅，分上下两篇来介绍，一些算法定义解释和动态图过程分析展示大多来自于自由全面的维基百科。此文为上篇，介绍算法引入排序以及介绍部分简单的排序算法。下篇介绍剩余的排序算法和下一章预告。</p><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><p>排序算法大致可以分为两大类：<strong>非线性时间比较类排序和线性时间非比较类</strong>。前者是通过比较来决定元素间的次序，其时间复杂度不能突破O（nlogn）；后者不通过比较来决定元素间的次序，但是可以突破基于比较排序的时间下界，以线性时间运行。有点数学基础的各位看官很好理解线性和非线性的区别，以及过程中会提到复杂度，这里不在赘述，以后有机会单开一篇介绍。</p><h4 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h4><p>冒泡排序（Bubble Sort）是一种简单的排序算法，常作为程序设计入门算法介绍。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。</p><p><strong>逻辑描述</strong></p><ul><li>比较相邻的元素。如果第一个比第二个大，就交换他们两个。</li><li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。</li><li>针对所有的元素重复以上的步骤，除了最后一个。</li><li>持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。</li></ul><p><strong>代码实现</strong></p><p>比较常见的算法，代码略。</p><h4 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h4><p>选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理如下。首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。</p><p><strong>逻辑描述</strong></p><p>N个记录的直接选择排序可经过N-1趟直接选择排序得到有序结果。</p><ul><li>初始状态：无序区为R[1…n]，有序区为空</li><li>第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R[i..n]。该趟排序从当前无序区中选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区</li><li>n-1趟结束，数组有序化了</li></ul><p><strong>代码实现</strong></p><p>比较常见的算法，代码略。</p><h4 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h4><p><strong>插入排序</strong>（Insertion Sort）是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p><p><strong>逻辑描述</strong></p><p>插入排序在实现上，通常采用in-place排序（即只需用到<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e66384bc40452c5452f33563fe0e27e803b0cc21" alt="{\displaystyle O(1)}">的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。</p><ol><li>从第一个元素开始，该元素可以认为已经被排序</li><li>取出下一个元素，在已经排序的元素序列中从后向前扫描</li><li>如果该元素（已排序）大于新元素，将该元素移到下一位置</li><li>重复步骤3，直到找到已排序的元素小于或者等于新元素的位置</li><li>将新元素插入到该位置后</li><li>重复步骤2~5</li></ol><p><strong>代码实现</strong></p><p>比较常见的算法，代码略。</p><h4 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h4><p>希尔排序（Shell Sort），也称递减增量排序算法，是插入排序的一种更高效的改进版本。</p><p><strong>逻辑描述</strong></p><p>先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：</p><ul><li>选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1</li><li>按增量序列个数k，对序列进行k趟排序</li><li>每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度</li></ul><p><strong>代码实现</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.pross.sort;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@describe</span>:</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:彭爽pross</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>: 2018/10/27</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShellSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] shellSort(<span class="keyword">int</span>[] array) &#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">int</span> j;</span><br><span class="line"><span class="keyword">int</span> temp;</span><br><span class="line"><span class="comment">//自定义间隔序列</span></span><br><span class="line"><span class="keyword">int</span> number = array.length / <span class="number">2</span>;</span><br><span class="line"><span class="keyword">while</span> (number &gt;= <span class="number">1</span>) &#123;</span><br><span class="line"><span class="keyword">for</span> (i = number; i &lt; array.length; i++) &#123;</span><br><span class="line">temp = array[i];</span><br><span class="line">j = i - number;</span><br><span class="line"><span class="keyword">while</span> (j &gt;= <span class="number">0</span> &amp;&amp; array[j] &lt; temp) &#123;</span><br><span class="line">array[j + number] = array[j];</span><br><span class="line">j = j - number;</span><br><span class="line">&#125;</span><br><span class="line">array[j + number] = temp;</span><br><span class="line">&#125;</span><br><span class="line">number = number / <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> array;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>算法分析</strong></p><p>希尔排序是基于插入排序的以下两点性质而提出改进方法的：1.插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率；2.但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位。</p><p>希尔排序的核心在于间隔序列的设定。既可以提前设定好间隔序列，也可以动态的定义间隔序列。动态定义间隔序列的算法是《算法（第4版）》的合著者Robert Sedgewick提出的。</p><h4 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h4><p>归并排序（Merge sort，或mergesort）是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。</p><p><strong>逻辑描述</strong></p><ol><li>将序列每相邻两个数字进行归并操作，形成<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/284284713ad8f1ba13458b896c87efc4b9b7df9c" alt="{\displaystyle ceil(n/2)}">个序列，排序后每个序列包含两/一个元素</li><li>若此时序列数不是一个则将上述序列再次归并，形成<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0f7b6be8e0c402e981a78d573dc3072c3d24a3c4" alt="{\displaystyle ceil(n/4)}">个序列，每个序列包含四/三个元素</li><li>重复第2步操作，直到所有元素排序完毕，即序列数为1</li></ol><p><strong>代码实现</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.pross.sort;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@describe</span>: 归并排序</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:彭爽pross</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>: 2018/10/27</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MergeSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] mergeSort(<span class="keyword">int</span>[] arr) &#123;</span><br><span class="line"><span class="keyword">int</span>[] orderedArr = <span class="keyword">new</span> <span class="keyword">int</span>[arr.length];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; arr.length * <span class="number">2</span>; i *= <span class="number">2</span>) &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; (arr.length + i - <span class="number">1</span>) / i; j++) &#123;</span><br><span class="line"><span class="keyword">int</span> left = i * j;</span><br><span class="line"><span class="keyword">int</span> mid = left + i / <span class="number">2</span> &gt;= arr.length ? (arr.length - <span class="number">1</span>) : (left + i / <span class="number">2</span>);</span><br><span class="line"><span class="keyword">int</span> right = i * (j + <span class="number">1</span>) - <span class="number">1</span> &gt;= arr.length ? (arr.length - <span class="number">1</span>) : (i * (j + <span class="number">1</span>) - <span class="number">1</span>);</span><br><span class="line"><span class="keyword">int</span> start = left, l = left, m = mid;</span><br><span class="line"><span class="keyword">while</span> (l &lt; mid &amp;&amp; m &lt;= right) &#123;</span><br><span class="line"><span class="keyword">if</span> (arr[l] &lt; arr[m]) &#123;</span><br><span class="line">orderedArr[start++] = arr[l++];</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">orderedArr[start++] = arr[m++];</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (l &lt; mid)</span><br><span class="line">orderedArr[start++] = arr[l++];</span><br><span class="line"><span class="keyword">while</span> (m &lt;= right)</span><br><span class="line">orderedArr[start++] = arr[m++];</span><br><span class="line">System.arraycopy(orderedArr, left, arr, left, right - left + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> orderedArr;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>上篇介绍了，冒泡排序，选择排序，插入排序，希尔排序和归并排序。</p><p>所有代码可以在<a href="https://github.com/prosscode/java-learning-case/tree/master/algorithm/src/main/java/org/pross/sort">我的Github</a>查阅。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;算法（algorithm），在数学（算学）和计算机科学之中，为任何良定义的具体计算步骤的一个序列，常用语计算，数据处理和自动推理。精确而言，算法是一个表示为有限长列表的有效方法。算法应包含清晰定义的指令用于计算函数。&lt;/p&gt;
&lt;p&gt;——&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E7%AE%97%E6%B3%95&quot;&gt;维基百科&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;程序猿圈子里似乎都默然这样的一个等式：程序=数据结构+算法。思考起来，就感觉相当于：作文=语法+词语。这句话相当出名，因为这是1986年尼古拉斯赵四（逃）在获得图灵奖时说的一句话，现在听起来，似乎没有什么不正确的。当然，这就好比当年牛顿在1687年提出万有引力一样，现在看起来是废话一样，但是当时这句话确定奠定了程序的基础概念。&lt;/p&gt;</summary>
    
    
    
    
    <category term="算法" scheme="https://pross.space/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>相见</title>
    <link href="https://pross.space/blog/2018/09/28/meet.html"/>
    <id>https://pross.space/blog/2018/09/28/meet.html</id>
    <published>2018-09-28T13:36:25.000Z</published>
    <updated>2021-01-30T07:11:56.765Z</updated>
    
    <content type="html"><![CDATA[<p>分享几个简短的思考和观点。</p><p><strong>关于代码</strong></p><blockquote><p>「为了理解一个简单函数的运行过程，今天的软件工程师可能需要追踪25个文件。因为每个文件都包含一个 Java 方法，它会向另一个文件的另一个方法发消息。为了方便查看20层的堆栈，人们发明了 Eclipse 那样的复杂工具。实际做事的那一行代码，埋藏在数百行胶水代码、无数个接口和其他冗余代码之下。」</p><p>– <a href="http://blogs.harvard.edu/philg/2018/09/18/is-data-scientist-the-new-programmer/">Philip Greenspun</a>，麻省理工学院的计算机教授</p></blockquote><p>插嘴一句，现在还是习惯使用JetBrains家的IDEA，风格简约，爽心悦目。看到很多关于集成开发环境工具好坏的争论，Eclipse什么什么不好，IDEA哪里哪里特别方便，无聊之者，还不如老老实实把BUG解决掉，赶快回家睡觉。</p><p>由Phillip Greenspun的一段话引出，只是非常印证最近的工作。为了理解这个方法函数的功能是什么，不停的追踪发现，不停的向下挖掘，在经历层层封锁之后终于找到了真相，心里带着窃喜，还是要骂咧咧一句：原来你就在这里，原来你是这样实现的，原来你干着这样的事。然后带着些许满足感返回去，继续下一行代码的探索与发现。</p><a id="more"></a><p><strong>关于改变观点</strong></p><p>亚马逊的老板贝佐斯说，「如果一个人经常改变自己的看法，更可能得到正确的观点。」以前没有从这方面角度思考过这个问题，经常改变自己的看法和观点不是立场不确定么？你都不确定自己的观点是否确定怎么值得别人相信你？</p><p>仔细思考贝佐斯的话，还是有一点道理。如今世界变化的太快了，聪明的人都会不断的修改自己对世界的理解，重新考虑自己以前考虑的问题，不断的用汲取的新的知识，新的思维方式来完善自己的观点和看法，然后得出不一样的结论。这样说来，不是意味之前的观点就是错误的，而应该说自己的观点是暂时的，因为我们都在成长，今天的你和昨天的你都会不一样。</p><p>这样理解贝佐斯的话可能更有建造性，「如果一个人经常改变自己过去事情的看法，更可能得到正确的观点。」另外，写完这句话，我对这个观点看法已经改变了。: )</p><p><strong>关于读书</strong></p><p>池老师的<a href="https://book.douban.com/subject/26663519/">MacTalk·跨越边界</a>，已经断断续续在通勤之余已经阅读完。感受还是有一些，另外开篇文章再来说一说。</p><p>我觉得读书是由点及面的成长，现在阅读的这本书为点，书中涉及到的知识，介绍的人物，作者阅读书籍为扩展的面，这是一个循环辐射学习的过程。比如我读完跨越边界，对软件项目的思考，持续学习的观点，时代的技术发展（毕竟池老师是70后程序员）都有一定的感悟和自己的理解；对高晓松的《如丧》，《鱼羊野史》，冯大辉的博客文集，一生只为欢笑的linus，传奇工程师沃兹大神都抱着浓厚的兴趣，这样就是面的展开。</p><p>读书和写博客都引用同一句话，「读书会带来很多好处，却没有任何明显的坏处。」</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;分享几个简短的思考和观点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关于代码&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;「为了理解一个简单函数的运行过程，今天的软件工程师可能需要追踪25个文件。因为每个文件都包含一个 Java 方法，它会向另一个文件的另一个方法发消息。为了方便查看20层的堆栈，人们发明了 Eclipse 那样的复杂工具。实际做事的那一行代码，埋藏在数百行胶水代码、无数个接口和其他冗余代码之下。」&lt;/p&gt;
&lt;p&gt;– &lt;a href=&quot;http://blogs.harvard.edu/philg/2018/09/18/is-data-scientist-the-new-programmer/&quot;&gt;Philip Greenspun&lt;/a&gt;，麻省理工学院的计算机教授&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;插嘴一句，现在还是习惯使用JetBrains家的IDEA，风格简约，爽心悦目。看到很多关于集成开发环境工具好坏的争论，Eclipse什么什么不好，IDEA哪里哪里特别方便，无聊之者，还不如老老实实把BUG解决掉，赶快回家睡觉。&lt;/p&gt;
&lt;p&gt;由Phillip Greenspun的一段话引出，只是非常印证最近的工作。为了理解这个方法函数的功能是什么，不停的追踪发现，不停的向下挖掘，在经历层层封锁之后终于找到了真相，心里带着窃喜，还是要骂咧咧一句：原来你就在这里，原来你是这样实现的，原来你干着这样的事。然后带着些许满足感返回去，继续下一行代码的探索与发现。&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔杂记" scheme="https://pross.space/tags/%E9%9A%8F%E7%AC%94%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>你需要多久才能变成一个&quot;傻瓜&quot;</title>
    <link href="https://pross.space/blog/2018/09/24/how-long-does-it-take-you-to-become-a-fool.html"/>
    <id>https://pross.space/blog/2018/09/24/how-long-does-it-take-you-to-become-a-fool.html</id>
    <published>2018-09-24T10:41:47.000Z</published>
    <updated>2021-01-30T07:11:57.036Z</updated>
    
    <content type="html"><![CDATA[<p>金出武雄（Kanade Takeo）是美国卡内基·梅隆大学（CMU）的机器人视觉研究所所长，也是世界上最重要的计算机是视觉研究人员之一。</p><p><img src="./kanade_takeo_2014.jpg"></p><p>微信之父张小龙在《微信背后的产品观》一文中讲到：“产品经理要有傻瓜心态。”这里的傻瓜并不是真正的傻掉，而是需要有一种外行的心态，保持“stay foolish”。张小龙说，自己需要经过5~10分钟的酝酿才能达到傻瓜状态，马化腾需要1分钟，功力最深的乔布斯可以在专家和傻瓜之间随意切换，来去自如。</p><a id="more"></a><p>最早听到类似的说法是通过池老师在博客中介绍的金出武雄教授。他出版了一本书，名字叫做《像外行一样思考，像专家一样实践》，关于这本书的创作，金教授如是说：</p><blockquote><p>听过我的演讲或言论之后，有很多人表示：“你的话，简直就是谎话，几乎都是谎话、是玩笑、像是真话，是真话，是自吹自擂、虽然很有建设性但……杂七杂八还有点意思。”于是我想，要不要把这些收集起来，写一本书呢？</p></blockquote><p>于是这本书就诞生了，这是一个小插曲。这本书是金教授对其日常研究、生活和学习的经验进行收集整理而成的一本小册子。但其中的内容远不止这些，无论是学术、技术、产品、演讲、写作、互联网、教育、思考的本质等，书中都有所涉猎，并且观点奇特，思路新颖，适合各个创造性领域的人群阅读。</p><p><img src="./book.jpg"></p><p>虽然今天主题是这本书，我还没有看完这本书，但是池老师读了一遍并在<code>mactalk·跨越边界</code>上总结了，我就站在巨人的肩膀上，挑几个思考性的观点，做一下学习思考的笔记。</p><h4 id="Best-First"><a href="#Best-First" class="headerlink" title="Best First"></a>Best First</h4><p>金教授有个观点叫做”Best First“，意为最好东西一定要放在最前面。无论是演讲还是写书，金教授都遵循这个规则。观众或读者都希望开始的时候就看到最好的东西，很多演讲或图书都喜欢做一些冗长的铺垫才进入主题，岂不知那些铺垫已经耗尽了我们观众的耐心。</p><p>这个观点非常的有趣，基于此，我们就知道，书中的核心内容毫无疑问就是第一章：像外行一样思考，像专家一样实践。</p><h4 id="关于反对"><a href="#关于反对" class="headerlink" title="关于反对"></a>关于反对</h4><blockquote><p>明斯基教授，您总是能在各种领域中想出很多创造性的，引人入胜且能够引导新方向的构思。请问您的诀窍是什么呢？</p><p>他回答说：这个很简单，只要反对大家的所说的就可以了。大家都认同的好想法基本上都不太令人满意。</p></blockquote><h4 id="关于迷茫"><a href="#关于迷茫" class="headerlink" title="关于迷茫"></a>关于迷茫</h4><blockquote><p>金教授说：越能干的人越迷茫。</p><p>就算是卡内基·梅隆大学的计算机科学系和机器人研究所的博士研究生，他们出类拔萃无所不能，也避免不了这种感觉。不，应该说，正是这种人，才更容易陷入不安和迷茫。</p></blockquote><p>如果你工作时，经常在”能不能行呢？“的不安感和“啊，成功了！”的成就感之间往复行走，那么恭喜你，离成功已经没有几公里了。交织着这两种感觉的体验将成为你智慧和体力的强有力基石。这也从某种程度上解释了我为什么会经常处于一种迷茫的状态么？</p><h4 id="关于记忆力"><a href="#关于记忆力" class="headerlink" title="关于记忆力"></a>关于记忆力</h4><blockquote><p>日常生活中，对于人的知觉、思考、行动等，追本溯源，最终都会落在记忆上，如果头脑中没有知识和信息作为工具、材料，是不可能发挥规划能力和创造能力的。构思就是通过重组脑海中的记忆而产生的。如果没有良好而广博的记忆内容做基础，根本产生不了什么好的构思。因此，最有效的学习方法就是记忆。把他人长时间思考总结出来的成果记忆下来，不仅高效快捷，也能为自身的思考扩展基础。当然，这里所谓的记忆，是指”经过理解的记忆”，这一点无需多言。</p></blockquote><h4 id="关于颠覆"><a href="#关于颠覆" class="headerlink" title="关于颠覆"></a>关于颠覆</h4><blockquote><p>计算机的发展日新月异。20世纪60年代，计算机像竞赛一样指数发展，但到了20世纪80年代，发展速度减缓，甚至有人说计算机不会再进步了，还举了很多例子：硅晶体上不能画再细的线了，不能制造出更小的晶体管了，硬盘的存储密度不能再增大了，等等。根据这些说法他们得出的结论是：发展瓶颈终将到来。</p></blockquote><p>科学的进步就是不断突破极限和开辟新的领域，每个人的奋斗就是突破自己。</p><h4 id="关于不可能原则"><a href="#关于不可能原则" class="headerlink" title="关于不可能原则"></a>关于不可能原则</h4><blockquote><p>第一条：科学工作者声明某件事情是可行的时候，基本上他不会错。但当他说不可能的时候，他很可能错了。第二条：发现极限在哪里的唯一方法就是超越极限，尝试向稍微超越这个极限的领域迈进、冒险。第三条：无论是哪种技术，只要它是非常先进的，那看起来都跟魔术没什么区别。</p></blockquote><p>如果出现一个想法和创意，看起来不可能实现，实际上你可能错了。如果发现自己的所做的事情已经做到了极限，可以试试超越极限迈进一步。</p><h4 id="关于演讲和交流"><a href="#关于演讲和交流" class="headerlink" title="关于演讲和交流"></a>关于演讲和交流</h4><blockquote><p>在与他人交流的过程中完善自己的想法。无论什么样的构想，最初大都只是个偶然的想法。锤炼构想的方法就是跟他人交流，在交谈中验证是不是一个有价值的想法，并且获取相关知识，修正不完备的地方。升华构想的关键是“交流”，因为他人有很多自己角度的认识和想法，借鉴过来才能完善自己的构想。</p></blockquote><h4 id="创造的基础是模仿"><a href="#创造的基础是模仿" class="headerlink" title="创造的基础是模仿"></a>创造的基础是模仿</h4><blockquote><p>模仿、相似，这样不是很好吗？最初的想法的确是相同的，但在此基础之上添加东西、使之升华的水平高低才是决定胜负的关键。因此，大部分的创造都是在模仿的基础之上增加其附加价值的东西。独创、创造，不是无中生有的魔术。</p></blockquote><p>有一段时间自己非常厌恶<code>CV战士</code>式的工作，总想造点新的轮子或工具。想要创造出的新的东西，那一定是在原有的基础上或思维格局上进行新的改造和发现。</p><p>最后结尾引用池老师的总结。回到最初的问题，如何在专家和傻瓜之间进行自由的切换呢？其实金教授已经写在书里了：</p><p>思考的时候，要像外行一样单纯直接，实践的时候则要像专家一样严密细致，并且要有以专业知识和方法武装起来的“我做得到”的乐观主义精神。要记住，独特的、好的创意和好的结尾，不管是对研究而言，还是对商业运营而言，都不是自己突然冒出来的东西，那一定是刻苦的努力和长期的思考带来的。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;金出武雄（Kanade Takeo）是美国卡内基·梅隆大学（CMU）的机器人视觉研究所所长，也是世界上最重要的计算机是视觉研究人员之一。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;./kanade_takeo_2014.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;微信之父张小龙在《微信背后的产品观》一文中讲到：“产品经理要有傻瓜心态。”这里的傻瓜并不是真正的傻掉，而是需要有一种外行的心态，保持“stay foolish”。张小龙说，自己需要经过5~10分钟的酝酿才能达到傻瓜状态，马化腾需要1分钟，功力最深的乔布斯可以在专家和傻瓜之间随意切换，来去自如。&lt;/p&gt;</summary>
    
    
    
    
    <category term="随笔杂记" scheme="https://pross.space/tags/%E9%9A%8F%E7%AC%94%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
</feed>
