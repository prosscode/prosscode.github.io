<!-- build time:Fri Sep 28 2018 21:41:44 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>理解Spark核心之RDD · PROSS</title><meta name="description" content="理解Spark核心之RDD - RukiapR0ss"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://pross.space/atom.xml" title="PROSS"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/prosscode" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">理解Spark核心之RDD</h1><div class="post-info">May 29, 2018</div><div class="post-content"><p>Spark是围绕RDD的概念展开的，RDD是可以并行操作的容错元素集合。RDD全称是Resilient Distributed Datasets（弹性分布式数据集）</p><a id="more"></a><h4 id="理解RDD"><a href="#理解RDD" class="headerlink" title="理解RDD"></a>理解RDD</h4><p>如果你在Spark集群中加载了一个很大的文本数据，Spark就会将该文本抽象为一个RDD，这个RDD根据你定义的分区策略（比如HashKey）可以分为数个Partition，这样就可以对各个分区进行并行处理，从而提高效率。</p><p>RDD是一个容错的，并行的数据结构，可以让用户显示地将数据存储到磁盘和内存中，并能控制数据的分区。同时，RDD还提供了一组丰富的操作来操作这些数据。在这些操作中，比如Map、flatMap、filter等转换操作实现了monad模式（Monad是一种设计模式，表示将一个运算过程，通过函数拆解成互相连接的多个步骤；你只要提供下一步运算所需的函数，整个运算就会自动进行下去。），很好的切合了Scala的集合操作。另外，RDD还提供了比如join，groupBy，reduceByKey（action操作）等更为方便的操作，用来支持常见的数据运算。</p><p>RDD是一系列只读分区的集合，它只能从文件中读取并创建，或者从旧的RDD生成新的RDD。RDD的每一次变换操作都会生成新的RDD，而不是在原来的基础上进行修改，这种粗粒度的数据操作方式为RDD带来了容错和数据共享方面的优势，但是在面对大数据集中频繁的小操作的时候，显得效率比较低下。</p><h4 id="RDD原理"><a href="#RDD原理" class="headerlink" title="RDD原理"></a>RDD原理</h4><p>RDD实际上是一个类（sc.textFile()方法返回一个RDD对象，然后用line接收这个对象），而这个RDD类中也定义了一系列的用于操作的方法，也就是一些算子操作。</p><p>这个类为了实现对数据的操作，里面有分区信息，用于记录特定RDD的分区情况；依赖关系，指向其父RDD；一个函数，用于记录父RDD到自己的转换操作；划分策略和数据位置的元数据。在DAG中这样的RDD就可以看成一个个节点，RDD中的存储的依赖关系就是DAG的边。在Spark中，数据在物理上被划分为一个个的block，这些block由blockmanager统一管理的。</p><p>在设计RDD之间的依赖关系时，设计者将RDD之间的依赖关系分为两类：窄依赖和宽依赖。RDD作为数据结构，本质上是一个只读的分区记录集合。一个RDD可以包含多个分区，每个分区就是一个DataSet片段。RDD可以相互依赖，如果RDD的每个分区最多只能被一个Child RDD的一个分区使用，则称之位narrow dependency（窄依赖）；若多个Child RDD分区都可以依赖，则称为wide dependency（宽依赖），而join操作则会产生wide dependency。</p><p><img src="/archives/2018/05/29/narrowAndwide.jpg" alt="narrow和wide"></p><p><img src="/archives/2018/05/29/rdd-dependencies.png" alt="narrow和wide的区别"></p><blockquote><p>Spark之所以将依赖分为narrow与wide，基于以下两点原因：</p><p>narrow dependecies可以支持在同一个cluster node上，并且以管道形式执行多行命令，例如在执行了map操作后，紧接着执行filter。相反，wide dependencies需要所有的父分区都是可用的，可能还需要调用类似MapReduce之类的操作进行跨节点传递。</p><p>其次从失败恢复的角度考虑，narrow dependencies的失败恢复更有效，因为它只需要重新计算丢失的parent partition即可，而且可以并行的在不同节点进行重计算。而wide dependencies牵涉到RDD各级的多个parent partitions。</p></blockquote><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>RDD是Spark的核心，也是整个Spark架构的基础，特性总结如下：</p><ul><li>不变的数据结构存储</li><li>支持跨集群的分布式数据结构</li><li>可以根据数据记录的Key对结构进行分区</li><li>提供了粗粒度的操作，且这些操作支持分区</li><li>它将数据存储在内存中，从而提供了低延迟性</li></ul></div></article></div></main><footer><div class="paginator"><a href="/archives/2018/06/19/" class="prev">PREV</a><a href="/archives/2018/05/15/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname="pross-space",disqus_identifier="archives/2018/05/29/",disqus_title="理解Spark核心之RDD",disqus_url="https://pross.space/archives/2018/05/29/";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}()</script><script id="dsq-count-scr" src="//pross-space.disqus.com/count.js" async></script><div class="copyright"><p>© 2017 - 2018 <a href="https://pross.space">RukiapR0ss</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html><!-- rebuild by neat -->