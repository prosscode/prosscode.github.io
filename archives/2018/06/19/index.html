<!-- build time:Sun Oct 28 2018 00:54:32 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>SparkStreaming之解析updateStateByKey · PROSS</title><meta name="description" content="SparkStreaming之解析updateStateByKey - RukiapR0ss"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://pross.space/atom.xml" title="PROSS"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/prosscode" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">SparkStreaming之解析updateStateByKey</h1><div class="post-info">Jun 19, 2018</div><div class="post-content"><p>说到Spark Streaming的状态管理，就会想到updateStateByKey，还有mapWithState。今天整理了一下，着重了解一下前者。</p><a id="more"></a><h4 id="状态管理的需求"><a href="#状态管理的需求" class="headerlink" title="状态管理的需求"></a>状态管理的需求</h4><p>举一个最简单的需求例子来解释状态（state）管理，现在有这样的一个需求：计算从数据流开始到目前为止单词出现的次数。是不是看起来很眼熟，这其实就是一个升级版的wordcount，只不过需要在每个batchInterval计算当前batch的单词计数，然后对各个批次的计数进行累加。每一个批次的累积的计数就是当前的一个状态值。我们需要把这个状态保存下来，和后面批次单词的计数结果来进行计算，这样我们就能不断的在历史的基础上进行次数的更新。</p><p>SparkStreaming提供了两种方法来解决这个问题：updateStateByKey和mapWithState。mapWithState是1.6版本新增的功能，官方说性能较updateStateByKey提升10倍。</p><h4 id="updateStateByKey概述"><a href="#updateStateByKey概述" class="headerlink" title="updateStateByKey概述"></a>updateStateByKey概述</h4><p>updateStateByKey，统计全局的Key的状态，就算没有数据输入，也会在每一个批次的时候返回之前的key的状态。假设5s产生一个批次的数据，那么就是5s的时候就更新一次key的值，然后返回。如果数据量又比较大，又需要不断的更新每个Key的state， 那么就一定会涉及到状态的保存和容错。所以，要使用updateStateByKey就需要设置一个checkpoint目录，开启checkpoint机制。因为key的State是在内存中维护的，如果宕机，则重启之后之前维护的状态就没有了，所以要长期保存的话则需要启用<code>checkpoint</code>，以便于恢复数据。</p><h4 id="updateStateByKey代码例子"><a href="#updateStateByKey代码例子" class="headerlink" title="updateStateByKey代码例子"></a>updateStateByKey代码例子</h4><p>现在我们来看看怎么用的，首先看一个updateStateByKey使用的简单例子：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment">  * Author: shawn pross</span></div><div class="line"><span class="comment">  * Date: 2018/06/18</span></div><div class="line"><span class="comment">  * Description: test updateStateByKey op</span></div><div class="line"><span class="comment">  */</span></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestUpdateStateByKey</span> </span>&#123;</div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">		<span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</div><div class="line">		conf.setAppName(<span class="string">s"<span class="subst">$&#123;this.getClass.getSimpleName&#125;</span>"</span>)</div><div class="line">		conf.setMaster(<span class="string">"local[2]"</span>)</div><div class="line">		<span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">        <span class="comment">/**</span></div><div class="line"><span class="comment">        	* 创建context,3 second batch size</span></div><div class="line"><span class="comment">			* 创建一个接收器(ReceiverInputDStream),接收从机器上的端口，通过socket发过来的数据</span></div><div class="line"><span class="comment">			*/</span></div><div class="line">		<span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(<span class="number">3</span>))</div><div class="line">		<span class="keyword">val</span> bathLine = ssc.socketTextStream(<span class="string">"127.0.0.1"</span>, <span class="number">9999</span>)</div><div class="line">		<span class="comment">/**</span></div><div class="line"><span class="comment">			* 传入updateStateByKey的函数</span></div><div class="line"><span class="comment">			*</span></div><div class="line"><span class="comment">			* 源码定义：</span></div><div class="line"><span class="comment">			* 	def updateStateByKey[S: ClassTag](</span></div><div class="line"><span class="comment">			* 	updateFunc: (Seq[V], Option[S]) =&gt; Option[S]): DStream[(K, S)] = ssc.withScope &#123;</span></div><div class="line"><span class="comment">			* 	updateStateByKey(updateFunc, defaultPartitioner())</span></div><div class="line"><span class="comment">			* &#125;</span></div><div class="line"><span class="comment">			*/</span></div><div class="line">		<span class="keyword">val</span> updateFunc = (currValues: <span class="type">Seq</span>[<span class="type">Int</span>], prevValueState: <span class="type">Option</span>[<span class="type">Int</span>]) =&gt; &#123;</div><div class="line">			<span class="comment">//通过Spark内部的reduceByKey按key规约，然后这里传入某key当前批次的Seq/List,再计算当前批次的总和</span></div><div class="line">			<span class="keyword">val</span> currentCount = currValues.sum</div><div class="line">			<span class="comment">// 已累加的值</span></div><div class="line">			<span class="keyword">val</span> previousCount = prevValueState.getOrElse(<span class="number">0</span>)</div><div class="line">			<span class="comment">// 返回累加后的结果，是一个Option[Int]类型</span></div><div class="line">			<span class="type">Some</span>(currentCount + previousCount)</div><div class="line">		&#125;</div><div class="line">		<span class="comment">//先聚合成键值对的形式</span></div><div class="line">		bathLine.map(x=&gt;(x,<span class="number">1</span>)).updateStateByKey(updateFunc).print()</div><div class="line">        </div><div class="line">		ssc.start()</div><div class="line">		ssc.awaitTermination()</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>代码很简单，注释也比较详细。其中要说明的是<code>updateStateByKey</code>的参数还有几个可选项：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateStateByKey</span></span>[<span class="type">S</span>: <span class="type">ClassTag</span>](</div><div class="line">    <span class="comment">//状态更新功能</span></div><div class="line">    updateFunc: (<span class="type">Seq</span>[<span class="type">V</span>], <span class="type">Option</span>[<span class="type">S</span>]) =&gt; <span class="type">Option</span>[<span class="type">S</span>],</div><div class="line">    <span class="comment">//用于控制新RDD中每个RDD的分区的分区程序</span></div><div class="line">    partitioner: <span class="type">Partitioner</span>,</div><div class="line">    <span class="comment">//是否记住生成的RDD中的分区对象</span></div><div class="line">    rememberPartitioner: <span class="type">Boolean</span>,  </div><div class="line">    <span class="comment">//每个键的初始状态值</span></div><div class="line">    initialRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">S</span>)],</div><div class="line">  ): <span class="type">DStream</span>[(<span class="type">K</span>, <span class="type">S</span>)] = ssc.withScope &#123;</div><div class="line">    ...</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="updateStateByKey源码分析"><a href="#updateStateByKey源码分析" class="headerlink" title="updateStateByKey源码分析"></a>updateStateByKey源码分析</h4><p>通过上面简单的小例子可以知道，使用updateStateByKey是需要先转换为键值对的形式的，而map返回的是<code>MappedDStream</code>，而进入<code>MappedDStream</code>中也没有updateStateByKey方法，然后其父类DStream中也没有。但是DStream的半生对象中有一个隐式的转换函数<code>toPairDStreamFunctions</code>。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// map实现，返回MappedDStream</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](mapFunc: <span class="type">T</span> =&gt; <span class="type">U</span>): <span class="type">DStream</span>[<span class="type">U</span>] = ssc.withScope &#123;</div><div class="line">    <span class="keyword">new</span> <span class="type">MappedDStream</span>(<span class="keyword">this</span>, context.sparkContext.clean(mapFunc))</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="comment">// MappedDStream父类是DStream</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MappedDStream</span>[<span class="type">T</span>: <span class="type">ClassTag</span>, <span class="type">U</span>: <span class="type">ClassTag</span>] (<span class="params"></span></span></div><div class="line"><span class="class"><span class="params">    parent: <span class="type">DStream</span>[<span class="type">T</span>],</span></span></div><div class="line"><span class="class"><span class="params">    mapFunc: <span class="type">T</span> =&gt; <span class="type">U</span></span></span></div><div class="line"><span class="class"><span class="params">  </span>) <span class="keyword">extends</span> <span class="title">DStream</span>[<span class="type">U</span>](<span class="params">parent.ssc</span>) </span>&#123;</div><div class="line">    ...</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// DStream中隐式的转换函数</span></div><div class="line"><span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">toPairDStreamFunctions</span></span>[<span class="type">K</span>, <span class="type">V</span>](stream: <span class="type">DStream</span>[(<span class="type">K</span>, <span class="type">V</span>)])</div><div class="line">      (<span class="keyword">implicit</span> kt: <span class="type">ClassTag</span>[<span class="type">K</span>], vt: <span class="type">ClassTag</span>[<span class="type">V</span>], ord: <span class="type">Ordering</span>[<span class="type">K</span>] = <span class="literal">null</span>):</div><div class="line">    <span class="type">PairDStreamFunctions</span>[<span class="type">K</span>, <span class="type">V</span>] = &#123;</div><div class="line">    <span class="keyword">new</span> <span class="type">PairDStreamFunctions</span>[<span class="type">K</span>, <span class="type">V</span>](stream)</div><div class="line">  &#125;</div></pre></td></tr></table></figure><p>看到<code>new PairDStreamFunctions</code>就不陌生了。<code>PairDStreamFunctions</code>中存在updateStateByKey方法，Seq[V]表示当前key对应的所有值，Option[S] 是当前key的历史状态，返回的是新的状态。也就是绕了一个圈子又回到原地。最后updateStateByKey最终会在这里面new出了一个<code>StateDStream</code>对象。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateStateByKey</span></span>[<span class="type">S</span>: <span class="type">ClassTag</span>](</div><div class="line">     updateFunc: (<span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">Seq</span>[<span class="type">V</span>], <span class="type">Option</span>[<span class="type">S</span>])]) =&gt; <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">S</span>)],</div><div class="line">     partitioner: <span class="type">Partitioner</span>,</div><div class="line">     rememberPartitioner: <span class="type">Boolean</span>,</div><div class="line">     initialRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">S</span>)]): <span class="type">DStream</span>[(<span class="type">K</span>, <span class="type">S</span>)] = ssc.withScope &#123;</div><div class="line">   <span class="keyword">val</span> cleanedFunc = ssc.sc.clean(updateFunc)</div><div class="line">   <span class="keyword">val</span> newUpdateFunc = (_: <span class="type">Time</span>, it: <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">Seq</span>[<span class="type">V</span>], <span class="type">Option</span>[<span class="type">S</span>])]) =&gt; &#123;</div><div class="line">     cleanedFunc(it)</div><div class="line">   &#125;</div><div class="line">   <span class="keyword">new</span> <span class="type">StateDStream</span>(self, newUpdateFunc, partitioner, rememberPartitioner, <span class="type">Some</span>(initialRDD))</div><div class="line"> &#125;</div></pre></td></tr></table></figure><p>继续进去<code>StateDStream</code>看看，在其<code>compute</code>方法中，会先获取上一个batch计算出的RDD（包含了至程序开始到上一个batch单词的累计计数），然后在获取本次batch中<code>StateDStream</code>的父类计算出的RDD（本次batch的单词计数）分别是<code>prevStateRDD</code>和<code>parentRDD</code>，然后在调用 <code>computeUsingPreviousRDD</code> 方法：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> [<span class="keyword">this</span>] <span class="function"><span class="keyword">def</span> <span class="title">computeUsingPreviousRDD</span></span>(</div><div class="line">    batchTime: <span class="type">Time</span>,</div><div class="line">    parentRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)],</div><div class="line">    prevStateRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">S</span>)]) = &#123;</div><div class="line">  <span class="comment">// Define the function for the mapPartition operation on cogrouped RDD;</span></div><div class="line">  <span class="comment">// first map the cogrouped tuple to tuples of required type,</span></div><div class="line">  <span class="comment">// and then apply the update function</span></div><div class="line">  <span class="keyword">val</span> updateFuncLocal = updateFunc</div><div class="line">  <span class="keyword">val</span> finalFunc = (iterator: <span class="type">Iterator</span>[(<span class="type">K</span>, (<span class="type">Iterable</span>[<span class="type">V</span>], <span class="type">Iterable</span>[<span class="type">S</span>]))]) =&gt; &#123;</div><div class="line">    <span class="keyword">val</span> i = iterator.map &#123; t =&gt;</div><div class="line">      <span class="keyword">val</span> itr = t._2._2.iterator</div><div class="line">      <span class="keyword">val</span> headOption = <span class="keyword">if</span> (itr.hasNext) <span class="type">Some</span>(itr.next()) <span class="keyword">else</span> <span class="type">None</span></div><div class="line">      (t._1, t._2._1.toSeq, headOption)</div><div class="line">    &#125;</div><div class="line">    updateFuncLocal(batchTime, i)</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">val</span> cogroupedRDD = parentRDD.cogroup(prevStateRDD, partitioner)</div><div class="line">  <span class="keyword">val</span> stateRDD = cogroupedRDD.mapPartitions(finalFunc, preservePartitioning)</div><div class="line">  <span class="type">Some</span>(stateRDD)</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>最后返回<code>stateRDD</code>结果。至此，updateStateByKey方法源码执行过程水落石出。</p></div></article></div></main><footer><div class="paginator"><a href="/archives/2018/08/25/" class="prev">PREV</a><a href="/archives/2018/05/29/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname="pross-space",disqus_identifier="archives/2018/06/19/",disqus_title="SparkStreaming之解析updateStateByKey",disqus_url="https://pross.space/archives/2018/06/19/";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}()</script><script id="dsq-count-scr" src="//pross-space.disqus.com/count.js" async></script><div class="copyright"><p>© 2017 - 2018 <a href="https://pross.space">RukiapR0ss</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html><!-- rebuild by neat -->