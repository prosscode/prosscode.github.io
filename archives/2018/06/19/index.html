<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>SparkStreaming之解析updateStateByKey | PROSS</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 5.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">SparkStreaming之解析updateStateByKey</h1><a id="logo" href="/.">PROSS</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a class="current" href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a><a href="/daysmatter/"><i class="fa fa-home"> DaysMatter</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">SparkStreaming之解析updateStateByKey</h1><div class="post-meta">Jun 19, 2018</div><a class="disqus-comment-count" data-disqus-identifier="archives/2018/06/19/" href="/archives/2018/06/19/#disqus_thread"></a><div class="post-content"><p>说到Spark Streaming的状态管理，就会想到updateStateByKey，还有mapWithState。今天整理了一下，着重了解一下前者。</p>
<a id="more"></a>

<h4 id="状态管理的需求"><a href="#状态管理的需求" class="headerlink" title="状态管理的需求"></a>状态管理的需求</h4><p>举一个最简单的需求例子来解释状态（state）管理，现在有这样的一个需求：计算从数据流开始到目前为止单词出现的次数。是不是看起来很眼熟，这其实就是一个升级版的wordcount，只不过需要在每个batchInterval计算当前batch的单词计数，然后对各个批次的计数进行累加。每一个批次的累积的计数就是当前的一个状态值。我们需要把这个状态保存下来，和后面批次单词的计数结果来进行计算，这样我们就能不断的在历史的基础上进行次数的更新。</p>
<p>SparkStreaming提供了两种方法来解决这个问题：updateStateByKey和mapWithState。mapWithState是1.6版本新增的功能，官方说性能较updateStateByKey提升10倍。</p>
<h4 id="updateStateByKey概述"><a href="#updateStateByKey概述" class="headerlink" title="updateStateByKey概述"></a>updateStateByKey概述</h4><p>updateStateByKey，统计全局的Key的状态，就算没有数据输入，也会在每一个批次的时候返回之前的key的状态。假设5s产生一个批次的数据，那么就是5s的时候就更新一次key的值，然后返回。如果数据量又比较大，又需要不断的更新每个Key的state， 那么就一定会涉及到状态的保存和容错。所以，要使用updateStateByKey就需要设置一个checkpoint目录，开启checkpoint机制。因为key的State是在内存中维护的，如果宕机，则重启之后之前维护的状态就没有了，所以要长期保存的话则需要启用<code>checkpoint</code>，以便于恢复数据。</p>
<h4 id="updateStateByKey代码例子"><a href="#updateStateByKey代码例子" class="headerlink" title="updateStateByKey代码例子"></a>updateStateByKey代码例子</h4><p>现在我们来看看怎么用的，首先看一个updateStateByKey使用的简单例子：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Author: shawn pross</span></span><br><span class="line"><span class="comment">  * Date: 2018/06/18</span></span><br><span class="line"><span class="comment">  * Description: test updateStateByKey op</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TestUpdateStateByKey</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">		<span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">		conf.setAppName(<span class="string">s&quot;<span class="subst">$&#123;this.getClass.getSimpleName&#125;</span>&quot;</span>)</span><br><span class="line">		conf.setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">		<span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">        	* 创建context,3 second batch size</span></span><br><span class="line"><span class="comment">			* 创建一个接收器(ReceiverInputDStream),接收从机器上的端口，通过socket发过来的数据</span></span><br><span class="line"><span class="comment">			*/</span></span><br><span class="line">		<span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line">		<span class="keyword">val</span> bathLine = ssc.socketTextStream(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">9999</span>)</span><br><span class="line">		<span class="comment">/**</span></span><br><span class="line"><span class="comment">			* 传入updateStateByKey的函数</span></span><br><span class="line"><span class="comment">			*</span></span><br><span class="line"><span class="comment">			* 源码定义：</span></span><br><span class="line"><span class="comment">			* 	def updateStateByKey[S: ClassTag](</span></span><br><span class="line"><span class="comment">			* 	updateFunc: (Seq[V], Option[S]) =&gt; Option[S]): DStream[(K, S)] = ssc.withScope &#123;</span></span><br><span class="line"><span class="comment">			* 	updateStateByKey(updateFunc, defaultPartitioner())</span></span><br><span class="line"><span class="comment">			* &#125;</span></span><br><span class="line"><span class="comment">			*/</span></span><br><span class="line">		<span class="keyword">val</span> updateFunc = (currValues: <span class="type">Seq</span>[<span class="type">Int</span>], prevValueState: <span class="type">Option</span>[<span class="type">Int</span>]) =&gt; &#123;</span><br><span class="line">			<span class="comment">//通过Spark内部的reduceByKey按key规约，然后这里传入某key当前批次的Seq/List,再计算当前批次的总和</span></span><br><span class="line">			<span class="keyword">val</span> currentCount = currValues.sum</span><br><span class="line">			<span class="comment">// 已累加的值</span></span><br><span class="line">			<span class="keyword">val</span> previousCount = prevValueState.getOrElse(<span class="number">0</span>)</span><br><span class="line">			<span class="comment">// 返回累加后的结果，是一个Option[Int]类型</span></span><br><span class="line">			<span class="type">Some</span>(currentCount + previousCount)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//先聚合成键值对的形式</span></span><br><span class="line">		bathLine.map(x=&gt;(x,<span class="number">1</span>)).updateStateByKey(updateFunc).print()</span><br><span class="line">        </span><br><span class="line">		ssc.start()</span><br><span class="line">		ssc.awaitTermination()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码很简单，注释也比较详细。其中要说明的是<code>updateStateByKey</code>的参数还有几个可选项：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateStateByKey</span></span>[<span class="type">S</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    <span class="comment">//状态更新功能</span></span><br><span class="line">    updateFunc: (<span class="type">Seq</span>[<span class="type">V</span>], <span class="type">Option</span>[<span class="type">S</span>]) =&gt; <span class="type">Option</span>[<span class="type">S</span>],</span><br><span class="line">    <span class="comment">//用于控制新RDD中每个RDD的分区的分区程序</span></span><br><span class="line">    partitioner: <span class="type">Partitioner</span>,</span><br><span class="line">    <span class="comment">//是否记住生成的RDD中的分区对象</span></span><br><span class="line">    rememberPartitioner: <span class="type">Boolean</span>,  </span><br><span class="line">    <span class="comment">//每个键的初始状态值</span></span><br><span class="line">    initialRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">S</span>)],</span><br><span class="line">  ): <span class="type">DStream</span>[(<span class="type">K</span>, <span class="type">S</span>)] = ssc.withScope &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="updateStateByKey源码分析"><a href="#updateStateByKey源码分析" class="headerlink" title="updateStateByKey源码分析"></a>updateStateByKey源码分析</h4><p>通过上面简单的小例子可以知道，使用updateStateByKey是需要先转换为键值对的形式的，而map返回的是<code>MappedDStream</code>，而进入<code>MappedDStream</code>中也没有updateStateByKey方法，然后其父类DStream中也没有。但是DStream的半生对象中有一个隐式的转换函数<code>toPairDStreamFunctions</code>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// map实现，返回MappedDStream</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](mapFunc: <span class="type">T</span> =&gt; <span class="type">U</span>): <span class="type">DStream</span>[<span class="type">U</span>] = ssc.withScope &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">MappedDStream</span>(<span class="keyword">this</span>, context.sparkContext.clean(mapFunc))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// MappedDStream父类是DStream</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MappedDStream</span>[<span class="type">T</span>: <span class="type">ClassTag</span>, <span class="type">U</span>: <span class="type">ClassTag</span>] (<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    parent: <span class="type">DStream</span>[<span class="type">T</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    mapFunc: <span class="type">T</span> =&gt; <span class="type">U</span></span></span></span><br><span class="line"><span class="class"><span class="params">  </span>) <span class="keyword">extends</span> <span class="title">DStream</span>[<span class="type">U</span>](<span class="params">parent.ssc</span>) </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// DStream中隐式的转换函数</span></span><br><span class="line"><span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">toPairDStreamFunctions</span></span>[<span class="type">K</span>, <span class="type">V</span>](stream: <span class="type">DStream</span>[(<span class="type">K</span>, <span class="type">V</span>)])</span><br><span class="line">      (<span class="keyword">implicit</span> kt: <span class="type">ClassTag</span>[<span class="type">K</span>], vt: <span class="type">ClassTag</span>[<span class="type">V</span>], ord: <span class="type">Ordering</span>[<span class="type">K</span>] = <span class="literal">null</span>):</span><br><span class="line">    <span class="type">PairDStreamFunctions</span>[<span class="type">K</span>, <span class="type">V</span>] = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">PairDStreamFunctions</span>[<span class="type">K</span>, <span class="type">V</span>](stream)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>看到<code>new PairDStreamFunctions</code>就不陌生了。<code>PairDStreamFunctions</code>中存在updateStateByKey方法，Seq[V]表示当前key对应的所有值，Option[S] 是当前key的历史状态，返回的是新的状态。也就是绕了一个圈子又回到原地。最后updateStateByKey最终会在这里面new出了一个<code>StateDStream</code>对象。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateStateByKey</span></span>[<span class="type">S</span>: <span class="type">ClassTag</span>](</span><br><span class="line">     updateFunc: (<span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">Seq</span>[<span class="type">V</span>], <span class="type">Option</span>[<span class="type">S</span>])]) =&gt; <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">S</span>)],</span><br><span class="line">     partitioner: <span class="type">Partitioner</span>,</span><br><span class="line">     rememberPartitioner: <span class="type">Boolean</span>,</span><br><span class="line">     initialRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">S</span>)]): <span class="type">DStream</span>[(<span class="type">K</span>, <span class="type">S</span>)] = ssc.withScope &#123;</span><br><span class="line">   <span class="keyword">val</span> cleanedFunc = ssc.sc.clean(updateFunc)</span><br><span class="line">   <span class="keyword">val</span> newUpdateFunc = (_: <span class="type">Time</span>, it: <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">Seq</span>[<span class="type">V</span>], <span class="type">Option</span>[<span class="type">S</span>])]) =&gt; &#123;</span><br><span class="line">     cleanedFunc(it)</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">new</span> <span class="type">StateDStream</span>(self, newUpdateFunc, partitioner, rememberPartitioner, <span class="type">Some</span>(initialRDD))</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>继续进去<code>StateDStream</code>看看，在其<code>compute</code>方法中，会先获取上一个batch计算出的RDD（包含了至程序开始到上一个batch单词的累计计数），然后在获取本次batch中<code>StateDStream</code>的父类计算出的RDD（本次batch的单词计数）分别是<code>prevStateRDD</code>和<code>parentRDD</code>，然后在调用 <code>computeUsingPreviousRDD</code> 方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> [<span class="keyword">this</span>] <span class="function"><span class="keyword">def</span> <span class="title">computeUsingPreviousRDD</span></span>(</span><br><span class="line">    batchTime: <span class="type">Time</span>,</span><br><span class="line">    parentRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)],</span><br><span class="line">    prevStateRDD: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">S</span>)]) = &#123;</span><br><span class="line">  <span class="comment">// Define the function for the mapPartition operation on cogrouped RDD;</span></span><br><span class="line">  <span class="comment">// first map the cogrouped tuple to tuples of required type,</span></span><br><span class="line">  <span class="comment">// and then apply the update function</span></span><br><span class="line">  <span class="keyword">val</span> updateFuncLocal = updateFunc</span><br><span class="line">  <span class="keyword">val</span> finalFunc = (iterator: <span class="type">Iterator</span>[(<span class="type">K</span>, (<span class="type">Iterable</span>[<span class="type">V</span>], <span class="type">Iterable</span>[<span class="type">S</span>]))]) =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> i = iterator.map &#123; t =&gt;</span><br><span class="line">      <span class="keyword">val</span> itr = t._2._2.iterator</span><br><span class="line">      <span class="keyword">val</span> headOption = <span class="keyword">if</span> (itr.hasNext) <span class="type">Some</span>(itr.next()) <span class="keyword">else</span> <span class="type">None</span></span><br><span class="line">      (t._1, t._2._1.toSeq, headOption)</span><br><span class="line">    &#125;</span><br><span class="line">    updateFuncLocal(batchTime, i)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">val</span> cogroupedRDD = parentRDD.cogroup(prevStateRDD, partitioner)</span><br><span class="line">  <span class="keyword">val</span> stateRDD = cogroupedRDD.mapPartitions(finalFunc, preservePartitioning)</span><br><span class="line">  <span class="type">Some</span>(stateRDD)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后返回<code>stateRDD</code>结果。至此，updateStateByKey方法源码执行过程水落石出。</p>
</div><div class="tags"><a href="/tags/Spark/">Spark</a></div><div class="post-nav"><a class="pre" href="/archives/2018/08/25/">无题</a><a class="next" href="/archives/2018/05/29/">理解Spark核心之RDD</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://pross.space/archives/2018/06/19/';
    this.page.identifier = 'archives/2018/06/19/';
    this.page.title = 'SparkStreaming之解析updateStateByKey';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//pross-space.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//pross-space.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://pross-space.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://pross.space"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Thrift/" style="font-size: 15px;">Thrift</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Hibernate/" style="font-size: 15px;">Hibernate</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/MapReduce/" style="font-size: 15px;">MapReduce</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/tags/%E9%9A%8F%E7%AC%94%E6%9D%82%E8%AE%B0/" style="font-size: 15px;">随笔杂记</a> <a href="/tags/Swagger/" style="font-size: 15px;">Swagger</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 15px;">数据结构</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 15px;">设计模式</a> <a href="/tags/RPC/" style="font-size: 15px;">RPC</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/archives/2019/07/09/">Apache-Thrift-Thrift-Thrift</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/06/17/">远程过程调用</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/02/02/">使用Swagger2构建RESTful API</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/01/13/">散列表</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/01/01/">几种定时调度的介绍与实现</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/12/22/">Java线程池</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/12/16/">大O表示法</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/11/11/">你所忽视的排序算法（下）</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/10/27/">你所忽视的排序算法（上）</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/09/28/">相见</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/prosscode" title="Github" target="_blank">Github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">PROSS.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>