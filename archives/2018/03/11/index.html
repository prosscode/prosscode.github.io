<!-- build time:Sat Sep 01 2018 00:06:58 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>HDFS核心设计 · PROSS</title><meta name="description" content="HDFS核心设计 - RukiapR0ss"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://prosscode.github.io/atom.xml" title="PROSS"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/prosscode" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">HDFS核心设计</h1><div class="post-info">Mar 11, 2018</div><div class="post-content"><ul><li>心跳机制</li><li>安全模式</li><li>副本存放策略</li><li>负载均衡</li></ul><a id="more"></a><h3 id="HDFS相关概念"><a href="#HDFS相关概念" class="headerlink" title="HDFS相关概念"></a>HDFS相关概念</h3><p>HDFS（Hadoop Distributed File System Hadoop）分布式文件系统，主要用来解决海量数据的存储问题</p><p>HDFS中的文件在物理上是分块（block）存储，块的大小可以通过配置参数（dfs.blocksize）来规定，默认在Hadoop2.x版本中是128MB。</p><p>HDFS文件的各个block的存储管理由DataNode节点承担，DataNode是HDFS集群从节点，每一个block都可以在多个DataNode上存储多个副本（副本数量可以通过参数设置dfs.replication，默认是3）。</p><p>HDFS是设计成适应一次写入，多次读出的场景，不支持文件的修改。</p><p>HDFS核心API：Configuration、FileSystem。</p><h3 id="HDFS架构解释"><a href="#HDFS架构解释" class="headerlink" title="HDFS架构解释"></a>HDFS架构解释</h3><p>在上一篇的<a href="https://prosscode.github.io/2018/Hadoop集群环境搭建/">Hadoop集群环境搭建</a>中对集群规划分为：NameNode、DataNode、SecondaryNameNode以及ResourceManager和NodeManager。我们只知道需要这样去规划一个基本的分布式集群，并不知其所以然，那么这里对HDFS部分名词阐释：</p><p>主节点Namenode：掌管文件系统目录树，管理文件系统的元数据（一个block元信息消耗大约150byte的内存），负责保持和分配文件副本的数量，并处理客户端读写的请求。客户端请求访问HDFS都是通过向NameNode申请来进行的。</p><p>从节点DataNode：存储整个集群的所有的数据块，处理真正的数据读写。通过心跳机制定期汇报给NameNode有关block的信息。</p><p>SecondaryNameNode：严格说并不是NameNode备份节点，而是NameNode的助手，主要给NameNode分担压力之用。</p><p>下图可以很好的帮助理解</p><p><img src="/archives/2018/03/11/1.jpg" alt=""></p><h3 id="HDFS核心设计"><a href="#HDFS核心设计" class="headerlink" title="HDFS核心设计"></a>HDFS核心设计</h3><p><strong>心跳机制（HearBeat）</strong></p><p>在上面架构解释中说到，DataNode通过心跳机制定期汇报给NameNode有关block的信息，那么HDFS的心跳机制是什么原理呢？</p><p>我们知道，Hadoop是Master（NameNode、ResourceManager）/Slave（DataNode、NodeManager）结构，Master启动的时候会启动一个IPC（Inter-Process Comunocation，进程通信）server服务，等待Slave的连接；而Slave启动时，会主动连接master的IPC server服务，并且是每隔3秒连接一次master，这个每隔一段时间去连接一次的机智，我们形象的称为<strong>心跳</strong>。</p><p>Slave通过心跳汇报自己的信息给Master，Master也通过心跳给Slave下达命令；NameNode通过心跳得知DataNode的状态，ResourceManager 通过心跳得知 NodeManager 的状态。如果Master长时间都没有收到slave的心跳，就认为slave挂掉了，那么NameNode感知到Data挂掉死亡的时长是怎么计算的呢？</p><p>原理是这样的：DataNode启动好了之后，会专门启动一个线程来负责给NameNode发送心跳数据包，如果整个DataNode没有任何问题，但是仅仅只是当前负责发送信息的数据包线程挂掉了，那么NameNode会发送命名向这个DataNode进行确认，如果第一次没有返回结果，仅且只会检查第二次。如果发送数据包线程没有问题，是DataNode出现了某些问题，就没有DataNode的汇报；HDFS的标准： 如果连续10次没有收到DataNode的汇报，那么NameNode就会认为该DataNode存在宕机的可能。</p><p>这里需要查看hdfs-site.xml配置文件中的两个相关设置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>heartbeat.recheck.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>5000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.heartbeat.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure><p>那么计算公示就可以出来：<code>timeout=2*heartbeat.recheck.interval+10*dfs.heartbeat.interval</code></p><p>需要注意的是，<code>heartbeat.recheck.interval</code>时间单位是ms（毫秒，默认为5分钟），<code>dfs.heartbeat.interval</code>时间单位是s（秒，默认为3秒）。</p><p><strong>安全模式</strong></p><p>安全模式是HDFS的自我保护数据安全的措施，当NameNode发现集群中的block丢失率（默认为0.999f，可修改dfs.safemode.threshold.pct手动配置）达到一定比例时，NameNode就会进入安全模式，在安全模式下，客户端不能对HDFS上的任何数据进行操作，只能查看元数据信息。</p><p>安全模式常用操作命令：</p><p>强制NameNode退出安全模式：<code>hadoop dfsadmin -safemode leave</code></p><p>进入安全模式：<code>hadoop dfsadmin -safemode enter</code></p><p>查看安全模式状态：<code>hadoop dfsadmin -safemode get</code></p><p>等待安全模式结束：<code>hadoop dfsadmin -safemode wait</code></p><p><strong>副本存放策略</strong></p><p>数据分块存储和副本的存放是保证可靠性和高性能的关键</p><p>副本存放策略说明：HDFS默认的副本数是3，第一个Block副本放在客户端所在的Node里，如果客户端不在集群范围，则第一个Node随机选取（不会选择太满和太忙的Node），第二个副本放置到与第一个节点不同的机架中的其中一个Node，第三个副本在和第二个副本在同一个机架，随机放在不同的Node中。</p><p>下图Block1-3表示三个副本。</p><p><img src="/archives/2018/03/11/replication.png" alt=""></p><p>修改副本数：</p><p>修改集群文件hdfs-site.xml：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure><p>命令设置：命令+副本数+文件夹路径或某个文件路径</p><p><code>bin/hadoop fs -setrep -R 2 /</code></p><p><strong>负载均衡</strong></p><p>节点与节点之间磁盘利用率不平衡是HDFS集群非常容易出现的情况（集群内新增，删除节点，某个节点机器内一个盘存储达到饱和等）当HDFS负载不均衡时，需要对HDFS进行数据的负载均衡调整，数据均衡过程的核心是一个数据均衡算法。进行数据的负载均衡调整必须满足以下原则：</p><ul><li>数据平衡不能导致数据块减少，数据备份的丢失</li><li>管理员可以终止数据平衡进程</li><li>每次移动的数据量以及占用的网络资源必须是可控的</li><li>数据均衡过程中，不能影响NameNode的正常工作</li></ul><p>影响Balancer的几个参数：</p><p><code>- threshold</code>：默认设置是10，参数范围0-100，判断集群是否平衡的阀值，理论上设置的越小，整个集群越平衡</p><p><code>dfs.balance.bandwidthPerSec</code>：默认值是1048576（1M/S），Balancer运行时允许占用的带宽</p><p>用命令设置：</p><p><code>hadoop dfsadmin -setBalanacerBandwidth 10485760</code></p><p><code>sbin/start-balancer.sh -t(threshold) 10%</code></p><p>在hdfs-site.xml配置文件中设置bandwidthPerSec：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.balance.bandwidthPerSec<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>10485760<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">description</span>&gt;</span>负载均衡时的带宽大小设置<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure></div></article></div></main><footer><div class="paginator"><a href="/archives/2018/03/17/" class="prev">PREV</a><a href="/archives/2018/03/03/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname="pross.space",disqus_identifier="archives/2018/03/11/",disqus_title="HDFS核心设计",disqus_url="https://prosscode.github.io/archives/2018/03/11/";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}()</script><script id="dsq-count-scr" src="//pross.space.disqus.com/count.js" async></script><div class="copyright"><p>© 2017 - 2018 <a href="https://prosscode.github.io">RukiapR0ss</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html><!-- rebuild by neat -->