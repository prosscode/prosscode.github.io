<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>HDFS核心API编程案例 | PROSS</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 5.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">HDFS核心API编程案例</h1><a id="logo" href="/.">PROSS</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a class="current" href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a><a href="/daysmatter/"><i class="fa fa-home"> DaysMatter</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">HDFS核心API编程案例</h1><div class="post-meta">Mar 17, 2018</div><a class="disqus-comment-count" data-disqus-identifier="archives/2018/03/17/" href="/archives/2018/03/17/#disqus_thread"></a><div class="post-content"><ul>
<li>删除HDFS集群中所有的空文件和空目录</li>
<li>使用流的方式上传下载文件</li>
<li>统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比</li>
<li>统计出HDFS文件系统中平均副本数</li>
</ul>
<a id="more"></a>

<h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><p><a target="_blank" rel="noopener" href="https://prosscode.github.io/2018/Hadoop%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">Hadoop集群环境搭建</a>–&gt;将”windows平台编译hadoop安装包”解压，并配置环境变量–&gt;准备hadoop-eclipse-plugin.jar插件，配置到eclipse–&gt;eclipse中进入Map/Reduce Locations配置集群信息–&gt;Add User Library–&gt;添加common、hdfs、mapreduce、yarn相关依赖库–&gt;新建Java项目开始编写代码</p>
<p>做那么多操作，无非是要做到<strong>在本地eclipse中编写的程序能够操作HDFS集群中的文件</strong></p>
<h4 id="公共工具类"><a href="#公共工具类" class="headerlink" title="公共工具类"></a>公共工具类</h4><p><code>HDFSUtils.java</code>：初始化FileSystem对象和关闭FileSystem</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> pross shawn</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * create time：2018年3月14日</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * content：初始化FileSystem对象和关闭FileSystem</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSUtils</span> </span>&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> FileSystem fs=<span class="keyword">null</span>;</span><br><span class="line">  </span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 初始化FileSystem对象</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> Exception </span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">initFileSystem</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		Configuration conf=<span class="keyword">new</span> Configuration();</span><br><span class="line">		conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://hadoop02:9000&quot;</span>);</span><br><span class="line">		System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>, <span class="string">&quot;hadoop&quot;</span>);</span><br><span class="line">		fs=FileSystem.get(conf);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 关闭FileSystem的连接</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">closeFileSystem</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		fs.close();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所需要的依赖包：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.BlockLocation;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.LocatedFileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.RemoteIterator;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br></pre></td></tr></table></figure>
<h4 id="删除HDFS集群中所有空文件和空目录"><a href="#删除HDFS集群中所有空文件和空目录" class="headerlink" title="删除HDFS集群中所有空文件和空目录"></a>删除HDFS集群中所有空文件和空目录</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 删除HDFS集群中的所有空文件和空目录</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteEmptyDir</span><span class="params">(Path path)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	HDFSUtils.initFileSystem();</span><br><span class="line">	<span class="comment">// 当前路径就是空目录时</span></span><br><span class="line">	FileStatus[] listFile = HDFSUtils.fs.listStatus(path);</span><br><span class="line">	<span class="keyword">if</span> (listFile.length == <span class="number">0</span>) &#123;</span><br><span class="line">		<span class="comment">//删除空目录</span></span><br><span class="line">		HDFSUtils.fs.delete(path, <span class="keyword">true</span>);</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//如果不是空文件，先获取指定目录下的文件和子目录</span></span><br><span class="line">	RemoteIterator&lt;LocatedFileStatus&gt; listLocatedStatus = HDFSUtils.fs.listLocatedStatus(path);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span> (listLocatedStatus.hasNext()) &#123;</span><br><span class="line">		LocatedFileStatus next = listLocatedStatus.next();</span><br><span class="line">         	 <span class="comment">//获取当前目录和其父目录</span></span><br><span class="line">		Path currentPath = next.getPath();</span><br><span class="line">		Path parentPath=next.getPath().getParent();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 如果是文件夹，继续往下遍历</span></span><br><span class="line">		<span class="keyword">if</span> (next.isDirectory()) &#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 如果是空目录，删除</span></span><br><span class="line">			<span class="keyword">if</span> (HDFSUtils.fs.listStatus(currentPath).length == <span class="number">0</span>) &#123;</span><br><span class="line">				HDFSUtils.fs.delete(currentPath, <span class="keyword">true</span>);</span><br><span class="line">				<span class="keyword">if</span>(HDFSUtils.fs.listStatus(parentPath).length==<span class="number">0</span>)&#123;</span><br><span class="line">					HDFSUtils.fs.delete(parentPath, <span class="keyword">true</span>);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="comment">// 不是空目录，那么则重新遍历</span></span><br><span class="line">				<span class="keyword">if</span> (HDFSUtils.fs.exists(currentPath)) &#123;</span><br><span class="line">					AchieveClass.deleteEmptyDir(currentPath);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 如果是文件</span></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="comment">// 获取文件的长度</span></span><br><span class="line">			<span class="keyword">long</span> fileLength = next.getLen();</span><br><span class="line">			<span class="comment">// 当文件是空文件时， 删除</span></span><br><span class="line">			<span class="keyword">if</span> (fileLength == <span class="number">0</span>) &#123;</span><br><span class="line">				HDFSUtils.fs.delete(currentPath, <span class="keyword">true</span>);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 当空文件夹或者空文件删除时，有可能导致父文件夹为空文件夹，这里需要判断一下</span></span><br><span class="line">		<span class="keyword">int</span> length = HDFSUtils.fs.listStatus(parentPath).length;</span><br><span class="line">		<span class="keyword">if</span>(length == <span class="number">0</span>)&#123;</span><br><span class="line">			HDFSUtils.fs.delete(parentPath, <span class="keyword">true</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">     	HDFSUtils.closeFileSystem();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="使用流的方式上传下载文件"><a href="#使用流的方式上传下载文件" class="headerlink" title="使用流的方式上传下载文件"></a>使用流的方式上传下载文件</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用流的方式上传文件</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> srcPath  上传的本地路径</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> desPath  上传到HDFS上后的文件名称路径</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">putFileByStream</span><span class="params">(String srcPath,String desPath)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">	HDFSUtils.initFileSystem();</span><br><span class="line">	InputStream in = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(srcPath));</span><br><span class="line">     	 <span class="comment">//Path是HDFS上的文件路径</span></span><br><span class="line">	FSDataOutputStream out = HDFSUtils.fs.create(<span class="keyword">new</span> Path(desPath));</span><br><span class="line">	IOUtils.copyBytes(in, out,<span class="number">4096</span>,<span class="keyword">true</span>);</span><br><span class="line">	System.out.println(<span class="string">&quot;put successfully&quot;</span>);</span><br><span class="line">	HDFSUtils.closeFileSystem();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用流的方式下载文件 </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> srcPath HDFS上的下载文件的路径</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> desPath 下载到本地的文件路径</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getFileByStream</span><span class="params">(Path srcPath,File desPath)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">	HDFSUtils.initFileSystem();</span><br><span class="line">	FSDataInputStream in=HDFSUtils.fs.open(srcPath);</span><br><span class="line">	OutputStream out=<span class="keyword">new</span> FileOutputStream(desPath);</span><br><span class="line">	IOUtils.copyBytes(in, out,<span class="number">4096</span>,<span class="keyword">true</span>);</span><br><span class="line">	HDFSUtils.closeFileSystem();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比"><a href="#统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比" class="headerlink" title="统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比"></a>统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 统计出 HDFS文件系统中文件大小小于 HDFS集群中的默认块大小的文件占比 </span></span><br><span class="line"><span class="comment"> * 默认块大小为128MB</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">lessBlockSizeOfFile</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	HDFSUtils.initFileSystem();</span><br><span class="line">	FileStatus[] listStatus = HDFSUtils.fs.listStatus(<span class="keyword">new</span> Path(<span class="string">&quot;/&quot;</span>));</span><br><span class="line">	<span class="comment">// 文件总数</span></span><br><span class="line">	<span class="keyword">int</span> count = listStatus.length;</span><br><span class="line">	<span class="comment">// 小于block大小的文件数个数</span></span><br><span class="line">	<span class="keyword">int</span> lessBlock = <span class="number">0</span>;</span><br><span class="line">     	 <span class="comment">// 遍历</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; i++) &#123;</span><br><span class="line">         	<span class="comment">//如果文件大小小于128M，这lessBlock+1</span></span><br><span class="line">		<span class="keyword">if</span> (listStatus[i].getLen() &lt;= <span class="number">134217728</span>) &#123;</span><br><span class="line">			lessBlock += <span class="number">1</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	System.out.println(<span class="string">&quot;文件总数量为：&quot;</span> + count + <span class="string">&quot;个\n小于默认block的文件数量为：&quot;</span> + lessBlock + <span class="string">&quot;个&quot;</span> + <span class="string">&quot;\n文件大小小于默认块大小的文件占比:&quot;</span></span><br><span class="line">			+ (lessBlock*<span class="number">1D</span> / count) * <span class="number">100</span> + <span class="string">&quot;%&quot;</span>);</span><br><span class="line">	HDFSUtils.closeFileSystem();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="统计出HDFS文件系统中平均副本数"><a href="#统计出HDFS文件系统中平均副本数" class="headerlink" title="统计出HDFS文件系统中平均副本数"></a>统计出HDFS文件系统中平均副本数</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * HDFS文件系统中的平均副本数（副本总数/总数据块数）</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">avgRepofBlock</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	HDFSUtils.initFileSystem();</span><br><span class="line">	<span class="comment">// 副本总数</span></span><br><span class="line">	<span class="keyword">int</span> repCount = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// 数据块总数</span></span><br><span class="line">	<span class="keyword">int</span> blockCount = <span class="number">0</span>;</span><br><span class="line">     </span><br><span class="line">	RemoteIterator&lt;LocatedFileStatus&gt; listFiles = HDFSUtils.fs.listFiles(<span class="keyword">new</span> Path(<span class="string">&quot;/&quot;</span>), <span class="keyword">true</span>);</span><br><span class="line">	<span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">		LocatedFileStatus next = listFiles.next();</span><br><span class="line">		<span class="keyword">int</span> BlockNum = next.getBlockLocations().length;</span><br><span class="line">		<span class="keyword">if</span> (BlockNum != <span class="number">0</span>) &#123;</span><br><span class="line">			<span class="keyword">int</span> repNum = next.getReplication();</span><br><span class="line">			<span class="keyword">int</span> oneRepCount = BlockNum * repNum;</span><br><span class="line">			repCount += oneRepCount;</span><br><span class="line">			blockCount += BlockNum;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	System.out.println(<span class="string">&quot;副本总数：&quot;</span> + repCount + <span class="string">&quot;\n数据块总数：&quot;</span> + blockCount + <span class="string">&quot;\n平均副本数：&quot;</span> + repCount*<span class="number">1D</span> / blockCount);</span><br><span class="line">	HDFSUtils.closeFileSystem();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</div><div class="tags"><a href="/tags/HDFS/">HDFS</a></div><div class="post-nav"><a class="pre" href="/archives/2018/03/18/">MapReduce编程案例（上）</a><a class="next" href="/archives/2018/03/11/">HDFS核心设计</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://pross.space/archives/2018/03/17/';
    this.page.identifier = 'archives/2018/03/17/';
    this.page.title = 'HDFS核心API编程案例';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//pross-space.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//pross-space.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://pross-space.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://pross.space"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Thrift/" style="font-size: 15px;">Thrift</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Hibernate/" style="font-size: 15px;">Hibernate</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/MapReduce/" style="font-size: 15px;">MapReduce</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/tags/%E9%9A%8F%E7%AC%94%E6%9D%82%E8%AE%B0/" style="font-size: 15px;">随笔杂记</a> <a href="/tags/Swagger/" style="font-size: 15px;">Swagger</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 15px;">数据结构</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 15px;">设计模式</a> <a href="/tags/RPC/" style="font-size: 15px;">RPC</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/archives/2019/07/09/">Apache-Thrift-Thrift-Thrift</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/06/17/">远程过程调用</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/02/02/">使用Swagger2构建RESTful API</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/01/13/">散列表</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2019/01/01/">几种定时调度的介绍与实现</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/12/22/">Java线程池</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/12/16/">大O表示法</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/11/11/">你所忽视的排序算法（下）</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/10/27/">你所忽视的排序算法（上）</a></li><li class="post-list-item"><a class="post-list-link" href="/archives/2018/09/28/">相见</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/prosscode" title="Github" target="_blank">Github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">PROSS.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>