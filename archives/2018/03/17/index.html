<!-- build time:Tue Jul 10 2018 23:40:32 GMT+0800 (中国标准时间) --><!doctype html><html lang="zh-Hans"><head><meta http-equiv="Content-Type" content="text/html" charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="author" content="RukiapR0ss"><meta name="description" content="删除HDFS集群中所有的空文件和空目录使用流的方式上传下载文件统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比统计出HDFS文件系统中平均副本数"><title>HDFS核心API编程案例 [ PROSS ]</title><link rel="alternate" href="/atom.xml" title="PROSS"><link rel="shortcut icon" href="/images/favicon.ico"><link rel="stylesheet" href="/css/random.css"><link rel="stylesheet" href="/css/vegas.min.css"><link rel="stylesheet" href="/css/highlight-railscasts.css"><link rel="stylesheet" href="/css/jquery.fancybox.css"><link rel="stylesheet" href="/css/iconfont/iconfont.css"><link rel="stylesheet" href="/css/jquery.fancybox-thumbs.css"><link rel="stylesheet" href="/css/plyr.css"></head><body><div class="side-navigate hide-area"><div class="item prev"><a href="/archives/2018/03/18/"><div class="item-icon"></div></a><div class="item-title">MapReduce编程案例（上）</div></div><div class="item next"><a href="/archives/2018/03/11/"><div class="item-icon"></div></a><div class="item-title">HDFS核心设计</div></div></div><div id="outer-container" class="hide-area"><div id="container"><div id="menu-outer" class="slide-down"><div id="menu-inner"><div id="brand"><a onclick="openUserCard()"><img id="avatar" src="/images/avator.jpg"><div id="homelink">PROSS</div></a></div><div id="menu-list"><ul><li><a href="/index.html">Home</a></li><li class="active"><a href="/archives">Archives</a></li><li><a href="/tags">Tags</a></li><li><a href="/about">About</a></li></ul></div><div id="show-menu"><button>Menu</button></div></div></div><div id="content-outer"><div id="content-inner"><article id="post"><h1>HDFS核心API编程案例</h1><p class="page-title-sub"><span id="post-title-date">撰写于 2018-03-17</span> <span id="post-title-updated">修改于 2018-05-29</span> <span id="post-title-tags">标签 <a href="/tags/Hadoop/">Hadoop</a></span></p><ul><li>删除HDFS集群中所有的空文件和空目录</li><li>使用流的方式上传下载文件</li><li>统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比</li><li>统计出HDFS文件系统中平均副本数</li></ul><a id="more"></a><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><p><a href="https://prosscode.github.io/2018/Hadoop集群环境搭建/">Hadoop集群环境搭建</a>–&gt;将”windows平台编译hadoop安装包”解压，并配置环境变量–&gt;准备hadoop-eclipse-plugin.jar插件，配置到eclipse–&gt;eclipse中进入Map/Reduce Locations配置集群信息–&gt;Add User Library–&gt;添加common、hdfs、mapreduce、yarn相关依赖库–&gt;新建Java项目开始编写代码</p><p>做那么多操作，无非是要做到<strong>在本地eclipse中编写的程序能够操作HDFS集群中的文件</strong></p><h4 id="公共工具类"><a href="#公共工具类" class="headerlink" title="公共工具类"></a>公共工具类</h4><p><code>HDFSUtils.java</code>：初始化FileSystem对象和关闭FileSystem</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.util.Random;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * <span class="doctag">@author</span> pross shawn</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * create time：2018年3月14日</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * content：初始化FileSystem对象和关闭FileSystem</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSUtils</span> </span>&#123;</div><div class="line">	<span class="keyword">public</span> <span class="keyword">static</span> FileSystem fs=<span class="keyword">null</span>;</div><div class="line">  </div><div class="line">	<span class="comment">/**</span></div><div class="line"><span class="comment">	 * 初始化FileSystem对象</span></div><div class="line"><span class="comment">	 * <span class="doctag">@throws</span> Exception </span></div><div class="line"><span class="comment">	 */</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">initFileSystem</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</div><div class="line">		Configuration conf=<span class="keyword">new</span> Configuration();</div><div class="line">		conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop02:9000"</span>);</div><div class="line">		System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"hadoop"</span>);</div><div class="line">		fs=FileSystem.get(conf);</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="comment">/**</span></div><div class="line"><span class="comment">	 * 关闭FileSystem的连接</span></div><div class="line"><span class="comment">	 * <span class="doctag">@throws</span> Exception</span></div><div class="line"><span class="comment">	 */</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">closeFileSystem</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</div><div class="line">		fs.close();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>所需要的依赖包：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.io.File;</div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.io.OutputStream;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.BlockLocation;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.LocatedFileStatus;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.RemoteIterator;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div></pre></td></tr></table></figure><h4 id="删除HDFS集群中所有空文件和空目录"><a href="#删除HDFS集群中所有空文件和空目录" class="headerlink" title="删除HDFS集群中所有空文件和空目录"></a>删除HDFS集群中所有空文件和空目录</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * 删除HDFS集群中的所有空文件和空目录</span></div><div class="line"><span class="comment"> * </span></div><div class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteEmptyDir</span><span class="params">(Path path)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">	HDFSUtils.initFileSystem();</div><div class="line">	<span class="comment">// 当前路径就是空目录时</span></div><div class="line">	FileStatus[] listFile = HDFSUtils.fs.listStatus(path);</div><div class="line">	<span class="keyword">if</span> (listFile.length == <span class="number">0</span>) &#123;</div><div class="line">		<span class="comment">//删除空目录</span></div><div class="line">		HDFSUtils.fs.delete(path, <span class="keyword">true</span>);</div><div class="line">		<span class="keyword">return</span>;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">//如果不是空文件，先获取指定目录下的文件和子目录</span></div><div class="line">	RemoteIterator&lt;LocatedFileStatus&gt; listLocatedStatus = HDFSUtils.fs.listLocatedStatus(path);</div><div class="line"></div><div class="line">	<span class="keyword">while</span> (listLocatedStatus.hasNext()) &#123;</div><div class="line">		LocatedFileStatus next = listLocatedStatus.next();</div><div class="line">         	 <span class="comment">//获取当前目录和其父目录</span></div><div class="line">		Path currentPath = next.getPath();</div><div class="line">		Path parentPath=next.getPath().getParent();</div><div class="line">		</div><div class="line">		<span class="comment">// 如果是文件夹，继续往下遍历</span></div><div class="line">		<span class="keyword">if</span> (next.isDirectory()) &#123;</div><div class="line"></div><div class="line">			<span class="comment">// 如果是空目录，删除</span></div><div class="line">			<span class="keyword">if</span> (HDFSUtils.fs.listStatus(currentPath).length == <span class="number">0</span>) &#123;</div><div class="line">				HDFSUtils.fs.delete(currentPath, <span class="keyword">true</span>);</div><div class="line">				<span class="keyword">if</span>(HDFSUtils.fs.listStatus(parentPath).length==<span class="number">0</span>)&#123;</div><div class="line">					HDFSUtils.fs.delete(parentPath, <span class="keyword">true</span>);</div><div class="line">				&#125;</div><div class="line">			&#125; <span class="keyword">else</span> &#123;</div><div class="line">				<span class="comment">// 不是空目录，那么则重新遍历</span></div><div class="line">				<span class="keyword">if</span> (HDFSUtils.fs.exists(currentPath)) &#123;</div><div class="line">					AchieveClass.deleteEmptyDir(currentPath);</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line"></div><div class="line">		<span class="comment">// 如果是文件</span></div><div class="line">		&#125; <span class="keyword">else</span> &#123;</div><div class="line">			<span class="comment">// 获取文件的长度</span></div><div class="line">			<span class="keyword">long</span> fileLength = next.getLen();</div><div class="line">			<span class="comment">// 当文件是空文件时， 删除</span></div><div class="line">			<span class="keyword">if</span> (fileLength == <span class="number">0</span>) &#123;</div><div class="line">				HDFSUtils.fs.delete(currentPath, <span class="keyword">true</span>);</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		<span class="comment">// 当空文件夹或者空文件删除时，有可能导致父文件夹为空文件夹，这里需要判断一下</span></div><div class="line">		<span class="keyword">int</span> length = HDFSUtils.fs.listStatus(parentPath).length;</div><div class="line">		<span class="keyword">if</span>(length == <span class="number">0</span>)&#123;</div><div class="line">			HDFSUtils.fs.delete(parentPath, <span class="keyword">true</span>);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">     	HDFSUtils.closeFileSystem();</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="使用流的方式上传下载文件"><a href="#使用流的方式上传下载文件" class="headerlink" title="使用流的方式上传下载文件"></a>使用流的方式上传下载文件</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * 使用流的方式上传文件</span></div><div class="line"><span class="comment"> * <span class="doctag">@param</span> srcPath  上传的本地路径</span></div><div class="line"><span class="comment"> * <span class="doctag">@param</span> desPath  上传到HDFS上后的文件名称路径</span></div><div class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">putFileByStream</span><span class="params">(String srcPath,String desPath)</span> <span class="keyword">throws</span> Exception</span>&#123;</div><div class="line">	HDFSUtils.initFileSystem();</div><div class="line">	InputStream in = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(srcPath));</div><div class="line">     	 <span class="comment">//Path是HDFS上的文件路径</span></div><div class="line">	FSDataOutputStream out = HDFSUtils.fs.create(<span class="keyword">new</span> Path(desPath));</div><div class="line">	IOUtils.copyBytes(in, out,<span class="number">4096</span>,<span class="keyword">true</span>);</div><div class="line">	System.out.println(<span class="string">"put successfully"</span>);</div><div class="line">	HDFSUtils.closeFileSystem();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * 使用流的方式下载文件 </span></div><div class="line"><span class="comment"> * <span class="doctag">@param</span> srcPath HDFS上的下载文件的路径</span></div><div class="line"><span class="comment"> * <span class="doctag">@param</span> desPath 下载到本地的文件路径</span></div><div class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getFileByStream</span><span class="params">(Path srcPath,File desPath)</span> <span class="keyword">throws</span> Exception</span>&#123;</div><div class="line">	HDFSUtils.initFileSystem();</div><div class="line">	FSDataInputStream in=HDFSUtils.fs.open(srcPath);</div><div class="line">	OutputStream out=<span class="keyword">new</span> FileOutputStream(desPath);</div><div class="line">	IOUtils.copyBytes(in, out,<span class="number">4096</span>,<span class="keyword">true</span>);</div><div class="line">	HDFSUtils.closeFileSystem();</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比"><a href="#统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比" class="headerlink" title="统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比"></a>统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * 统计出 HDFS文件系统中文件大小小于 HDFS集群中的默认块大小的文件占比 </span></div><div class="line"><span class="comment"> * 默认块大小为128MB</span></div><div class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">lessBlockSizeOfFile</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">	HDFSUtils.initFileSystem();</div><div class="line">	FileStatus[] listStatus = HDFSUtils.fs.listStatus(<span class="keyword">new</span> Path(<span class="string">"/"</span>));</div><div class="line">	<span class="comment">// 文件总数</span></div><div class="line">	<span class="keyword">int</span> count = listStatus.length;</div><div class="line">	<span class="comment">// 小于block大小的文件数个数</span></div><div class="line">	<span class="keyword">int</span> lessBlock = <span class="number">0</span>;</div><div class="line">     	 <span class="comment">// 遍历</span></div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; i++) &#123;</div><div class="line">         	<span class="comment">//如果文件大小小于128M，这lessBlock+1</span></div><div class="line">		<span class="keyword">if</span> (listStatus[i].getLen() &lt;= <span class="number">134217728</span>) &#123;</div><div class="line">			lessBlock += <span class="number">1</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	System.out.println(<span class="string">"文件总数量为："</span> + count + <span class="string">"个\n小于默认block的文件数量为："</span> + lessBlock + <span class="string">"个"</span> + <span class="string">"\n文件大小小于默认块大小的文件占比:"</span></div><div class="line">			+ (lessBlock*<span class="number">1</span>D / count) * <span class="number">100</span> + <span class="string">"%"</span>);</div><div class="line">	HDFSUtils.closeFileSystem();</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="统计出HDFS文件系统中平均副本数"><a href="#统计出HDFS文件系统中平均副本数" class="headerlink" title="统计出HDFS文件系统中平均副本数"></a>统计出HDFS文件系统中平均副本数</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * HDFS文件系统中的平均副本数（副本总数/总数据块数）</span></div><div class="line"><span class="comment"> * <span class="doctag">@throws</span> Exception</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">avgRepofBlock</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">	HDFSUtils.initFileSystem();</div><div class="line">	<span class="comment">// 副本总数</span></div><div class="line">	<span class="keyword">int</span> repCount = <span class="number">0</span>;</div><div class="line">	<span class="comment">// 数据块总数</span></div><div class="line">	<span class="keyword">int</span> blockCount = <span class="number">0</span>;</div><div class="line">     </div><div class="line">	RemoteIterator&lt;LocatedFileStatus&gt; listFiles = HDFSUtils.fs.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</div><div class="line">	<span class="keyword">while</span> (listFiles.hasNext()) &#123;</div><div class="line">		LocatedFileStatus next = listFiles.next();</div><div class="line">		<span class="keyword">int</span> BlockNum = next.getBlockLocations().length;</div><div class="line">		<span class="keyword">if</span> (BlockNum != <span class="number">0</span>) &#123;</div><div class="line">			<span class="keyword">int</span> repNum = next.getReplication();</div><div class="line">			<span class="keyword">int</span> oneRepCount = BlockNum * repNum;</div><div class="line">			repCount += oneRepCount;</div><div class="line">			blockCount += BlockNum;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	System.out.println(<span class="string">"副本总数："</span> + repCount + <span class="string">"\n数据块总数："</span> + blockCount + <span class="string">"\n平均副本数："</span> + repCount*<span class="number">1</span>D / blockCount);</div><div class="line">	HDFSUtils.closeFileSystem();</div><div class="line">&#125;</div></pre></td></tr></table></figure></article><div class="random-toc-area"><button class="btn-hide-toc btn-hide-toc-show" style="display:none" onclick="TOCToggle()">显示目录</button> <button class="btn-hide-toc btn-hide-toc-hide" onclick="TOCToggle()">隐藏目录</button><div class="random-toc"><h2>目录</h2><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#准备工作"><span class="toc-text">准备工作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#公共工具类"><span class="toc-text">公共工具类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#删除HDFS集群中所有空文件和空目录"><span class="toc-text">删除HDFS集群中所有空文件和空目录</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#使用流的方式上传下载文件"><span class="toc-text">使用流的方式上传下载文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比"><span class="toc-text">统计HDFS文件系统中文件大小小于HDFS集群中默认块大小的文件占比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#统计出HDFS文件系统中平均副本数"><span class="toc-text">统计出HDFS文件系统中平均副本数</span></a></li></ol></div></div><nav id="pagination"><a href="/archives/2018/03/18/" class="prev">&larr; 上一篇 MapReduce编程案例（上）</a> <a href="/archives/2018/03/11/" class="next">下一篇 HDFS核心设计 &rarr;</a></nav><div id="uyan_frame"></div></div></div><div id="bottom-outer"><div id="bottom-inner">Site by RukiapR0ss using <a href="http://hexo.io">Hexo</a> & <a href="https://github.com/stiekel/hexo-theme-random">Random</a><br></div></div></div></div><script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2160266"></script><div id="user-card"><div class="center-field"><img class="avatar" src="/images/avator.jpg"><p id="description">我不会去表白，爱就是这么让人难堪，你也知道这藏头诗是多么无趣</p><ul class="social-icon"><li><a href="https://github.com/prosscode"><i class="icon iconfont github">&#xe606;</i></a></li><li><a href="https://www.zhihu.com/people/ProSS"><i class="icon iconfont zhihu">&#xe60b;</i></a></li><li><a href="/atom.xml"><i class="icon iconfont rss">&#xe60e;</i></a></li></ul></div></div><div id="btn-view">Hide</div><script>var isIgnoreHost=!1;window&&window.location&&window.location.host&&(isIgnoreHost=["localhost","127.0.0.1"].some(function(o){return 0===window.location.host.indexOf(o)}));var isTriggerAnalytics=!isIgnoreHost</script><script src="/js/jquery-2.2.3.min.js"></script><script src="/js/vegas.min.js"></script><script src="/js/random.js"></script><script src="/js/highlight.pack.js"></script><script src="/js/jquery.mousewheel.pack.js"></script><script src="/js/jquery.fancybox.pack.js"></script><script src="/js/jquery.fancybox-thumbs.js"></script><script src="/js/plyr.js"></script><script>var backgroundImages=[];$("#post").each(function(t){$(this).find("img").each(function(){if(!$(this).parent().hasClass("fancybox")&&!$(this).parent().hasClass("fancybox-thumb")){var t=this.alt||this.title;t&&$(this).after('<span class="caption">'+t+"</span>"),$(this).wrap('<a href="'+this.src+'" title="'+t+'" class="fancybox"></a>')}}),$(this).find(".fancybox").each(function(){$(this).attr("rel","post"+t)})}),$(".fancybox").fancybox();var vegasConfig={"preload­Image":!0,transition:["fade2"],timer:!0,delay:15e3,shuffle:!0,count:20},unsplashConfig={gravity:"center"},turnoffBackgroundImage=!1;turnoffBackgroundImage=!0;var backgroundColor="34495E";$(".fancybox-thumb").fancybox({prevEffect:"none",nextEffect:"none",helpers:{title:{type:"outside"},thumbs:{width:50,height:50}}}),$(".video-container iframe").each(function(t){var a=$(this).attr("src"),e=a.split("/").pop(),s=document.createElement("div");s.className="plyr";var n=document.createElement("div");switch(n.dataset.videoId=e,!0){case a.search("youtube.com")>=0:n.dataset.type="youtube";break;case a.search("vimeo.com")>=0:n.dataset.type="vimeo";break;default:return}s.appendChild(n),$(this).parent().html(s)}),plyr.setup(".plyr",{iconUrl:"/css/sprite.svg"})</script></body></html><!-- rebuild by neat -->