<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  
  <title>Kafka日志消息解析 | Pross&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
    <meta name="author" content="RukiapR0ss">
  
  
    <meta name="description" content="我们知道，写入kafka的消息都需要指定一个Topic（主题），Kafka可以根据Topic来对消息进行区分，每个Topic分为多个Partition（分区）。
Partition的概念是为了实现高伸缩性和提供负载均衡的作用，可以很好的让一个比较大的（数据量级）Topic中的消息可以分布到多台broker机器上。不仅如此，也可以提高并行能力，因为水平扩展后可以以Partition为粒度进行读写，这">
  
  <meta name="description" content="我们知道，写入kafka的消息都需要指定一个Topic（主题），Kafka可以根据Topic来对消息进行区分，每个Topic分为多个Partition（分区）。 Partition的概念是为了实现高伸缩性和提供负载均衡的作用，可以很好的让一个比较大的（数据量级）Topic中的消息可以分布到多台broker机器上。不仅如此，也可以提高并行能力，因为水平扩展后可以以Partition为粒度进行读写，这">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka日志消息解析">
<meta property="og:url" content="https://pross.space/blog/2021/03/14/kafka-log-message-analysis.html">
<meta property="og:site_name" content="Pross&#39;s Blog">
<meta property="og:description" content="我们知道，写入kafka的消息都需要指定一个Topic（主题），Kafka可以根据Topic来对消息进行区分，每个Topic分为多个Partition（分区）。 Partition的概念是为了实现高伸缩性和提供负载均衡的作用，可以很好的让一个比较大的（数据量级）Topic中的消息可以分布到多台broker机器上。不仅如此，也可以提高并行能力，因为水平扩展后可以以Partition为粒度进行读写，这">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-03-14T06:49:39.000Z">
<meta property="article:modified_time" content="2021-03-15T05:19:11.338Z">
<meta property="article:author" content="RukiapR0ss">
<meta property="article:tag" content="技术">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Pross&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div class="wrapper">
    <header id="header">
  <div class="title">
    <h1><a href="/">Pross&#39;s Blog</a></h1>
    <p><a href="/"></a></p>
  </div>
  <nav class="nav">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
        <li><a href="/about">About</a></li>
      
        <li><a href="/daysmatter">Daysmatter</a></li>
      
      
        <li><a href="/atom.xml">RSS</a></li>
      
    </ul>
    <div class="clearfix"></div>
  </nav>
  <div class="clearfix"></div>
</header>
    <div class="content"><article class="post">
  <header>
    
      <div class="icon"></div>
      <a href="/blog/2021/03/14/kafka-log-message-analysis.html">
  <time datetime="2021-03-14T06:49:39.000Z">
    2021-03-14
  </time>
</a>
    
    
  
    <h1 class="title">Kafka日志消息解析</h1>
  

  </header>
  
  <div class="entry">
    
      <p>我们知道，写入kafka的消息都需要指定一个Topic（主题），Kafka可以根据Topic来对消息进行区分，每个Topic分为多个Partition（分区）。</p>
<p>Partition的概念是为了实现高伸缩性和提供负载均衡的作用，可以很好的让一个比较大的（数据量级）Topic中的消息可以分布到多台broker机器上。不仅如此，也可以提高并行能力，因为水平扩展后可以以Partition为粒度进行读写，这样每个broker节点都能独立执行各自分区的读写请求；</p>
<p>Partition下就是Log的消息体，每条消息都只会保存在某一个分区中，而且在每个Partition下消息都是append模式写入的，也就是说，每个Partition下的消息都是顺序性的。</p>
<p>Kafka消息设计方式就是这样的三层结构：主题-分区-消息；说到设计，不同的分布式系统对分区的叫法也不大一样，在Kafka中的概念是Partition（分区），在ES中叫做Shard（分片），而在HBase中被称为Region。从表面上来看实现原理可能不尽相同，但对底层实现的思想却都是一致的。</p>
<p>话题扯回来，今天这篇文章分享的主题是：Kafka消息格式。</p>
<a id="more"></a>

<p>消息存储在哪，取决于broker端的<code>log.dirs</code>参数决定，目录文件如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── __consumer_offsets-0</span><br><span class="line">│   ├── 00000000000000000000.index</span><br><span class="line">│   ├── 00000000000000000000.log</span><br><span class="line">│   ├── 00000000000000000000.timeindex</span><br><span class="line">│   └── leader-epoch-checkpoint</span><br><span class="line">├── log-start-offset-checkpoint</span><br><span class="line">├── meta.properties</span><br><span class="line">├── recovery-point-offset-checkpoint</span><br><span class="line">├── replication-offset-checkpoint</span><br><span class="line">├── test1-0</span><br><span class="line">├── test2-0</span><br><span class="line">└── test2-1</span><br><span class="line">    ├── 00000000000000000000.index</span><br><span class="line">    ├── 00000000000000000000.log</span><br><span class="line">    ├── 00000000000000000000.timeindex</span><br><span class="line">    ├── 00000000000000000013.index</span><br><span class="line">    ├── 00000000000000000013.log</span><br><span class="line">    ├── 00000000000000000013.timeindex</span><br><span class="line">    └── leader-epoch-checkpoint</span><br></pre></td></tr></table></figure>
<h4 id="位移主题"><a href="#位移主题" class="headerlink" title="位移主题"></a>位移主题</h4><p>__consumer_offsets是位移主题，老版本的Consumer的位移管理是在Zookeeper，在新版本中位移管理机制中是作为一个内部Topic的方式来记录位移。</p>
<p>新版本位移管理机制其实也比较简单，是将Consumer的位移数据作为一条条普通的 Kafka 消息，提交到__consumer_offsets中，以前读写位移操作就由Zookeeper变成了Kafka自身。在位移主题中的消息包含三类，消费者组注册消息（Group Metadata）、消费者组的已提交位移消息（Offset Commit）和Tombstone消息；其写入提交过程都可以交由Kafka自动管理起来，应用上并没有太大的差异。</p>
<p><strong>注册消息</strong></p>
<p>我们随着获取注册消息的key和value方法一路看下去</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> key = <span class="type">GroupMetadataManager</span>.groupMetadataKey(group.groupId)</span><br><span class="line"><span class="keyword">val</span> value = <span class="type">GroupMetadataManager</span>.groupMetadataValue(group, groupAssignment, interBrokerProtocolVersion)</span><br></pre></td></tr></table></figure>
<p>注册消息的key</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">GroupMetadataKey</span>(<span class="params">version: <span class="type">Short</span>, key: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">BaseKey</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 保存的是消费者组名称</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">toString</span></span>: <span class="type">String</span> = key</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由GroupMetadataManager类中的groupMetadataKey方法而来</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[group] <span class="function"><span class="keyword">def</span> <span class="title">groupMetadataKey</span></span>(group: <span class="type">String</span>): <span class="type">Array</span>[<span class="type">Byte</span>] = &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> key = <span class="keyword">new</span> <span class="type">Struct</span>(<span class="type">CURRENT_GROUP_KEY_SCHEMA</span>)</span><br><span class="line">    key.set(<span class="type">GROUP_KEY_GROUP_FIELD</span>, group)</span><br><span class="line">		<span class="comment">// 构造ByteBuffer对象，容纳version和key</span></span><br><span class="line">    <span class="keyword">val</span> byteBuffer = <span class="type">ByteBuffer</span>.allocate(<span class="number">2</span> <span class="comment">/* version */</span> + key.sizeOf)</span><br><span class="line">    byteBuffer.putShort(<span class="type">CURRENT_GROUP_KEY_SCHEMA_VERSION</span>)</span><br><span class="line">  	<span class="comment">// 写入byteBuffer</span></span><br><span class="line">    key.writeTo(byteBuffer)</span><br><span class="line">    byteBuffer.array()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>注册消息的key构造完毕，接下来是value。groupMetadataValue 方法会将消费者组重要的元数据写入到字节数组并返回。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * GroupMetadata 消费者组元数据对象</span></span><br><span class="line"><span class="comment"> * assignment 分区消费分配方案</span></span><br><span class="line"><span class="comment"> * apiVersion api版本号</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span>[group] <span class="function"><span class="keyword">def</span> <span class="title">groupMetadataValue</span></span>(groupMetadata: <span class="type">GroupMetadata</span>,</span><br><span class="line">                                        assignment: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Array</span>[<span class="type">Byte</span>]],</span><br><span class="line">                                        apiVersion: <span class="type">ApiVersion</span>): <span class="type">Array</span>[<span class="type">Byte</span>] = &#123;</span><br><span class="line">  	...</span><br><span class="line">  	<span class="comment">// 依次写入消费者组主要的元数据信息</span></span><br><span class="line">    value.set(<span class="type">PROTOCOL_TYPE_KEY</span>, groupMetadata.protocolType.getOrElse(<span class="string">&quot;&quot;</span>))</span><br><span class="line">    value.set(<span class="type">GENERATION_KEY</span>, groupMetadata.generationId)</span><br><span class="line">    value.set(<span class="type">PROTOCOL_KEY</span>, groupMetadata.protocolOrNull)</span><br><span class="line">    value.set(<span class="type">LEADER_KEY</span>, groupMetadata.leaderOrNull)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">val</span> memberArray = groupMetadata.allMemberMetadata.map &#123; memberMetadata =&gt;</span><br><span class="line">      <span class="keyword">val</span> memberStruct = value.instance(<span class="type">MEMBERS_KEY</span>)</span><br><span class="line">      memberStruct.set(<span class="type">MEMBER_ID_KEY</span>, memberMetadata.memberId)</span><br><span class="line">      memberStruct.set(<span class="type">CLIENT_ID_KEY</span>, memberMetadata.clientId)</span><br><span class="line">      memberStruct.set(<span class="type">CLIENT_HOST_KEY</span>, memberMetadata.clientHost)</span><br><span class="line">      memberStruct.set(<span class="type">SESSION_TIMEOUT_KEY</span>, memberMetadata.sessionTimeoutMs)</span><br><span class="line">			...</span><br><span class="line">      <span class="comment">// 写入消费订阅信息和费分配方案信息</span></span><br><span class="line">      <span class="keyword">val</span> metadata = memberMetadata.metadata(protocol)</span><br><span class="line">      memberStruct.set(<span class="type">SUBSCRIPTION_KEY</span>, <span class="type">ByteBuffer</span>.wrap(metadata))</span><br><span class="line">      <span class="keyword">val</span> memberAssignment = assignment(memberMetadata.memberId)</span><br><span class="line">      assert(memberAssignment != <span class="literal">null</span>)</span><br><span class="line">      memberStruct.set(<span class="type">ASSIGNMENT_KEY</span>, <span class="type">ByteBuffer</span>.wrap(memberAssignment))</span><br><span class="line">      memberStruct</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    value.set(<span class="type">MEMBERS_KEY</span>, memberArray.toArray)</span><br><span class="line">  	<span class="comment">// 写入byteBuffer 并返回</span></span><br><span class="line">    <span class="keyword">val</span> byteBuffer = <span class="type">ByteBuffer</span>.allocate(<span class="number">2</span> <span class="comment">/* version */</span> + value.sizeOf)</span><br><span class="line">    byteBuffer.putShort(version)</span><br><span class="line">    value.writeTo(byteBuffer)</span><br><span class="line">    byteBuffer.array()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>随后会组装成消息体，通过appendForGroup方法写入到位移主题中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// build records</span></span><br><span class="line"><span class="keyword">val</span> records = &#123;</span><br><span class="line">          <span class="keyword">val</span> buffer = <span class="type">ByteBuffer</span>.allocate(<span class="type">AbstractRecords</span>.estimateSizeInBytes(magicValue, compressionType,</span><br><span class="line">            <span class="type">Seq</span>(<span class="keyword">new</span> <span class="type">SimpleRecord</span>(timestamp, key, value)).asJava))</span><br><span class="line">          <span class="keyword">val</span> builder = <span class="type">MemoryRecords</span>.builder(buffer, magicValue, compressionType, timestampType, <span class="number">0</span>L)</span><br><span class="line">          builder.append(timestamp, key, value)</span><br><span class="line">          builder.build()</span><br></pre></td></tr></table></figure>
<p>注册消息体主体结构为：&lt;消费者组名称 group.groupId , 消费者组主要的元数据信息 groupMetadata / 消费订阅信息 metadata / 分配方案信息 memberAssignment&gt;。</p>
<p><strong>位移消息</strong></p>
<p>构造位移消息的key</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 参数是version和GroupTopicPartition</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">OffsetKey</span>(<span class="params">version: <span class="type">Short</span>, key: <span class="type">GroupTopicPartition</span></span>) <span class="keyword">extends</span> <span class="title">BaseKey</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">toString</span></span>: <span class="type">String</span> = key.toString</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// GroupTopicPartition 类型是 &lt;消费者组名，主题，分区&gt; 的三元组。</span></span><br><span class="line"><span class="type">OffsetKey</span>(version, <span class="type">GroupTopicPartition</span>(group, <span class="keyword">new</span> <span class="type">TopicPartition</span>(topic, partition)))</span><br></pre></td></tr></table></figure>
<p>位移消息的value，在offsetCommitValue 方法决定了 value 中都有哪些元素。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> offsetAndMetadata = <span class="type">GroupMetadataManager</span>.readOffsetMessageValue(record.value)</span><br><span class="line">...</span><br><span class="line"><span class="keyword">private</span>[group] <span class="function"><span class="keyword">def</span> <span class="title">offsetCommitValue</span></span>(offsetAndMetadata: <span class="type">OffsetAndMetadata</span>,</span><br><span class="line">                                       apiVersion: <span class="type">ApiVersion</span>): <span class="type">Array</span>[<span class="type">Byte</span>] = &#123;</span><br><span class="line">  	<span class="comment">// 根据不同的消息格式版本，创建对应的对象</span></span><br><span class="line">    <span class="keyword">val</span> (version, value) = &#123;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">if</span> (apiVersion &lt; <span class="type">KAFKA_2_1_IV0</span> || offsetAndMetadata.expireTimestamp.nonEmpty) &#123;</span><br><span class="line">				...</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (apiVersion &lt; <span class="type">KAFKA_2_1_IV1</span>) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 依次写入位移值、Leader Epoch值、自定义元数据以及时间戳</span></span><br><span class="line">        <span class="keyword">val</span> value = <span class="keyword">new</span> <span class="type">Struct</span>(<span class="type">OFFSET_COMMIT_VALUE_SCHEMA_V3</span>)</span><br><span class="line">        value.set(<span class="type">OFFSET_VALUE_OFFSET_FIELD_V3</span>, offsetAndMetadata.offset)</span><br><span class="line">        value.set(<span class="type">OFFSET_VALUE_LEADER_EPOCH_FIELD_V3</span>,</span><br><span class="line">          offsetAndMetadata.leaderEpoch.orElse(<span class="type">RecordBatch</span>.<span class="type">NO_PARTITION_LEADER_EPOCH</span>))</span><br><span class="line">        value.set(<span class="type">OFFSET_VALUE_METADATA_FIELD_V3</span>, offsetAndMetadata.metadata)</span><br><span class="line">        value.set(<span class="type">OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3</span>, offsetAndMetadata.commitTimestamp)</span><br><span class="line">        (<span class="number">3</span>, value)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">		<span class="comment">// 构建ByteBuffer，写入消息格式版本和结构体并返回</span></span><br><span class="line">    <span class="keyword">val</span> byteBuffer = <span class="type">ByteBuffer</span>.allocate(<span class="number">2</span> <span class="comment">/* version */</span> + value.sizeOf)</span><br><span class="line">    byteBuffer.putShort(version.toShort)</span><br><span class="line">    value.writeTo(byteBuffer)</span><br><span class="line">    byteBuffer.array()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>随后也会组装消息体SimpleRecord，通过MemoryRecords.builder后，由appendForGroup方法发送。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> records = filteredOffsetMetadata.map &#123; <span class="keyword">case</span> (topicPartition, offsetAndMetadata) =&gt;</span><br><span class="line">            <span class="keyword">val</span> key = <span class="type">GroupMetadataManager</span>.offsetCommitKey(group.groupId, topicPartition)</span><br><span class="line">            <span class="keyword">val</span> value = <span class="type">GroupMetadataManager</span>.offsetCommitValue(offsetAndMetadata, interBrokerProtocolVersion)</span><br><span class="line">            <span class="keyword">new</span> <span class="type">SimpleRecord</span>(timestamp, key, value)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// build MemoryRecords</span></span><br><span class="line"><span class="keyword">val</span> builder = <span class="type">MemoryRecords</span>.builder(buffer, magicValue, compressionType, timestampType, <span class="number">0</span>L, time.milliseconds(),</span><br><span class="line">            producerId, producerEpoch, <span class="number">0</span>, isTxnOffsetCommit, <span class="type">RecordBatch</span>.<span class="type">NO_PARTITION_LEADER_EPOCH</span>)</span><br><span class="line"><span class="comment">// 可能会有多个record，遍历append build</span></span><br><span class="line">records.foreach(builder.append)</span><br><span class="line"></span><br><span class="line"><span class="comment">// entries终将会传入appendForGroup方法</span></span><br><span class="line"><span class="keyword">val</span> entries = <span class="type">Map</span>(offsetTopicPartition -&gt; builder.build())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>位移消息的主体格式是：&lt; version / &lt;消费者组名，主题，分区&gt; , 位移值 / Leader Epoch值 / 元数据信息 / 时间戳&gt;。</p>
<p><strong>Tombstone消息</strong></p>
<p>翻译过来就是墓碑消息，Tombstone消息的Value 为 null。Tombstone消息在注册消息和位移消息中都可能出现。如果在注册消息中出现，表示Kafka可以将该消费者组元数据从位移主题中删除；如果在位移消息中出现了，则表示Kafka能够将该消费者组在某主题分区上的位移提交数据删除。这很好的保证了，内部位移主题不会持续增加磁盘占用空间。</p>
<h4 id="Checkpoint文件"><a href="#Checkpoint文件" class="headerlink" title="Checkpoint文件"></a>Checkpoint文件</h4><p>Log-start-offset-checkpoint文件是用来标识LogStartOffset（日志的起始偏移量），recovery-point-offset-checkpoint和replication-offset-checkpoint这两个文件分别对应了Log End Offset（日志末端位移）和High Watermark（副本的高水印值）。</p>
<p>会有定时任务负责将所有分区的LogStartOffset，LEO，HW写到以上文件中，定时周期由broker端参数<code>log.flush.start.offset.checkpoint.interval.ms</code>，<code>log.flush.offset. checkpoint.interval.ms</code>，<code>replica.high.watermark.checkpoint.interval.ms</code>决定。</p>
<p>对应的机制是为了解决数据丢失或数据不一致的问题，在Kafka中还需要结合<code>Leader Epoch</code>来共同解决，日后可详细再言。</p>
<h4 id="消息日志"><a href="#消息日志" class="headerlink" title="消息日志"></a>消息日志</h4><p>消息存储的目录格式默认为：topic-partition_num；展示的Topic为test1（一个分区）和test2（两个分区）：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">├── test1-0</span><br><span class="line">├── test2-0</span><br><span class="line">└── test2-1</span><br><span class="line">    ├── 00000000000000000000.index</span><br><span class="line">    ├── 00000000000000000000.log</span><br><span class="line">    ├── 00000000000000000000.timeindex</span><br><span class="line">    ├── 00000000000000000013.index</span><br><span class="line">    ├── 00000000000000000013.log</span><br><span class="line">    ├── 00000000000000000013.timeindex</span><br><span class="line">    └── leader-epoch-checkpoint</span><br></pre></td></tr></table></figure>
<p>文章在开篇谈到，一个分区对应一个日志(Log)，为了防止日志过大，引入了日志分段(LogSegment）概念，切分成多个较小文件；Log在物理上是以文件夹的形式存储，而每个LogSegment对应着磁盘上的日志文件：以”.log”为文件后缀，和两个索引文件：偏移量的索引文件（以”.index”为文件后缀）和时间戳的索引文件（以”.timeindex”为文件后缀），而<code>leader-epoch-checkpoint</code>保存的是Leader Epoch的值（解决副本数据一致性需要）。</p>
<p><strong>LogSegment</strong></p>
<p>LogSegment的大小取决于broker端的<code>log.segment.bytes</code>参数决定，我们先看看LogSegment的构造参数：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * log Kafka消息对象</span></span><br><span class="line"><span class="comment"> * lazyOffsetIndex 位移索引文件</span></span><br><span class="line"><span class="comment"> * lazyTimeIndex 时间戳索引文件</span></span><br><span class="line"><span class="comment"> * txnIndex 已中止事务索引文件</span></span><br><span class="line"><span class="comment"> * baseOffset 每个日志段对象的起始位移</span></span><br><span class="line"><span class="comment"> * indexIntervalBytes 日志对象新增索引项的频率</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogSegment</span> <span class="title">private</span>[log] (<span class="params">val log: <span class="type">FileRecords</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyOffsetIndex: <span class="type">LazyOffsetIndex</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyTimeIndex: <span class="type">LazyTimeIndex</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val txnIndex: <span class="type">TransactionIndex</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val baseOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val indexIntervalBytes: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val rollJitterMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                               val time: <span class="type">Time</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">...</span></span><br><span class="line"><span class="class"><span class="comment">/**</span></span></span><br><span class="line"><span class="class"><span class="comment"> * largestOffset  待写入消息批次中消息的最大位移值</span></span></span><br><span class="line"><span class="class"><span class="comment"> * largestTimestamp 最大时间戳</span></span></span><br><span class="line"><span class="class"><span class="comment"> * shallowOffsetOfMaxTimestamp 最大时间戳对应消息的位移</span></span></span><br><span class="line"><span class="class"><span class="comment"> * records 待写入的消息体</span></span></span><br><span class="line"><span class="class"><span class="comment"> */</span></span></span><br><span class="line"><span class="class"><span class="title">def</span> <span class="title">append</span>(<span class="params">largestOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">             largestTimestamp: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">             shallowOffsetOfMaxTimestamp: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">             records: <span class="type">MemoryRecords</span></span>)</span>: <span class="type">Unit</span> = &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * startOffset 要读取的第一条消息的位移</span></span><br><span class="line"><span class="comment"> * maxSize 能读取的最大字节数</span></span><br><span class="line"><span class="comment"> * maxPosition 能读到的最大文件位置</span></span><br><span class="line"><span class="comment"> * minOneMessage 是否允许在消息体过大时至少返回第一条消息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(startOffset: </span><br><span class="line">         <span class="type">Long</span>, maxOffset: <span class="type">Option</span>[<span class="type">Long</span>], </span><br><span class="line">         maxSize: <span class="type">Int</span>, </span><br><span class="line">         maxPosition: <span class="type">Long</span> = size,</span><br><span class="line">         minOneMessage: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">FetchDataInfo</span> = &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * leaderEpochCache 在恢复过程中缓存的leaderEpoch值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recover</span></span>(producerStateManager: <span class="type">ProducerStateManager</span>, </span><br><span class="line">            leaderEpochCache: <span class="type">Option</span>[<span class="type">LeaderEpochFileCache</span>] = <span class="type">None</span>): <span class="type">Int</span> = &#123;...&#125;</span><br></pre></td></tr></table></figure>
<p>通过几项参数，大概可以猜测出这样构造LogSegment的意义。每个segment保存的是消息实体，FileRecords是必不可少，通过位移索引和时间戳索引可以快速定位到该segment的消息。在LogSegment类中，需要读写消息（append和read）；需要恢复日志段（recover），broker启动时需要从磁盘文件中加载所有的日志段信息到内存中等功能的实现。</p>
<p>可以通过Kafka client命令来查看消息存储的详细内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-run-class.sh kafka.tools.DumpLogSegments \ </span><br><span class="line">	--files /tmp/kafka-logs/test2-1/00000000000000000000.log \</span><br><span class="line">	--print-data-log </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">| offset: 342 CreateTime: 1615706871552 keysize: -1 valuesize: 50 sequence: -1 headerKeys: [] payload: &#123;<span class="string">&quot;type&quot;</span>:<span class="string">&quot;bootstrap-insert&quot;</span>,<span class="string">&quot;is_valid&quot;</span>:0,<span class="string">&quot;version&quot;</span>:4,<span class="string">&quot;ts&quot;</span>:1613980836,<span class="string">&quot;create_time&quot;</span>:<span class="string">&quot;2020-05-04 07:41:29&quot;</span>,<span class="string">&quot;update_time&quot;</span>:<span class="string">&quot;2020-07-04 12:40:15&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>根据位移值，我们可以通过.index文件快速查找消息所在文件位置；根据时间戳，我们可以通过.timeindex查找；所以快速的查找的根本原因，是基于消息存储格式和机制来决定的。</p>
<p><strong>Message</strong></p>
<p>接下来继续看下消息Message内部结构，也就是LogSegment构造类中的FileRecords参数是怎么样的格式。</p>
<p>前面有追踪过位移主题内的消息体的定义，都是采用的map格式，这是便于快速取得位移值；但是真正的消息实体和位移主题的消息格式还是有很大的不同，要考虑消息的完整性、元数据信息的表示、消息属性等等，另外我们只是讨论<strong>消息未压缩</strong>的情景。</p>
<p>Kafka的消息结构在设计时，有过几次设计变化：在Kafka 0.10.0版本之前都是采用的是无timestamp字段（v0版本），在其之后的版本添加了timestamp字段，表示消息的时间戳（v1版本）。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">v0</span><br><span class="line"><span class="type">Message</span> =&gt; <span class="type">Crc</span> <span class="type">MagicByte</span> <span class="type">Attributes</span> <span class="type">Key</span> <span class="type">Value</span></span><br><span class="line">  <span class="type">Crc</span> =&gt; int32</span><br><span class="line">  <span class="type">MagicByte</span> =&gt; int8</span><br><span class="line">  <span class="type">Attributes</span> =&gt; int8</span><br><span class="line">  <span class="type">Key</span> =&gt; bytes</span><br><span class="line">  <span class="type">Value</span> =&gt; bytes</span><br><span class="line">  </span><br><span class="line">v1 (supported since <span class="number">0.10</span><span class="number">.0</span>)</span><br><span class="line"><span class="type">Message</span> =&gt; <span class="type">Crc</span> <span class="type">MagicByte</span> <span class="type">Attributes</span> <span class="type">Key</span> <span class="type">Value</span></span><br><span class="line">	<span class="comment">// CRC用于检查代理和消息的完整</span></span><br><span class="line">  <span class="type">Crc</span> =&gt; int32</span><br><span class="line">	<span class="comment">// 版本id，用于允许消息二进制格式的向后兼容演变。当前值为1。</span></span><br><span class="line">  <span class="type">MagicByte</span> =&gt; int8</span><br><span class="line">	<span class="comment">// 保存有关消息的元数据属性</span></span><br><span class="line">	<span class="comment">// 最低3位包含用于消息的压缩解码器</span></span><br><span class="line">	<span class="comment">// 最低的第4位用于表示时间戳类型，0代表createtime,1代表logappendtime。</span></span><br><span class="line">  <span class="type">Attributes</span> =&gt; int8</span><br><span class="line">	<span class="comment">// 消息时间戳</span></span><br><span class="line">  <span class="type">Timestamp</span> =&gt; int64</span><br><span class="line">	<span class="comment">// 分区分配的可选消息密钥</span></span><br><span class="line">  <span class="type">Key</span> =&gt; bytes</span><br><span class="line">	<span class="comment">// 实际消息内容，可能是包含的一个消息集。</span></span><br><span class="line">  <span class="type">Value</span> =&gt; bytes</span><br></pre></td></tr></table></figure>
<p>实现类是message类：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Message</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// crc 消息的校验码，防止消息错误（4B）</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">CrcOffset</span> = <span class="number">0</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">CrcLength</span> = <span class="number">4</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// magic 消息格式的版本号（1B）</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">MagicOffset</span> = <span class="type">CrcOffset</span> + <span class="type">CrcLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">MagicLength</span> = <span class="number">1</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// attributes 消息的属性，比如压缩类型，时间戳类型，创建时间/追加时间 (1B)</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">AttributesOffset</span> = <span class="type">MagicOffset</span> + <span class="type">MagicLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">AttributesLength</span> = <span class="number">1</span></span><br><span class="line">  <span class="comment">// timestamp 时间戳信息(8B)</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">TimestampOffset</span> = <span class="type">AttributesOffset</span> + <span class="type">AttributesLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">TimestampLength</span> = <span class="number">8</span></span><br><span class="line">  <span class="comment">// key （4B）</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeySizeOffset_V0</span> = <span class="type">AttributesOffset</span> + <span class="type">AttributesLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeySizeOffset_V1</span> = <span class="type">TimestampOffset</span> + <span class="type">TimestampLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeySizeLength</span> = <span class="number">4</span> </span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeyOffset_V0</span> = <span class="type">KeySizeOffset_V0</span> + <span class="type">KeySizeLength</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">KeyOffset_V1</span> = <span class="type">KeySizeOffset_V1</span> + <span class="type">KeySizeLength</span></span><br><span class="line">  <span class="comment">// value （4B）</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">ValueSizeLength</span> = <span class="number">4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>发送一条key=”key”，value=”value”的消息，在v1版本中最小则会占用22+8+12=42B。</p>
<p>在kafka0.11.0版本后，改动是比较大的，在以前的版本，value是一个消息集（Message Set），而在v2版本中，直接把Crc检查校验，attributes的元数据属性等信息提入了Record Batch属性中，还参考了Protocol Buffer引入了变长整型（Varints）和ZigZag编码大大减少消息体大小。</p>
<p>v2版本Record Batch格式：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 表示当前RecordBatch的起始位移 (8B)</span></span><br><span class="line">baseOffset: int64 </span><br><span class="line"><span class="comment">// 计算partition leader epoch到headers之间的长度 (4B)</span></span><br><span class="line">batchLength: int32</span><br><span class="line"><span class="comment">// 用来确保数据可靠性 4B</span></span><br><span class="line">partitionLeaderEpoch: int32</span><br><span class="line"><span class="comment">// magic等于2 (1B)</span></span><br><span class="line">magic: int8 (current magic value is <span class="number">2</span>)</span><br><span class="line"><span class="comment">// 4B</span></span><br><span class="line">crc: int32</span><br><span class="line"><span class="comment">// 2B</span></span><br><span class="line">attributes: int16</span><br><span class="line">	bit <span class="number">0</span>~<span class="number">2</span>:</span><br><span class="line">		<span class="number">0</span>: no compression</span><br><span class="line">		<span class="number">1</span>: gzip</span><br><span class="line">		<span class="number">2</span>: snappy</span><br><span class="line">		<span class="number">3</span>: lz4</span><br><span class="line">	bit <span class="number">3</span>: timestampType</span><br><span class="line">	bit <span class="number">4</span>: isTransactional (<span class="number">0</span> means not transactional)</span><br><span class="line">	bit <span class="number">5</span>: isControlBatch (<span class="number">0</span> means not a control batch)</span><br><span class="line">	bit <span class="number">6</span>~<span class="number">15</span>: unused</span><br><span class="line"><span class="comment">// 4B</span></span><br><span class="line">lastOffsetDelta: int32</span><br><span class="line"><span class="comment">// 8B</span></span><br><span class="line">firstTimestamp: int64</span><br><span class="line">maxTimestamp: int64</span><br><span class="line">producerId: int64</span><br><span class="line">producerEpoch: int16</span><br><span class="line">baseSequence: int32</span><br><span class="line"><span class="comment">// batch records</span></span><br><span class="line">records: [<span class="type">Record</span>]</span><br></pre></td></tr></table></figure>
<p>v2版本Record格式：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 消息总长度 3B</span></span><br><span class="line">length: varint</span><br><span class="line"><span class="comment">// 弃用</span></span><br><span class="line">attributes: int8</span><br><span class="line">	bit <span class="number">0</span>~<span class="number">7</span>: unused</span><br><span class="line"><span class="comment">// 时间戳增量 3B</span></span><br><span class="line">timestampDelta: varint</span><br><span class="line"><span class="comment">// 位移增量 3B</span></span><br><span class="line">offsetDelta: varint</span><br><span class="line"><span class="comment">// key</span></span><br><span class="line">keyLength: varint</span><br><span class="line">key: byte[]</span><br><span class="line"><span class="comment">// value</span></span><br><span class="line">valueLen: varint</span><br><span class="line">value: byte[]</span><br><span class="line"><span class="type">Headers</span> =&gt; [<span class="type">Header</span>]</span><br></pre></td></tr></table></figure>
<p>v2版本格式中增加了length（消息总长度）、timestamp delta（时间戳增量）、offset delta（位移增量）和headers信息：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">headerKeyLength: varint</span><br><span class="line">headerKey: <span class="type">String</span></span><br><span class="line">headerValueLength: varint</span><br><span class="line"><span class="type">Value</span>: byte[]</span><br></pre></td></tr></table></figure>
<p>根据Varints的规则可以推导出0-63之间的数字占1个字节，64-8191之间的数字占2个字节，8192-1048575之间的数字占3个字节；而kafka broker的配置message.max.bytes的默认大小为1000012（Varints编码占3个字节）。</p>
<p>所以发送一条key=”key”，value=”value”的消息，在v2版本中最小则会占9+3+3=15B。在v0和v1版本的消息格式中，如果消息本身没有key，那么key length字段为-1，int类型的需要4个字节来保存，而v2版本的消息格式中与长度有关的字段都是采用Varints的编码，只需要一个字节，这也会节省很多空间大小。</p>
<hr>
<p>Kafka日志消息存储结构是比较复杂的，底层结构决定着上层功能。从消息结构中，也可以窥得一丝kafka设计的原理和实现的机制。在消息体结构介绍中，对引用的变长整型（Varints）和ZigZag编码了解的较少，所以讲述的不是很详细，不过也需要适可而止的深究技术的深度。</p>
<p>完。</p>
<p><strong>Refer</strong></p>
<p>[1] <a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-Messagesets">A Guide To The Kafka Protocol</a></p>
<p>[2] <a target="_blank" rel="noopener" href="https://kafka.apache.org/10/documentation.html#semantics">kafka deign documentation</a></p>

    
  </div>
  <footer>
    
      
      
  <div class="tags">
    <a class="tags-none-link" href="/tags/Kafka/" rel="tag">Kafka</a>, <a class="tags-none-link" href="/tags/%E6%8A%80%E6%9C%AF/" rel="tag">技术</a>
  </div>

    
    <div class="clearfix"></div>
  </footer>
</article>


</div>
  </div>
  <footer id="footer"><div class="copyright">
  
  &copy; 2021 <a href="/">RukiapR0ss</a>
  
</div>
<div class="theme-copyright">
  Theme by <a href="https://github.com/orderedlist" target="_blank">orderedlist</a>
   | 
  Redesign by <a href="http://heroicyang.com/" target="_blank">Heroic Yang</a>
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js"></script>
<script src="/js/scale.fix.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
  (function($){
    $('.fancybox').fancybox();
  })(jQuery);
</script>

</body>
</html>