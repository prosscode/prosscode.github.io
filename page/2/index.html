<!DOCTYPE HTML><html><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="chrome=1"><title>博客</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="author" content="pross"><meta property="og:type" content="website"><meta property="og:title" content="博客"><meta property="og:url" content="https://pross.space/page/2/index.html"><meta property="og:site_name" content="博客"><meta property="og:locale" content="en_US"><meta property="article:author" content="pross"><meta name="twitter:card" content="summary"><link rel="alternate" href="/atom.xml" title="博客" type="application/atom+xml"><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="stylesheet" href="/css/style.css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><meta name="generator" content="Hexo 5.4.0"></head><body><div class="wrapper"><header id="header"><div class="title"><h1><a href="/">博客</a></h1><p><a href="/"></a></p></div><nav class="nav"><ul><li><a href="/">Home</a></li><li><a href="/archives">Archives</a></li><li><a href="/about">About</a></li><li><a href="/daysmatter">Daysmatter</a></li><li><a href="/atom.xml">RSS</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div class="content"><article class="post"><header><div class="icon"></div><a href="/blog/2019/apache-thrift-thrift-thrift/"><time datetime="2019-09-09T15:10:18.000Z">2019-09-09</time></a><h1 class="title"><a href="/blog/2019/apache-thrift-thrift-thrift/">Apache-Thrift-Thrift-Thrift</a></h1></header><div class="entry"><p>接着上篇文章说。</p><p>我们知道了Apache Thrift主要用于各个服务之间的RPC通信，并且支持跨语言；包括C++，Java，Python，PHP，Ruby，Go，Node.js等等，还有一些都没听说过的语言；而且从上篇文章的RPC例子中可以发现，Thrift是一个典型的CS（客户端/服务端）架构；加上跨语言的特性，我们可以推断一下：客户端和服务端是可以使用不同的语言开发的。</p><p>如果CS端可以使用不同的语言来开发，那么一定是有一种中间语言来关联客户端和服务端（相同语言也需要关联客户端和服务端）。其实这个答案都知道，那就是接口定义语言：IDL（Interface Description Language）；下面我们从IDL进行开场表演，进行一次Thrift RPC的完整演出。</p></div><footer class="end-sep"><div class="alignleft"><a href="/blog/2019/apache-thrift-thrift-thrift/#more" class="more-link">Read More</a></div><div class="clearfix"></div></footer></article><article class="post"><header><div class="icon"></div><a href="/blog/2019/remote-procedure-call/"><time datetime="2019-08-16T16:13:44.000Z">2019-08-17</time></a><h1 class="title"><a href="/blog/2019/remote-procedure-call/">远程过程调用</a></h1></header><div class="entry"><p>原本是写一篇Apache Thrift in HiveServer，改写JDBC连接Hive相关应用的推文，因为HiveServer是使用Thrift提供服务创建网络RPC的多种语言客户端；单独拿出来说，使用Thrift也可以轻松构建RPC服务器，是轻量级的跨语言的远程服务调用框架。说到远程过程调用，感觉又要解释很多，所以就先上个前菜，说一说远程过程调用（RPC）；并加了一份佐料：关于JDBC连接Hive的实现。</p></div><footer class="end-sep"><div class="alignleft"><a href="/blog/2019/remote-procedure-call/#more" class="more-link">Read More</a></div><div class="clearfix"></div></footer></article><article class="post"><header><div class="icon"></div><a href="/blog/2019/understand-the-rdd-at-core-of-spark/"><time datetime="2019-05-29T09:04:41.000Z">2019-05-29</time></a><h1 class="title"><a href="/blog/2019/understand-the-rdd-at-core-of-spark/">理解Spark核心之RDD</a></h1></header><div class="entry"><p>Spark是围绕RDD的概念展开的，RDD是可以并行操作的容错元素集合。RDD全称是Resilient Distributed Datasets（弹性分布式数据集）</p><h4 id="理解RDD"><a href="#理解RDD" class="headerlink" title="理解RDD"></a>理解RDD</h4><p>如果你在Spark集群中加载了一个很大的文本数据，Spark就会将该文本抽象为一个RDD，这个RDD根据你定义的分区策略（比如HashKey）可以分为数个Partition，这样就可以对各个分区进行并行处理，从而提高效率。</p></div><footer class="end-sep"><div class="alignleft"><a href="/blog/2019/understand-the-rdd-at-core-of-spark/#more" class="more-link">Read More</a></div><div class="clearfix"></div></footer></article><article class="post"><header><div class="icon"></div><a href="/blog/2019/spark-operating-mode/"><time datetime="2019-03-15T12:56:12.000Z">2019-03-15</time></a><h1 class="title"><a href="/blog/2019/spark-operating-mode/">Spark的运行模式</a></h1></header><div class="entry"><p>Spark是新一代基于内存的计算框架，是用于大规模数据处理的同意分析引擎。相比于Hadoop MapReduce计算框架，Spark将中间计算结果保留在内存中，速度提升10~100倍；同时采用弹性分布式数据集（RDD）实现迭代计算，更好的适用于数据挖掘、机器学习，极大的提升开发效率。</p><p>Spark的运行模式，它不仅支持单机模式，同时支持集群模式运行；这里具体的总结一下Spark的各种运行模式的区分。</p><h4 id="Local模式"><a href="#Local模式" class="headerlink" title="Local模式"></a>Local模式</h4><p>Local模式又称本地模式，通过Local模式运行非常简单，只需要把Spark的安装包解压后，改一些常用的配置即可使用，而不用启动Spark的Master、Worker进程（只有集群的Standalone模式运行时，才需要这两个角色），也不用启动Hadoop的服务，除非你需要用到HDFS。</p></div><footer class="end-sep"><div class="alignleft"><a href="/blog/2019/spark-operating-mode/#more" class="more-link">Read More</a></div><div class="clearfix"></div></footer></article><article class="post"><header><div class="icon"></div><a href="/blog/2019/use-swagger2-to-build-a-restful-api/"><time datetime="2019-02-01T17:00:44.000Z">2019-02-02</time></a><h1 class="title"><a href="/blog/2019/use-swagger2-to-build-a-restful-api/">使用Swagger2构建RESTful API</a></h1></header><div class="entry"><p>吐槽了一阵公司提供的记录接口文档工具后，抽个空档时间搭了个RESTful风格的API文档Demo，感觉还不错，在这里记录一下，技术栈使用Spring Boot+Swagger2。</p><p>Swagger可以很轻松的整合到Spring Boot中，在代码里根据swagger语法打些标签，生成可预览的Api文档，减少了很多时间写API接口文档上，让维护文档和修改代码整合一体了，并且可以与Spring MVC程序配合组织出强大RESTful API文档，也能提供了强大的页面测试功能来调试测试每个接口。</p></div><footer class="end-sep"><div class="alignleft"><a href="/blog/2019/use-swagger2-to-build-a-restful-api/#more" class="more-link">Read More</a></div><div class="clearfix"></div></footer></article><article class="post"><header><div class="icon"></div><a href="/blog/2019/hash-table/"><time datetime="2019-01-13T14:55:23.000Z">2019-01-13</time></a><h1 class="title"><a href="/blog/2019/hash-table/">散列表</a></h1></header><div class="entry"><p>关于算法系列，在前面已经整理过大O表示法和排序算法相关的文章，今天接着上次的话说一说散列表（Hash Table，也叫哈希表），顺便穿插和另外两种基本的数据结构，数组和链表比较；并在最后介绍良好的散列函数——SHA函数的使用。这三种基本数据结构，可简可繁，在写代码时候都是比较频繁使用的，那我们先从散列表开始入手。</p></div><footer class="end-sep"><div class="alignleft"><a href="/blog/2019/hash-table/#more" class="more-link">Read More</a></div><div class="clearfix"></div></footer></article><nav id="pagination"><a href="/" class="prev">Prev</a> <a href="/page/3/" class="next">Next</a><div class="clearfix"></div></nav></div></div><footer id="footer"><div class="copyright">&copy; 2025 <a href="/">pross</a> <span>,</span> Theme by <a href="https://github.com/orderedlist" target="_blank">orderedlist</a></div><div class="clearfix"></div></footer><script src="//ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js"></script><script src="/js/scale.fix.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>